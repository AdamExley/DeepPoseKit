<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.7.0" />
<title>deepposekit.models.DeepLabCut API documentation</title>
<meta name="description" content="" />
<link href='https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.0/normalize.min.css' rel='stylesheet'>
<link href='https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/8.0.0/sanitize.min.css' rel='stylesheet'>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" rel="stylesheet">
<style>.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{font-weight:bold}#index h4 + ul{margin-bottom:.6em}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>deepposekit.models.DeepLabCut</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python"># -*- coding: utf-8 -*-
# Copyright 2018-2019 Jacob M. Graving &lt;jgraving@gmail.com&gt;
#
# Licensed under the Apache License, Version 2.0 (the &#34;License&#34;);
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at

#    http://www.apache.org/licenses/LICENSE-2.0

# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an &#34;AS IS&#34; BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from tensorflow.keras import Input, Model
from tensorflow.keras.layers import Conv2DTranspose, Concatenate
from deepposekit.models.layers.util import Float
from deepposekit.models.layers.deeplabcut import ImageNetPreprocess, MODELS
from deepposekit.models.layers.convolutional import SubPixelUpscaling

from deepposekit.models.engine import BaseModel
from functools import partial


__docstring__ = &#34;&#34;&#34;
    Define a DeepLabCut model from Mathis et al., 2018 [1][2]
    See `References` for details on the model architecture.

    Parameters
    ----------
    train_generator : class deepposekit.io.TrainingGenerator
        A deepposekit.io.TrainingGenerator class for generating
        images and confidence maps.
    subpixel: bool, default = True
        Whether to use subpixel maxima for calculating
        keypoint coordinates in the prediction model.
    weights: &#34;imagnet&#34; or None, default is &#34;imagenet&#34;
        Which weights to use for initialization. &#34;imagenet&#34; uses
        weights pretrained on imagenet. None uses randomly initialized
        weights.
    backbone: string, default is &#34;resnet50&#34;
        pretrained backbone network to use. Must be one of {}. See [3].
    alpha: float, default is 1.0
        Which MobileNetV2 to use. Must be one of:
        {}
        Not used if backbone is not &#34;mobilenetv2&#34;.

    Attributes
    -------
    train_model: keras.Model
        A model for training the network to produce confidence maps with
        one input layer for images
    predict_model: keras.Model
        A model for predicting keypoint coordinates using with Maxima2D or
        SubpixelMaxima2D layers at the output of the network.

    Both of these models share the same computational graph,
    so training train_model updates the weights of predict_model

    References
    ----------
    [1] Mathis, A., Mamidanna, P., Cury, K. M., Abe, T., Murthy, V. N.,
        Mathis, M. W., &amp; Bethge, M. (2018). DeepLabCut: markerless pose
        estimation of user-defined body parts with deep learning (p. 1).
        Nature Publishing Group.
    [2] Nath, T., Mathis, A., Chen, A. C., Patel, A., Bethge, M.,
        &amp; Mathis, M. W. (2019). Using DeepLabCut for 3D markerless
        pose estimation across species and behaviors. Nature protocols,
        14(7), 2152-2176.
    [3] Mathis, A., Yuksekgonol, M., Rogers, B., Bethge, M., Mathis, M. (2019).
        Pretraining boosts out-of-domain-robustness for pose estimation.
        arXiv cs.CV https://arxiv.org/abs/1909.11229


    &#34;&#34;&#34;.format(
    list(MODELS.keys()), [0.35, 0.50, 0.75, 1.0, 1.3, 1.4]
)


class DeepLabCut(BaseModel):
    __doc__ = __docstring__

    def __init__(
        self,
        train_generator,
        subpixel=True,
        weights=&#34;imagenet&#34;,
        backbone=&#34;resnet50&#34;,
        alpha=1.0,
        **kwargs
    ):

        self.subpixel = subpixel
        self.weights = weights
        self.backbone = backbone
        self.alpha = alpha
        super(DeepLabCut, self).__init__(train_generator, subpixel, **kwargs)

    def __init_model__(self):

        batch_shape = (
            None,
            self.train_generator.height,
            self.train_generator.width,
            self.train_generator.n_channels,
        )

        input_layer = Input(batch_shape=batch_shape, dtype=&#34;uint8&#34;)
        to_float = Float()(input_layer)
        if batch_shape[-1] is 1:
            to_float = Concatenate()([to_float] * 3)
        if self.backbone in list(MODELS.keys()):
            normalized = ImageNetPreprocess(self.backbone)(to_float)
        else:
            raise ValueError(
                &#34;backbone model {} is not supported. Must be one of {}&#34;.format(
                    self.backbone, list(MODELS.keys())
                )
            )
        backbone = MODELS[self.backbone]
        if self.backbone in list(MODELS.keys()):
            input_shape = (self.train_generator.height, self.train_generator.width, 3)
        if self.backbone.startswith(&#34;mobile&#34;):
            input_shape = None
            backbone = partial(backbone, alpha=self.alpha)
        pretrained_model = backbone(
            include_top=False, weights=self.weights, input_shape=input_shape
        )
        pretrained_features = pretrained_model(normalized)
        if self.train_generator.downsample_factor is 4:
            x = pretrained_features
            x_out = Conv2D(self.train_generator.n_output_channels, (1, 1))(x)
        elif self.train_generator.downsample_factor is 3:
            x = pretrained_features
            x_out = Conv2DTranspose(
                self.train_generator.n_output_channels,
                (3, 3),
                strides=(2, 2),
                padding=&#34;same&#34;,
            )(x)
        elif self.train_generator.downsample_factor is 2:
            x = pretrained_features
            x = SubPixelUpscaling()(x)
            x_out = Conv2DTranspose(
                self.train_generator.n_output_channels,
                (3, 3),
                strides=(2, 2),
                padding=&#34;same&#34;,
            )(x)
        else:
            raise ValueError(
                &#34;`downsample_factor={}` is not supported for DeepLabCut. Adjust your TrainingGenerator&#34;.format(
                    self.train_generator.downsample_factor
                )
            )

        self.train_model = Model(input_layer, x_out, name=self.__class__.__name__)

    def get_config(self):
        config = {
            &#34;name&#34;: self.__class__.__name__,
            &#34;subpixel&#34;: self.subpixel,
            &#34;weights&#34;: self.weights,
            &#34;backbone&#34;: self.backbone,
            &#34;alpha&#34;: self.alpha if self.backbone is &#34;mobilenetv2&#34; else None,
        }
        base_config = super(DeepLabCut, self).get_config()
        return dict(list(config.items()) + list(base_config.items()))</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="deepposekit.models.DeepLabCut.DeepLabCut"><code class="flex name class">
<span>class <span class="ident">DeepLabCut</span></span>
<span>(</span><span>train_generator, subpixel=True, weights='imagenet', backbone='resnet50', alpha=1.0, **kwargs)</span>
</code></dt>
<dd>
<section class="desc"><p>Define a DeepLabCut model from Mathis et al., 2018 [1][2]
See <code>References</code> for details on the model architecture.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>train_generator</code></strong> :&ensp;<code>class</code> <a title="deepposekit.io.TrainingGenerator" href="../io/TrainingGenerator.html"><code>deepposekit.io.TrainingGenerator</code></a></dt>
<dd>A deepposekit.io.TrainingGenerator class for generating
images and confidence maps.</dd>
<dt><strong><code>subpixel</code></strong> :&ensp;<code>bool</code>, default = <code>True</code></dt>
<dd>Whether to use subpixel maxima for calculating
keypoint coordinates in the prediction model.</dd>
<dt><strong><code>weights</code></strong> :&ensp;<code>"imagnet"</code> or <code>None</code>, default <code>is</code> <code>"imagenet"</code></dt>
<dd>Which weights to use for initialization. "imagenet" uses
weights pretrained on imagenet. None uses randomly initialized
weights.</dd>
<dt><strong><code>backbone</code></strong> :&ensp;<code>string</code>, default <code>is</code> <code>"resnet50"</code></dt>
<dd>pretrained backbone network to use. Must be one of ['resnet50', 'resnet101', 'resnet152', 'mobilenetv2', 'densenet121', 'densenet169', 'densenet201']. See [3].</dd>
<dt><strong><code>alpha</code></strong> :&ensp;<code>float</code>, default <code>is</code> <code>1.0</code></dt>
<dd>Which MobileNetV2 to use. Must be one of:
[0.35, 0.5, 0.75, 1.0, 1.3, 1.4]
Not used if backbone is not "mobilenetv2".</dd>
</dl>
<h2 id="attributes">Attributes</h2>
<dl>
<dt><strong><code>train_model</code></strong> :&ensp;<code>keras.Model</code></dt>
<dd>A model for training the network to produce confidence maps with
one input layer for images</dd>
<dt><strong><code>predict_model</code></strong> :&ensp;<code>keras.Model</code></dt>
<dd>A model for predicting keypoint coordinates using with Maxima2D or
SubpixelMaxima2D layers at the output of the network.</dd>
</dl>
<p>Both of these models share the same computational graph,
so training train_model updates the weights of predict_model</p>
<h2 id="references">References</h2>
<p>[1] Mathis, A., Mamidanna, P., Cury, K. M., Abe, T., Murthy, V. N.,
Mathis, M. W., &amp; Bethge, M. (2018). DeepLabCut: markerless pose
estimation of user-defined body parts with deep learning (p. 1).
Nature Publishing Group.
[2] Nath, T., Mathis, A., Chen, A. C., Patel, A., Bethge, M.,
&amp; Mathis, M. W. (2019). Using DeepLabCut for 3D markerless
pose estimation across species and behaviors. Nature protocols,
14(7), 2152-2176.
[3] Mathis, A., Yuksekgonol, M., Rogers, B., Bethge, M., Mathis, M. (2019).
Pretraining boosts out-of-domain-robustness for pose estimation.
arXiv cs.CV <a href="https://arxiv.org/abs/1909.11229">https://arxiv.org/abs/1909.11229</a></p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class DeepLabCut(BaseModel):
    __doc__ = __docstring__

    def __init__(
        self,
        train_generator,
        subpixel=True,
        weights=&#34;imagenet&#34;,
        backbone=&#34;resnet50&#34;,
        alpha=1.0,
        **kwargs
    ):

        self.subpixel = subpixel
        self.weights = weights
        self.backbone = backbone
        self.alpha = alpha
        super(DeepLabCut, self).__init__(train_generator, subpixel, **kwargs)

    def __init_model__(self):

        batch_shape = (
            None,
            self.train_generator.height,
            self.train_generator.width,
            self.train_generator.n_channels,
        )

        input_layer = Input(batch_shape=batch_shape, dtype=&#34;uint8&#34;)
        to_float = Float()(input_layer)
        if batch_shape[-1] is 1:
            to_float = Concatenate()([to_float] * 3)
        if self.backbone in list(MODELS.keys()):
            normalized = ImageNetPreprocess(self.backbone)(to_float)
        else:
            raise ValueError(
                &#34;backbone model {} is not supported. Must be one of {}&#34;.format(
                    self.backbone, list(MODELS.keys())
                )
            )
        backbone = MODELS[self.backbone]
        if self.backbone in list(MODELS.keys()):
            input_shape = (self.train_generator.height, self.train_generator.width, 3)
        if self.backbone.startswith(&#34;mobile&#34;):
            input_shape = None
            backbone = partial(backbone, alpha=self.alpha)
        pretrained_model = backbone(
            include_top=False, weights=self.weights, input_shape=input_shape
        )
        pretrained_features = pretrained_model(normalized)
        if self.train_generator.downsample_factor is 4:
            x = pretrained_features
            x_out = Conv2D(self.train_generator.n_output_channels, (1, 1))(x)
        elif self.train_generator.downsample_factor is 3:
            x = pretrained_features
            x_out = Conv2DTranspose(
                self.train_generator.n_output_channels,
                (3, 3),
                strides=(2, 2),
                padding=&#34;same&#34;,
            )(x)
        elif self.train_generator.downsample_factor is 2:
            x = pretrained_features
            x = SubPixelUpscaling()(x)
            x_out = Conv2DTranspose(
                self.train_generator.n_output_channels,
                (3, 3),
                strides=(2, 2),
                padding=&#34;same&#34;,
            )(x)
        else:
            raise ValueError(
                &#34;`downsample_factor={}` is not supported for DeepLabCut. Adjust your TrainingGenerator&#34;.format(
                    self.train_generator.downsample_factor
                )
            )

        self.train_model = Model(input_layer, x_out, name=self.__class__.__name__)

    def get_config(self):
        config = {
            &#34;name&#34;: self.__class__.__name__,
            &#34;subpixel&#34;: self.subpixel,
            &#34;weights&#34;: self.weights,
            &#34;backbone&#34;: self.backbone,
            &#34;alpha&#34;: self.alpha if self.backbone is &#34;mobilenetv2&#34; else None,
        }
        base_config = super(DeepLabCut, self).get_config()
        return dict(list(config.items()) + list(base_config.items()))</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="deepposekit.models.engine.BaseModel" href="engine.html#deepposekit.models.engine.BaseModel">BaseModel</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="deepposekit.models.DeepLabCut.DeepLabCut.get_config"><code class="name flex">
<span>def <span class="ident">get_config</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_config(self):
    config = {
        &#34;name&#34;: self.__class__.__name__,
        &#34;subpixel&#34;: self.subpixel,
        &#34;weights&#34;: self.weights,
        &#34;backbone&#34;: self.backbone,
        &#34;alpha&#34;: self.alpha if self.backbone is &#34;mobilenetv2&#34; else None,
    }
    base_config = super(DeepLabCut, self).get_config()
    return dict(list(config.items()) + list(base_config.items()))</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="deepposekit.models.engine.BaseModel" href="engine.html#deepposekit.models.engine.BaseModel">BaseModel</a></b></code>:
<ul class="hlist">
<li><code><a title="deepposekit.models.engine.BaseModel.fit" href="engine.html#deepposekit.models.engine.BaseModel.fit">fit</a></code></li>
</ul>
</li>
</ul>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="deepposekit.models" href="index.html">deepposekit.models</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="deepposekit.models.DeepLabCut.DeepLabCut" href="#deepposekit.models.DeepLabCut.DeepLabCut">DeepLabCut</a></code></h4>
<ul class="">
<li><code><a title="deepposekit.models.DeepLabCut.DeepLabCut.get_config" href="#deepposekit.models.DeepLabCut.DeepLabCut.get_config">get_config</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.7.0</a>.</p>
</footer>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad()</script>
</body>
</html>
<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.7.0" />
<title>deepposekit.models.LEAP API documentation</title>
<meta name="description" content="" />
<link href='https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.0/normalize.min.css' rel='stylesheet'>
<link href='https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/8.0.0/sanitize.min.css' rel='stylesheet'>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" rel="stylesheet">
<style>.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{font-weight:bold}#index h4 + ul{margin-bottom:.6em}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>deepposekit.models.LEAP</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python"># -*- coding: utf-8 -*-
# Copyright 2018-2019 Jacob M. Graving &lt;jgraving@gmail.com&gt;
#
# Licensed under the Apache License, Version 2.0 (the &#34;License&#34;);
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at

#    http://www.apache.org/licenses/LICENSE-2.0

# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an &#34;AS IS&#34; BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from tensorflow.keras import Input, Model
from tensorflow.keras.layers import Conv2D, Conv2DTranspose, BatchNormalization

from deepposekit.models.layers.convolutional import UpSampling2D
from deepposekit.models.layers.util import ImageNormalization
from deepposekit.models.layers.leap import ConvBlock2D, ConvPool2D
from deepposekit.models.engine import BaseModel


class LEAP(BaseModel):
    def __init__(
        self,
        train_generator,
        filters=64,
        upsampling=False,
        activation=&#34;relu&#34;,
        batchnorm=False,
        use_bias=True,
        pooling=&#34;max&#34;,
        interpolation=&#34;bilinear&#34;,
        subpixel=False,
        initializer=&#34;glorot_uniform&#34;,
        **kwargs
    ):
        &#34;&#34;&#34;
        Define a LEAP model from Pereira et al., 2018 [1]
        See `References` for details on the model architecture.

        Parameters
        ----------
        train_generator : class deepposekit.io.TrainingGenerator
            A deepposekit.io.TrainingGenerator class for generating
            images and confidence maps.
        filters : int, default = 64
            The base number of channels to output from each
            convolutional layer. Increases by up to a factor
            of 4 with network depth.
        upsampling_layers: bool, default = False
            Whether to use upsampling or transposed convolutions
            for upsampling layers. Default is False, which uses
            transposed convolutions.
        activation: str or callable, default = &#39;relu&#39;
            The activation function to use for each convolutional layer.
        batchnorm : bool, default = False
            Whether to use batch normalization in each convolutional block.
            If activation is &#39;selu&#39; then batchnorm is automatically set to
            False, as the network is already self-normalizing.
        pooling: str, default = &#39;max&#39;
            The type of pooling to use during downsampling.
            Must be either &#39;max&#39; or &#39;average&#39;.
        interpolation: str, default = &#39;nearest&#39;
            The type of interpolation to use when upsampling.
            Must be &#39;nearest&#39;, &#39;bilinear&#39;, or &#39;bicubic&#39;.
            The default is &#39;nearest&#39;, which is the most efficient.
        subpixel: bool, default = True
            Whether to use subpixel maxima for calculating
            keypoint coordinates in the prediction model.
        initializer: str or callable, default=&#39;glorot_uniform&#39;
            The initializer for the convolutional kernels.
            Default is &#39;glorot_uniform&#39; which is the keras default.
            If activation is &#39;selu&#39;, the initializer is automatically
            changed to &#39;lecun_normal&#39;, which is the recommended initializer
            for that activation function [4].

        Attributes
        -------
        train_model: keras.Model
            A model for training the network to produce confidence maps with
            one input layer for images
        predict_model: keras.Model
            A model for predicting keypoint coordinates using with Maxima2D or
            SubpixelMaxima2D layers at the output of the network.

        Both of these models share the same computational graph,
        so training train_model updates the weights of predict_model

        References
        ----------
        1.  Pereira, T. D., Aldarondo, D. E., Willmore, L., Kislin,
            M., Wang, S. S. H., Murthy, M., &amp; Shaevitz, J. W. (2018).
            Fast animal pose estimation using deep neural networks.
            bioRxiv, 331181.

        &#34;&#34;&#34;
        self.filters = filters
        self.upsampling = upsampling
        self.activation = activation
        if activation is &#34;selu&#34;:
            batchnorm = False
            use_bias = False
        if batchnorm:
            use_bias = False
        self.batchnorm = batchnorm
        self.use_bias = use_bias
        self.pooling = pooling
        self.interpolation = interpolation
        self.subpixel = subpixel
        self.initializer = initializer
        super(LEAP, self).__init__(train_generator, subpixel, **kwargs)

    def __init_model__(self):
        if self.train_generator.downsample_factor is not 0:
            raise ValueError(&#34;LEAP is only compatible with a downsample_factor of 0&#34;)
        normalized = ImageNormalization()(self.inputs)

        x1 = ConvPool2D(
            n_layers=3,
            filters=self.filters,
            kernel_size=3,
            pooling=self.pooling,
            activation=self.activation,
            initializer=self.initializer,
            batchnorm=self.batchnorm,
            use_bias=self.use_bias,
        )(normalized)
        x2 = ConvPool2D(
            n_layers=3,
            filters=self.filters * 2,
            kernel_size=3,
            pooling=self.pooling,
            activation=self.activation,
            initializer=self.initializer,
            batchnorm=self.batchnorm,
            use_bias=self.use_bias,
        )(x1)
        x3 = ConvBlock2D(
            n_layers=3,
            filters=self.filters * 4,
            kernel_size=3,
            activation=self.activation,
            initializer=self.initializer,
            batchnorm=self.batchnorm,
            use_bias=self.use_bias,
        )(x2)

        if self.upsampling:
            x4 = UpSampling2D(interpolation=self.interpolation)(x3)
        else:
            x4 = Conv2DTranspose(
                self.filters * 2,
                kernel_size=3,
                strides=2,
                padding=&#34;same&#34;,
                activation=self.activation,
                kernel_initializer=&#34;glorot_normal&#34;,
                use_bias=self.use_bias,
            )(x3)
        if self.batchnorm:
            x4 = BatchNormalization()(x4)

        x4 = ConvBlock2D(
            n_layers=2,
            filters=self.filters * 2,
            kernel_size=3,
            activation=self.activation,
            initializer=self.initializer,
            batchnorm=self.batchnorm,
            use_bias=self.use_bias,
        )(x4)

        if self.upsampling:
            x_out = UpSampling2D(interpolation=self.interpolation)(x4)
            x_out = Conv2D(
                self.train_generator.n_output_channels,
                kernel_size=3,
                padding=&#34;same&#34;,
                activation=&#34;linear&#34;,
            )(x_out)
        else:
            x_out = Conv2DTranspose(
                self.train_generator.n_output_channels,
                kernel_size=3,
                strides=2,
                padding=&#34;same&#34;,
                activation=&#34;linear&#34;,
                kernel_initializer=&#34;glorot_normal&#34;,
            )(x4)

        self.train_model = Model(self.inputs, x_out, name=self.__class__.__name__)

    def get_config(self):
        config = {
            &#34;name&#34;: self.__class__.__name__,
            &#34;filters&#34;: self.filters,
            &#34;batchnorm&#34;: self.batchnorm,
            &#34;upsampling&#34;: self.upsampling,
            &#34;use_bias&#34;: self.use_bias,
            &#34;activation&#34;: self.activation,
            &#34;pooling&#34;: self.pooling,
            &#34;interpolation&#34;: self.interpolation,
            &#34;subpixel&#34;: self.subpixel,
            &#34;initializer&#34;: self.initializer,
        }
        base_config = super(LEAP, self).get_config()
        return dict(list(config.items()) + list(base_config.items()))</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="deepposekit.models.LEAP.LEAP"><code class="flex name class">
<span>class <span class="ident">LEAP</span></span>
<span>(</span><span>train_generator, filters=64, upsampling=False, activation='relu', batchnorm=False, use_bias=True, pooling='max', interpolation='bilinear', subpixel=False, initializer='glorot_uniform', **kwargs)</span>
</code></dt>
<dd>
<section class="desc"><p>Define a LEAP model from Pereira et al., 2018 [1]
See <code>References</code> for details on the model architecture.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>train_generator</code></strong> :&ensp;<code>class</code> <a title="deepposekit.io.TrainingGenerator" href="../io/TrainingGenerator.html"><code>deepposekit.io.TrainingGenerator</code></a></dt>
<dd>A deepposekit.io.TrainingGenerator class for generating
images and confidence maps.</dd>
<dt><strong><code>filters</code></strong> :&ensp;<code>int</code>, default = <code>64</code></dt>
<dd>The base number of channels to output from each
convolutional layer. Increases by up to a factor
of 4 with network depth.</dd>
<dt><strong><code>upsampling_layers</code></strong> :&ensp;<code>bool</code>, default = <code>False</code></dt>
<dd>Whether to use upsampling or transposed convolutions
for upsampling layers. Default is False, which uses
transposed convolutions.</dd>
<dt><strong><code>activation</code></strong> :&ensp;<code>str</code> or <code>callable</code>, default = <code>'relu'</code></dt>
<dd>The activation function to use for each convolutional layer.</dd>
<dt><strong><code>batchnorm</code></strong> :&ensp;<code>bool</code>, default = <code>False</code></dt>
<dd>Whether to use batch normalization in each convolutional block.
If activation is 'selu' then batchnorm is automatically set to
False, as the network is already self-normalizing.</dd>
<dt><strong><code>pooling</code></strong> :&ensp;<code>str</code>, default = <code>'max'</code></dt>
<dd>The type of pooling to use during downsampling.
Must be either 'max' or 'average'.</dd>
<dt><strong><code>interpolation</code></strong> :&ensp;<code>str</code>, default = <code>'nearest'</code></dt>
<dd>The type of interpolation to use when upsampling.
Must be 'nearest', 'bilinear', or 'bicubic'.
The default is 'nearest', which is the most efficient.</dd>
<dt><strong><code>subpixel</code></strong> :&ensp;<code>bool</code>, default = <code>True</code></dt>
<dd>Whether to use subpixel maxima for calculating
keypoint coordinates in the prediction model.</dd>
<dt><strong><code>initializer</code></strong> :&ensp;<code>str</code> or <code>callable</code>, default=<code>'glorot_uniform'</code></dt>
<dd>The initializer for the convolutional kernels.
Default is 'glorot_uniform' which is the keras default.
If activation is 'selu', the initializer is automatically
changed to 'lecun_normal', which is the recommended initializer
for that activation function [4].</dd>
</dl>
<h2 id="attributes">Attributes</h2>
<dl>
<dt><strong><code>train_model</code></strong> :&ensp;<code>keras.Model</code></dt>
<dd>A model for training the network to produce confidence maps with
one input layer for images</dd>
<dt><strong><code>predict_model</code></strong> :&ensp;<code>keras.Model</code></dt>
<dd>A model for predicting keypoint coordinates using with Maxima2D or
SubpixelMaxima2D layers at the output of the network.</dd>
</dl>
<p>Both of these models share the same computational graph,
so training train_model updates the weights of predict_model</p>
<h2 id="references">References</h2>
<ol>
<li>Pereira, T. D., Aldarondo, D. E., Willmore, L., Kislin,
M., Wang, S. S. H., Murthy, M., &amp; Shaevitz, J. W. (2018).
Fast animal pose estimation using deep neural networks.
bioRxiv, 331181.</li>
</ol></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class LEAP(BaseModel):
    def __init__(
        self,
        train_generator,
        filters=64,
        upsampling=False,
        activation=&#34;relu&#34;,
        batchnorm=False,
        use_bias=True,
        pooling=&#34;max&#34;,
        interpolation=&#34;bilinear&#34;,
        subpixel=False,
        initializer=&#34;glorot_uniform&#34;,
        **kwargs
    ):
        &#34;&#34;&#34;
        Define a LEAP model from Pereira et al., 2018 [1]
        See `References` for details on the model architecture.

        Parameters
        ----------
        train_generator : class deepposekit.io.TrainingGenerator
            A deepposekit.io.TrainingGenerator class for generating
            images and confidence maps.
        filters : int, default = 64
            The base number of channels to output from each
            convolutional layer. Increases by up to a factor
            of 4 with network depth.
        upsampling_layers: bool, default = False
            Whether to use upsampling or transposed convolutions
            for upsampling layers. Default is False, which uses
            transposed convolutions.
        activation: str or callable, default = &#39;relu&#39;
            The activation function to use for each convolutional layer.
        batchnorm : bool, default = False
            Whether to use batch normalization in each convolutional block.
            If activation is &#39;selu&#39; then batchnorm is automatically set to
            False, as the network is already self-normalizing.
        pooling: str, default = &#39;max&#39;
            The type of pooling to use during downsampling.
            Must be either &#39;max&#39; or &#39;average&#39;.
        interpolation: str, default = &#39;nearest&#39;
            The type of interpolation to use when upsampling.
            Must be &#39;nearest&#39;, &#39;bilinear&#39;, or &#39;bicubic&#39;.
            The default is &#39;nearest&#39;, which is the most efficient.
        subpixel: bool, default = True
            Whether to use subpixel maxima for calculating
            keypoint coordinates in the prediction model.
        initializer: str or callable, default=&#39;glorot_uniform&#39;
            The initializer for the convolutional kernels.
            Default is &#39;glorot_uniform&#39; which is the keras default.
            If activation is &#39;selu&#39;, the initializer is automatically
            changed to &#39;lecun_normal&#39;, which is the recommended initializer
            for that activation function [4].

        Attributes
        -------
        train_model: keras.Model
            A model for training the network to produce confidence maps with
            one input layer for images
        predict_model: keras.Model
            A model for predicting keypoint coordinates using with Maxima2D or
            SubpixelMaxima2D layers at the output of the network.

        Both of these models share the same computational graph,
        so training train_model updates the weights of predict_model

        References
        ----------
        1.  Pereira, T. D., Aldarondo, D. E., Willmore, L., Kislin,
            M., Wang, S. S. H., Murthy, M., &amp; Shaevitz, J. W. (2018).
            Fast animal pose estimation using deep neural networks.
            bioRxiv, 331181.

        &#34;&#34;&#34;
        self.filters = filters
        self.upsampling = upsampling
        self.activation = activation
        if activation is &#34;selu&#34;:
            batchnorm = False
            use_bias = False
        if batchnorm:
            use_bias = False
        self.batchnorm = batchnorm
        self.use_bias = use_bias
        self.pooling = pooling
        self.interpolation = interpolation
        self.subpixel = subpixel
        self.initializer = initializer
        super(LEAP, self).__init__(train_generator, subpixel, **kwargs)

    def __init_model__(self):
        if self.train_generator.downsample_factor is not 0:
            raise ValueError(&#34;LEAP is only compatible with a downsample_factor of 0&#34;)
        normalized = ImageNormalization()(self.inputs)

        x1 = ConvPool2D(
            n_layers=3,
            filters=self.filters,
            kernel_size=3,
            pooling=self.pooling,
            activation=self.activation,
            initializer=self.initializer,
            batchnorm=self.batchnorm,
            use_bias=self.use_bias,
        )(normalized)
        x2 = ConvPool2D(
            n_layers=3,
            filters=self.filters * 2,
            kernel_size=3,
            pooling=self.pooling,
            activation=self.activation,
            initializer=self.initializer,
            batchnorm=self.batchnorm,
            use_bias=self.use_bias,
        )(x1)
        x3 = ConvBlock2D(
            n_layers=3,
            filters=self.filters * 4,
            kernel_size=3,
            activation=self.activation,
            initializer=self.initializer,
            batchnorm=self.batchnorm,
            use_bias=self.use_bias,
        )(x2)

        if self.upsampling:
            x4 = UpSampling2D(interpolation=self.interpolation)(x3)
        else:
            x4 = Conv2DTranspose(
                self.filters * 2,
                kernel_size=3,
                strides=2,
                padding=&#34;same&#34;,
                activation=self.activation,
                kernel_initializer=&#34;glorot_normal&#34;,
                use_bias=self.use_bias,
            )(x3)
        if self.batchnorm:
            x4 = BatchNormalization()(x4)

        x4 = ConvBlock2D(
            n_layers=2,
            filters=self.filters * 2,
            kernel_size=3,
            activation=self.activation,
            initializer=self.initializer,
            batchnorm=self.batchnorm,
            use_bias=self.use_bias,
        )(x4)

        if self.upsampling:
            x_out = UpSampling2D(interpolation=self.interpolation)(x4)
            x_out = Conv2D(
                self.train_generator.n_output_channels,
                kernel_size=3,
                padding=&#34;same&#34;,
                activation=&#34;linear&#34;,
            )(x_out)
        else:
            x_out = Conv2DTranspose(
                self.train_generator.n_output_channels,
                kernel_size=3,
                strides=2,
                padding=&#34;same&#34;,
                activation=&#34;linear&#34;,
                kernel_initializer=&#34;glorot_normal&#34;,
            )(x4)

        self.train_model = Model(self.inputs, x_out, name=self.__class__.__name__)

    def get_config(self):
        config = {
            &#34;name&#34;: self.__class__.__name__,
            &#34;filters&#34;: self.filters,
            &#34;batchnorm&#34;: self.batchnorm,
            &#34;upsampling&#34;: self.upsampling,
            &#34;use_bias&#34;: self.use_bias,
            &#34;activation&#34;: self.activation,
            &#34;pooling&#34;: self.pooling,
            &#34;interpolation&#34;: self.interpolation,
            &#34;subpixel&#34;: self.subpixel,
            &#34;initializer&#34;: self.initializer,
        }
        base_config = super(LEAP, self).get_config()
        return dict(list(config.items()) + list(base_config.items()))</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="deepposekit.models.engine.BaseModel" href="engine.html#deepposekit.models.engine.BaseModel">BaseModel</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="deepposekit.models.LEAP.LEAP.get_config"><code class="name flex">
<span>def <span class="ident">get_config</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_config(self):
    config = {
        &#34;name&#34;: self.__class__.__name__,
        &#34;filters&#34;: self.filters,
        &#34;batchnorm&#34;: self.batchnorm,
        &#34;upsampling&#34;: self.upsampling,
        &#34;use_bias&#34;: self.use_bias,
        &#34;activation&#34;: self.activation,
        &#34;pooling&#34;: self.pooling,
        &#34;interpolation&#34;: self.interpolation,
        &#34;subpixel&#34;: self.subpixel,
        &#34;initializer&#34;: self.initializer,
    }
    base_config = super(LEAP, self).get_config()
    return dict(list(config.items()) + list(base_config.items()))</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="deepposekit.models.engine.BaseModel" href="engine.html#deepposekit.models.engine.BaseModel">BaseModel</a></b></code>:
<ul class="hlist">
<li><code><a title="deepposekit.models.engine.BaseModel.fit" href="engine.html#deepposekit.models.engine.BaseModel.fit">fit</a></code></li>
</ul>
</li>
</ul>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="deepposekit.models" href="index.html">deepposekit.models</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="deepposekit.models.LEAP.LEAP" href="#deepposekit.models.LEAP.LEAP">LEAP</a></code></h4>
<ul class="">
<li><code><a title="deepposekit.models.LEAP.LEAP.get_config" href="#deepposekit.models.LEAP.LEAP.get_config">get_config</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.7.0</a>.</p>
</footer>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad()</script>
</body>
</html>
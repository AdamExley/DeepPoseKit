<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.7.0" />
<title>deepposekit.callbacks API documentation</title>
<meta name="description" content="" />
<link href='https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.0/normalize.min.css' rel='stylesheet'>
<link href='https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/8.0.0/sanitize.min.css' rel='stylesheet'>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" rel="stylesheet">
<style>.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{font-weight:bold}#index h4 + ul{margin-bottom:.6em}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>deepposekit.callbacks</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python"># -*- coding: utf-8 -*-
# Copyright 2018-2019 Jacob M. Graving &lt;jgraving@gmail.com&gt;
#
# Licensed under the Apache License, Version 2.0 (the &#34;License&#34;);
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at

#    http://www.apache.org/licenses/LICENSE-2.0

# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an &#34;AS IS&#34; BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import numpy as np
import h5py
import json

from tensorflow.keras.callbacks import Callback
import tensorflow.keras.callbacks as callbacks
from tensorflow.python.platform import tf_logging as logging

from deepposekit.models.engine import BaseModel
from deepposekit.utils.io import get_json_type


class Logger(Callback):
    &#34;&#34;&#34; Saves the loss and validation metrics during training

    Parameters
    ----------
    filepath: str
        Name of the .h5 file.
    validation_batch_size: int
        Batch size for running evaluation
    &#34;&#34;&#34;

    def __init__(
        self,
        filepath=None,
        validation_batch_size=1,
        confidence_threshold=None,
        verbose=1,
        batch_size=None,
        **kwargs
    ):

        super(Logger, self).__init__(**kwargs)
        if isinstance(filepath, str):
            if filepath.endswith(&#34;.h5&#34;):
                self.filepath = filepath
            else:
                raise ValueError(&#34;filepath must be .h5 file&#34;)
        elif filepath is not None:
            raise TypeError(&#34;filepath must be type `str` or None&#34;)
        else:
            self.filepath = filepath

        self.verbose = verbose
        self.batch_size = validation_batch_size if batch_size is None else batch_size
        self.confidence_threshold = confidence_threshold

        if self.filepath is not None:
            with h5py.File(self.filepath, &#34;w&#34;) as h5file:
                if &#34;logs&#34; not in h5file:
                    group = h5file.create_group(&#34;logs&#34;)
                    group.create_dataset(
                        &#34;loss&#34;, shape=(0,), dtype=np.float64, maxshape=(None,)
                    )
                    group.create_dataset(
                        &#34;val_loss&#34;, shape=(0,), dtype=np.float64, maxshape=(None,)
                    )
                    group.create_dataset(
                        &#34;y_pred&#34;,
                        shape=(0, 0, 0, 0),
                        dtype=np.float64,
                        maxshape=(None, None, None, None),
                    )
                    group.create_dataset(
                        &#34;y_error&#34;,
                        shape=(0, 0, 0, 0),
                        dtype=np.float64,
                        maxshape=(None, None, None, None),
                    )
                    group.create_dataset(
                        &#34;euclidean&#34;,
                        shape=(0, 0, 0),
                        dtype=np.float64,
                        maxshape=(None, None, None),
                    )
                    group.create_dataset(
                        &#34;confidence&#34;,
                        shape=(0, 0, 0),
                        dtype=np.float64,
                        maxshape=(None, None, None),
                    )

    def on_train_begin(self, logs):
        return

    def on_train_end(self, logs):
        return

    def on_epoch_begin(self, epoch, logs):
        return

    def on_epoch_end(self, epoch, logs):
        logs = logs or {}
        evaluation_dict = self.evaluation_model.evaluate(self.batch_size)
        y_pred = evaluation_dict[&#34;y_pred&#34;]
        y_error = evaluation_dict[&#34;y_error&#34;]
        euclidean = evaluation_dict[&#34;euclidean&#34;]
        confidence = evaluation_dict[&#34;confidence&#34;]
        if self.filepath is not None:
            with h5py.File(self.filepath) as h5file:
                values = {
                    &#34;val_loss&#34;: np.array([logs.get(&#34;val_loss&#34;)]).reshape(1),
                    &#34;loss&#34;: np.array([logs.get(&#34;loss&#34;)]).reshape(1),
                    &#34;y_pred&#34;: y_pred[None, ...],
                    &#34;y_error&#34;: y_error[None, ...],
                    &#34;euclidean&#34;: euclidean[None, ...],
                    &#34;confidence&#34;: confidence[None, ...],
                }
                for key, value in values.items():
                    data = h5file[&#34;logs&#34;][key]
                    value = np.array(value)
                    data.resize(tuple(value.shape))
                    if data.shape[0] == 0:
                        data[:] = value
                    else:
                        data.resize(data.shape[0] + 1, axis=0)
                        data[-1] = value

        euclidean = euclidean.flatten()
        confidence = confidence.flatten()

        if self.confidence_threshold:
            mask = confidence &gt;= confidence_threshold
            euclidean = euclidean[mask]
            confidence = confidence[mask]

        keypoint_percentile = np.percentile(
            [euclidean, confidence], [0, 5, 25, 50, 75, 95, 100], axis=1
        ).T
        euclidean_perc, confidence_perc = keypoint_percentile

        euclidean_mean, confidence_mean = np.mean([euclidean, confidence], axis=1)

        logs[&#34;euclidean&#34;] = euclidean_mean
        logs[&#34;confidence&#34;] = confidence_mean

        if self.verbose:
            print(
                &#34;evaluation_metrics: \n&#34;
                &#34;euclidean - mean: {:5.2f} (0%: {:5.2f}, 5%: {:5.2f}, 25%: {:5.2f}, 50%: {:5.2f}, 75%: {:5.2f}, 95%: {:5.2f}, 100%: {:5.2f}) \n&#34;
                &#34;confidence - mean: {:5.2f} (0%: {:5.2f}, 5%: {:5.2f}, 25%: {:5.2f}, 50%: {:5.2f}, 75%: {:5.2f}, 95%: {:5.2f}, 100%: {:5.2f}) \n&#34;.format(
                    euclidean_mean,
                    euclidean_perc[0],
                    euclidean_perc[1],
                    euclidean_perc[2],
                    euclidean_perc[3],
                    euclidean_perc[4],
                    euclidean_perc[5],
                    euclidean_perc[6],
                    confidence_mean,
                    confidence_perc[0],
                    confidence_perc[1],
                    confidence_perc[2],
                    confidence_perc[3],
                    confidence_perc[4],
                    confidence_perc[5],
                    confidence_perc[6],
                )
            )

    def on_batch_begin(self, batch, logs):
        return

    def on_batch_end(self, batch, logs):
        return

    def pass_model(self, model):
        if isinstance(model, BaseModel):
            self.evaluation_model = model
        else:
            raise TypeError(&#34;model must be a deepposekit BaseModel class&#34;)
        if self.filepath is not None:
            with h5py.File(self.filepath, &#34;r+&#34;) as h5file:
                # create attributes for the group based on the two dicts
                for key, value in model.get_config().items():
                    if isinstance(value, str):
                        value = value.encode(&#34;utf8&#34;)  # str not supported in h5py
                    if value is None:
                        value = &#34;None&#34;.encode(&#34;utf8&#34;)
                    if key not in h5file.attrs:
                        h5file.attrs.create(key, value)

                if &#34;logger_config&#34; not in h5file.attrs:
                    h5file.attrs[&#34;logger_config&#34;] = json.dumps(
                        model.get_config(), default=get_json_type
                    ).encode(&#34;utf8&#34;)


class ModelCheckpoint(callbacks.ModelCheckpoint):
    &#34;&#34;&#34;Save the model after every epoch.

    `filepath` can contain named formatting options,
    which will be filled the value of `epoch` and
    keys in `logs` (passed in `on_epoch_end`).

    For example: if `filepath` is `weights.{epoch:02d}-{val_loss:.2f}.hdf5`,
    then the model checkpoints will be saved with the epoch number and
    the validation loss in the filename.

    # Arguments
        filepath: string, path to save the model file.
        monitor: quantity to monitor.
        verbose: verbosity mode, 0 or 1.
        save_best_only: if `save_best_only=True`,
            the latest best model according to
            the quantity monitored will not be overwritten.
        mode: one of {auto, min, max}.
            If `save_best_only=True`, the decision
            to overwrite the current save file is made
            based on either the maximization or the
            minimization of the monitored quantity. For `val_acc`,
            this should be `max`, for `val_loss` this should
            be `min`, etc. In `auto` mode, the direction is
            automatically inferred from the name of the monitored quantity.
        save_freq: `&#39;epoch&#39;` or integer. When using `&#39;epoch&#39;`, the callback saves
            the model after each epoch. When using integer, the callback saves the
            model at end of a batch at which this many samples have been seen since
            last saving. Note that if the saving isn&#39;t aligned to epochs, the
            monitored metric may potentially be less reliable (it could reflect as
            little as 1 batch, since the metrics get reset every epoch). Defaults to
            `&#39;epoch&#39;`
    &#34;&#34;&#34;

    def __init__(
        self,
        filepath,
        monitor=&#34;val_loss&#34;,
        verbose=0,
        save_best_only=True,
        mode=&#34;auto&#34;,
        save_freq=&#34;epoch&#34;,
        **kwargs
    ):
        super(ModelCheckpoint, self).__init__(
            filepath=filepath,
            monitor=monitor,
            verbose=verbose,
            save_best_only=save_best_only,
            mode=mode,
            save_freq=save_freq,
            **kwargs
        )

    def pass_model(self, model):
        if isinstance(model, BaseModel):
            self.model = model
        else:
            raise TypeError(&#34;model must be a deepposekit BaseModel class&#34;)

    def set_model(self, model):
        pass</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="deepposekit.callbacks.Logger"><code class="flex name class">
<span>class <span class="ident">Logger</span></span>
<span>(</span><span>filepath=None, validation_batch_size=1, confidence_threshold=None, verbose=1, batch_size=None, **kwargs)</span>
</code></dt>
<dd>
<section class="desc"><p>Saves the loss and validation metrics during training</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>filepath</code></strong> :&ensp;<code>str</code></dt>
<dd>Name of the .h5 file.</dd>
<dt><strong><code>validation_batch_size</code></strong> :&ensp;<code>int</code></dt>
<dd>Batch size for running evaluation</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Logger(Callback):
    &#34;&#34;&#34; Saves the loss and validation metrics during training

    Parameters
    ----------
    filepath: str
        Name of the .h5 file.
    validation_batch_size: int
        Batch size for running evaluation
    &#34;&#34;&#34;

    def __init__(
        self,
        filepath=None,
        validation_batch_size=1,
        confidence_threshold=None,
        verbose=1,
        batch_size=None,
        **kwargs
    ):

        super(Logger, self).__init__(**kwargs)
        if isinstance(filepath, str):
            if filepath.endswith(&#34;.h5&#34;):
                self.filepath = filepath
            else:
                raise ValueError(&#34;filepath must be .h5 file&#34;)
        elif filepath is not None:
            raise TypeError(&#34;filepath must be type `str` or None&#34;)
        else:
            self.filepath = filepath

        self.verbose = verbose
        self.batch_size = validation_batch_size if batch_size is None else batch_size
        self.confidence_threshold = confidence_threshold

        if self.filepath is not None:
            with h5py.File(self.filepath, &#34;w&#34;) as h5file:
                if &#34;logs&#34; not in h5file:
                    group = h5file.create_group(&#34;logs&#34;)
                    group.create_dataset(
                        &#34;loss&#34;, shape=(0,), dtype=np.float64, maxshape=(None,)
                    )
                    group.create_dataset(
                        &#34;val_loss&#34;, shape=(0,), dtype=np.float64, maxshape=(None,)
                    )
                    group.create_dataset(
                        &#34;y_pred&#34;,
                        shape=(0, 0, 0, 0),
                        dtype=np.float64,
                        maxshape=(None, None, None, None),
                    )
                    group.create_dataset(
                        &#34;y_error&#34;,
                        shape=(0, 0, 0, 0),
                        dtype=np.float64,
                        maxshape=(None, None, None, None),
                    )
                    group.create_dataset(
                        &#34;euclidean&#34;,
                        shape=(0, 0, 0),
                        dtype=np.float64,
                        maxshape=(None, None, None),
                    )
                    group.create_dataset(
                        &#34;confidence&#34;,
                        shape=(0, 0, 0),
                        dtype=np.float64,
                        maxshape=(None, None, None),
                    )

    def on_train_begin(self, logs):
        return

    def on_train_end(self, logs):
        return

    def on_epoch_begin(self, epoch, logs):
        return

    def on_epoch_end(self, epoch, logs):
        logs = logs or {}
        evaluation_dict = self.evaluation_model.evaluate(self.batch_size)
        y_pred = evaluation_dict[&#34;y_pred&#34;]
        y_error = evaluation_dict[&#34;y_error&#34;]
        euclidean = evaluation_dict[&#34;euclidean&#34;]
        confidence = evaluation_dict[&#34;confidence&#34;]
        if self.filepath is not None:
            with h5py.File(self.filepath) as h5file:
                values = {
                    &#34;val_loss&#34;: np.array([logs.get(&#34;val_loss&#34;)]).reshape(1),
                    &#34;loss&#34;: np.array([logs.get(&#34;loss&#34;)]).reshape(1),
                    &#34;y_pred&#34;: y_pred[None, ...],
                    &#34;y_error&#34;: y_error[None, ...],
                    &#34;euclidean&#34;: euclidean[None, ...],
                    &#34;confidence&#34;: confidence[None, ...],
                }
                for key, value in values.items():
                    data = h5file[&#34;logs&#34;][key]
                    value = np.array(value)
                    data.resize(tuple(value.shape))
                    if data.shape[0] == 0:
                        data[:] = value
                    else:
                        data.resize(data.shape[0] + 1, axis=0)
                        data[-1] = value

        euclidean = euclidean.flatten()
        confidence = confidence.flatten()

        if self.confidence_threshold:
            mask = confidence &gt;= confidence_threshold
            euclidean = euclidean[mask]
            confidence = confidence[mask]

        keypoint_percentile = np.percentile(
            [euclidean, confidence], [0, 5, 25, 50, 75, 95, 100], axis=1
        ).T
        euclidean_perc, confidence_perc = keypoint_percentile

        euclidean_mean, confidence_mean = np.mean([euclidean, confidence], axis=1)

        logs[&#34;euclidean&#34;] = euclidean_mean
        logs[&#34;confidence&#34;] = confidence_mean

        if self.verbose:
            print(
                &#34;evaluation_metrics: \n&#34;
                &#34;euclidean - mean: {:5.2f} (0%: {:5.2f}, 5%: {:5.2f}, 25%: {:5.2f}, 50%: {:5.2f}, 75%: {:5.2f}, 95%: {:5.2f}, 100%: {:5.2f}) \n&#34;
                &#34;confidence - mean: {:5.2f} (0%: {:5.2f}, 5%: {:5.2f}, 25%: {:5.2f}, 50%: {:5.2f}, 75%: {:5.2f}, 95%: {:5.2f}, 100%: {:5.2f}) \n&#34;.format(
                    euclidean_mean,
                    euclidean_perc[0],
                    euclidean_perc[1],
                    euclidean_perc[2],
                    euclidean_perc[3],
                    euclidean_perc[4],
                    euclidean_perc[5],
                    euclidean_perc[6],
                    confidence_mean,
                    confidence_perc[0],
                    confidence_perc[1],
                    confidence_perc[2],
                    confidence_perc[3],
                    confidence_perc[4],
                    confidence_perc[5],
                    confidence_perc[6],
                )
            )

    def on_batch_begin(self, batch, logs):
        return

    def on_batch_end(self, batch, logs):
        return

    def pass_model(self, model):
        if isinstance(model, BaseModel):
            self.evaluation_model = model
        else:
            raise TypeError(&#34;model must be a deepposekit BaseModel class&#34;)
        if self.filepath is not None:
            with h5py.File(self.filepath, &#34;r+&#34;) as h5file:
                # create attributes for the group based on the two dicts
                for key, value in model.get_config().items():
                    if isinstance(value, str):
                        value = value.encode(&#34;utf8&#34;)  # str not supported in h5py
                    if value is None:
                        value = &#34;None&#34;.encode(&#34;utf8&#34;)
                    if key not in h5file.attrs:
                        h5file.attrs.create(key, value)

                if &#34;logger_config&#34; not in h5file.attrs:
                    h5file.attrs[&#34;logger_config&#34;] = json.dumps(
                        model.get_config(), default=get_json_type
                    ).encode(&#34;utf8&#34;)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>tensorflow.python.keras.callbacks.Callback</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="deepposekit.callbacks.Logger.on_batch_begin"><code class="name flex">
<span>def <span class="ident">on_batch_begin</span></span>(<span>self, batch, logs)</span>
</code></dt>
<dd>
<section class="desc"><p>A backwards compatibility alias for <code>on_train_batch_begin</code>.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def on_batch_begin(self, batch, logs):
    return</code></pre>
</details>
</dd>
<dt id="deepposekit.callbacks.Logger.on_batch_end"><code class="name flex">
<span>def <span class="ident">on_batch_end</span></span>(<span>self, batch, logs)</span>
</code></dt>
<dd>
<section class="desc"><p>A backwards compatibility alias for <code>on_train_batch_end</code>.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def on_batch_end(self, batch, logs):
    return</code></pre>
</details>
</dd>
<dt id="deepposekit.callbacks.Logger.on_epoch_begin"><code class="name flex">
<span>def <span class="ident">on_epoch_begin</span></span>(<span>self, epoch, logs)</span>
</code></dt>
<dd>
<section class="desc"><p>Called at the start of an epoch.</p>
<p>Subclasses should override for any actions to run. This function should only
be called during TRAIN mode.</p>
<h2 id="arguments">Arguments</h2>
<dl>
<dt><strong><code>epoch</code></strong></dt>
<dd>integer, index of epoch.</dd>
<dt><strong><code>logs</code></strong></dt>
<dd>dict. Currently no data is passed to this argument for this method
but that may change in the future.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def on_epoch_begin(self, epoch, logs):
    return</code></pre>
</details>
</dd>
<dt id="deepposekit.callbacks.Logger.on_epoch_end"><code class="name flex">
<span>def <span class="ident">on_epoch_end</span></span>(<span>self, epoch, logs)</span>
</code></dt>
<dd>
<section class="desc"><p>Called at the end of an epoch.</p>
<p>Subclasses should override for any actions to run. This function should only
be called during TRAIN mode.</p>
<h2 id="arguments">Arguments</h2>
<dl>
<dt><strong><code>epoch</code></strong></dt>
<dd>integer, index of epoch.</dd>
<dt><strong><code>logs</code></strong></dt>
<dd>dict, metric results for this training epoch, and for the
validation epoch if validation is performed. Validation result keys
are prefixed with <code>val_</code>.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def on_epoch_end(self, epoch, logs):
    logs = logs or {}
    evaluation_dict = self.evaluation_model.evaluate(self.batch_size)
    y_pred = evaluation_dict[&#34;y_pred&#34;]
    y_error = evaluation_dict[&#34;y_error&#34;]
    euclidean = evaluation_dict[&#34;euclidean&#34;]
    confidence = evaluation_dict[&#34;confidence&#34;]
    if self.filepath is not None:
        with h5py.File(self.filepath) as h5file:
            values = {
                &#34;val_loss&#34;: np.array([logs.get(&#34;val_loss&#34;)]).reshape(1),
                &#34;loss&#34;: np.array([logs.get(&#34;loss&#34;)]).reshape(1),
                &#34;y_pred&#34;: y_pred[None, ...],
                &#34;y_error&#34;: y_error[None, ...],
                &#34;euclidean&#34;: euclidean[None, ...],
                &#34;confidence&#34;: confidence[None, ...],
            }
            for key, value in values.items():
                data = h5file[&#34;logs&#34;][key]
                value = np.array(value)
                data.resize(tuple(value.shape))
                if data.shape[0] == 0:
                    data[:] = value
                else:
                    data.resize(data.shape[0] + 1, axis=0)
                    data[-1] = value

    euclidean = euclidean.flatten()
    confidence = confidence.flatten()

    if self.confidence_threshold:
        mask = confidence &gt;= confidence_threshold
        euclidean = euclidean[mask]
        confidence = confidence[mask]

    keypoint_percentile = np.percentile(
        [euclidean, confidence], [0, 5, 25, 50, 75, 95, 100], axis=1
    ).T
    euclidean_perc, confidence_perc = keypoint_percentile

    euclidean_mean, confidence_mean = np.mean([euclidean, confidence], axis=1)

    logs[&#34;euclidean&#34;] = euclidean_mean
    logs[&#34;confidence&#34;] = confidence_mean

    if self.verbose:
        print(
            &#34;evaluation_metrics: \n&#34;
            &#34;euclidean - mean: {:5.2f} (0%: {:5.2f}, 5%: {:5.2f}, 25%: {:5.2f}, 50%: {:5.2f}, 75%: {:5.2f}, 95%: {:5.2f}, 100%: {:5.2f}) \n&#34;
            &#34;confidence - mean: {:5.2f} (0%: {:5.2f}, 5%: {:5.2f}, 25%: {:5.2f}, 50%: {:5.2f}, 75%: {:5.2f}, 95%: {:5.2f}, 100%: {:5.2f}) \n&#34;.format(
                euclidean_mean,
                euclidean_perc[0],
                euclidean_perc[1],
                euclidean_perc[2],
                euclidean_perc[3],
                euclidean_perc[4],
                euclidean_perc[5],
                euclidean_perc[6],
                confidence_mean,
                confidence_perc[0],
                confidence_perc[1],
                confidence_perc[2],
                confidence_perc[3],
                confidence_perc[4],
                confidence_perc[5],
                confidence_perc[6],
            )
        )</code></pre>
</details>
</dd>
<dt id="deepposekit.callbacks.Logger.on_train_begin"><code class="name flex">
<span>def <span class="ident">on_train_begin</span></span>(<span>self, logs)</span>
</code></dt>
<dd>
<section class="desc"><p>Called at the beginning of training.</p>
<p>Subclasses should override for any actions to run.</p>
<h2 id="arguments">Arguments</h2>
<dl>
<dt><strong><code>logs</code></strong></dt>
<dd>dict. Currently no data is passed to this argument for this method
but that may change in the future.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def on_train_begin(self, logs):
    return</code></pre>
</details>
</dd>
<dt id="deepposekit.callbacks.Logger.on_train_end"><code class="name flex">
<span>def <span class="ident">on_train_end</span></span>(<span>self, logs)</span>
</code></dt>
<dd>
<section class="desc"><p>Called at the end of training.</p>
<p>Subclasses should override for any actions to run.</p>
<h2 id="arguments">Arguments</h2>
<dl>
<dt><strong><code>logs</code></strong></dt>
<dd>dict. Currently no data is passed to this argument for this method
but that may change in the future.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def on_train_end(self, logs):
    return</code></pre>
</details>
</dd>
<dt id="deepposekit.callbacks.Logger.pass_model"><code class="name flex">
<span>def <span class="ident">pass_model</span></span>(<span>self, model)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def pass_model(self, model):
    if isinstance(model, BaseModel):
        self.evaluation_model = model
    else:
        raise TypeError(&#34;model must be a deepposekit BaseModel class&#34;)
    if self.filepath is not None:
        with h5py.File(self.filepath, &#34;r+&#34;) as h5file:
            # create attributes for the group based on the two dicts
            for key, value in model.get_config().items():
                if isinstance(value, str):
                    value = value.encode(&#34;utf8&#34;)  # str not supported in h5py
                if value is None:
                    value = &#34;None&#34;.encode(&#34;utf8&#34;)
                if key not in h5file.attrs:
                    h5file.attrs.create(key, value)

            if &#34;logger_config&#34; not in h5file.attrs:
                h5file.attrs[&#34;logger_config&#34;] = json.dumps(
                    model.get_config(), default=get_json_type
                ).encode(&#34;utf8&#34;)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="deepposekit.callbacks.ModelCheckpoint"><code class="flex name class">
<span>class <span class="ident">ModelCheckpoint</span></span>
<span>(</span><span>filepath, monitor='val_loss', verbose=0, save_best_only=True, mode='auto', save_freq='epoch', **kwargs)</span>
</code></dt>
<dd>
<section class="desc"><p>Save the model after every epoch.</p>
<p><code>filepath</code> can contain named formatting options,
which will be filled the value of <code>epoch</code> and
keys in <code>logs</code> (passed in <code>on_epoch_end</code>).</p>
<p>For example: if <code>filepath</code> is <code>weights.{epoch:02d}-{val_loss:.2f}.hdf5</code>,
then the model checkpoints will be saved with the epoch number and
the validation loss in the filename.</p>
<h1 id="arguments">Arguments</h1>
<pre><code>filepath: string, path to save the model file.
monitor: quantity to monitor.
verbose: verbosity mode, 0 or 1.
save_best_only: if `save_best_only=True`,
    the latest best model according to
    the quantity monitored will not be overwritten.
mode: one of {auto, min, max}.
    If `save_best_only=True`, the decision
    to overwrite the current save file is made
    based on either the maximization or the
    minimization of the monitored quantity. For `val_acc`,
    this should be `max`, for `val_loss` this should
    be `min`, etc. In `auto` mode, the direction is
    automatically inferred from the name of the monitored quantity.
save_freq: `'epoch'` or integer. When using `'epoch'`, the callback saves
    the model after each epoch. When using integer, the callback saves the
    model at end of a batch at which this many samples have been seen since
    last saving. Note that if the saving isn't aligned to epochs, the
    monitored metric may potentially be less reliable (it could reflect as
    little as 1 batch, since the metrics get reset every epoch). Defaults to
    `'epoch'`
</code></pre></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class ModelCheckpoint(callbacks.ModelCheckpoint):
    &#34;&#34;&#34;Save the model after every epoch.

    `filepath` can contain named formatting options,
    which will be filled the value of `epoch` and
    keys in `logs` (passed in `on_epoch_end`).

    For example: if `filepath` is `weights.{epoch:02d}-{val_loss:.2f}.hdf5`,
    then the model checkpoints will be saved with the epoch number and
    the validation loss in the filename.

    # Arguments
        filepath: string, path to save the model file.
        monitor: quantity to monitor.
        verbose: verbosity mode, 0 or 1.
        save_best_only: if `save_best_only=True`,
            the latest best model according to
            the quantity monitored will not be overwritten.
        mode: one of {auto, min, max}.
            If `save_best_only=True`, the decision
            to overwrite the current save file is made
            based on either the maximization or the
            minimization of the monitored quantity. For `val_acc`,
            this should be `max`, for `val_loss` this should
            be `min`, etc. In `auto` mode, the direction is
            automatically inferred from the name of the monitored quantity.
        save_freq: `&#39;epoch&#39;` or integer. When using `&#39;epoch&#39;`, the callback saves
            the model after each epoch. When using integer, the callback saves the
            model at end of a batch at which this many samples have been seen since
            last saving. Note that if the saving isn&#39;t aligned to epochs, the
            monitored metric may potentially be less reliable (it could reflect as
            little as 1 batch, since the metrics get reset every epoch). Defaults to
            `&#39;epoch&#39;`
    &#34;&#34;&#34;

    def __init__(
        self,
        filepath,
        monitor=&#34;val_loss&#34;,
        verbose=0,
        save_best_only=True,
        mode=&#34;auto&#34;,
        save_freq=&#34;epoch&#34;,
        **kwargs
    ):
        super(ModelCheckpoint, self).__init__(
            filepath=filepath,
            monitor=monitor,
            verbose=verbose,
            save_best_only=save_best_only,
            mode=mode,
            save_freq=save_freq,
            **kwargs
        )

    def pass_model(self, model):
        if isinstance(model, BaseModel):
            self.model = model
        else:
            raise TypeError(&#34;model must be a deepposekit BaseModel class&#34;)

    def set_model(self, model):
        pass</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>tensorflow.python.keras.callbacks.ModelCheckpoint</li>
<li>tensorflow.python.keras.callbacks.Callback</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="deepposekit.callbacks.ModelCheckpoint.pass_model"><code class="name flex">
<span>def <span class="ident">pass_model</span></span>(<span>self, model)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def pass_model(self, model):
    if isinstance(model, BaseModel):
        self.model = model
    else:
        raise TypeError(&#34;model must be a deepposekit BaseModel class&#34;)</code></pre>
</details>
</dd>
<dt id="deepposekit.callbacks.ModelCheckpoint.set_model"><code class="name flex">
<span>def <span class="ident">set_model</span></span>(<span>self, model)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_model(self, model):
    pass</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="deepposekit" href="index.html">deepposekit</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="deepposekit.callbacks.Logger" href="#deepposekit.callbacks.Logger">Logger</a></code></h4>
<ul class="two-column">
<li><code><a title="deepposekit.callbacks.Logger.on_batch_begin" href="#deepposekit.callbacks.Logger.on_batch_begin">on_batch_begin</a></code></li>
<li><code><a title="deepposekit.callbacks.Logger.on_batch_end" href="#deepposekit.callbacks.Logger.on_batch_end">on_batch_end</a></code></li>
<li><code><a title="deepposekit.callbacks.Logger.on_epoch_begin" href="#deepposekit.callbacks.Logger.on_epoch_begin">on_epoch_begin</a></code></li>
<li><code><a title="deepposekit.callbacks.Logger.on_epoch_end" href="#deepposekit.callbacks.Logger.on_epoch_end">on_epoch_end</a></code></li>
<li><code><a title="deepposekit.callbacks.Logger.on_train_begin" href="#deepposekit.callbacks.Logger.on_train_begin">on_train_begin</a></code></li>
<li><code><a title="deepposekit.callbacks.Logger.on_train_end" href="#deepposekit.callbacks.Logger.on_train_end">on_train_end</a></code></li>
<li><code><a title="deepposekit.callbacks.Logger.pass_model" href="#deepposekit.callbacks.Logger.pass_model">pass_model</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="deepposekit.callbacks.ModelCheckpoint" href="#deepposekit.callbacks.ModelCheckpoint">ModelCheckpoint</a></code></h4>
<ul class="">
<li><code><a title="deepposekit.callbacks.ModelCheckpoint.pass_model" href="#deepposekit.callbacks.ModelCheckpoint.pass_model">pass_model</a></code></li>
<li><code><a title="deepposekit.callbacks.ModelCheckpoint.set_model" href="#deepposekit.callbacks.ModelCheckpoint.set_model">set_model</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.7.0</a>.</p>
</footer>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad()</script>
</body>
</html>
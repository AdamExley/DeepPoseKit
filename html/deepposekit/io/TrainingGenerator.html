<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.7.0" />
<title>deepposekit.io.TrainingGenerator API documentation</title>
<meta name="description" content="" />
<link href='https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.0/normalize.min.css' rel='stylesheet'>
<link href='https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/8.0.0/sanitize.min.css' rel='stylesheet'>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" rel="stylesheet">
<style>.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{font-weight:bold}#index h4 + ul{margin-bottom:.6em}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>deepposekit.io.TrainingGenerator</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python"># -*- coding: utf-8 -*-
# Copyright 2018-2019 Jacob M. Graving &lt;jgraving@gmail.com&gt;
#
# Licensed under the Apache License, Version 2.0 (the &#34;License&#34;);
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at

#    http://www.apache.org/licenses/LICENSE-2.0

# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an &#34;AS IS&#34; BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from tensorflow.keras.utils import Sequence
import imgaug.augmenters as iaa

import numpy as np
import copy

from deepposekit.utils.keypoints import draw_confidence_maps, graph_to_edges
from deepposekit.utils.image import check_grayscale
from deepposekit.io.BaseGenerator import BaseGenerator

import warnings

__all__ = [&#34;TrainingGenerator&#34;]


class TrainingGenerator(Sequence):
    &#34;&#34;&#34;
    Generates data for training a model.
    
    Automatically loads annotated data and produces
    augmented images and confidence maps for each keypoint.

    Parameters
    ----------
    generator: deepposekit.io.BaseGenerator
        An instance of BaseGenerator (deepposekit.io.BaseGenerator) object.
        The output of the generator must be `(images, keypoints)`, where images
        are a numpy array of shape (n_images, height, width, channels), and 
        keypoints are a numpy array of shape (n_images, n_keypoints, 2), where
        2 is the row, column coordinates of the keypoints in each image.
    downsample_factor : int, default = 0
        The factor for determining the output shape of the confidence
        maps for estimating keypoints. This is determined as
        shape // 2**downsample_factor. The default is 0, which
        produces confidence maps that are the same shape
        as the input images.
    use_graph : bool, default = True
        Whether to generate confidence maps for the parent graph
        as lines drawn between connected keypoints. This can help reduce
        keypoint estimation error when training the network.
    augmenter : class or list, default = None
        A imgaug.Augmenter, or list of imgaug.Augmenter
        for applying augmentations to images and keypoints.
        Default is None, which applies no augmentations.
    shuffle : bool, default = True
        Whether to randomly shuffle the data.
    sigma : float, default = 3
        The standard deviation of the Gaussian confidence peaks.
        This is scaled to sigma // 2**downsample_factor.
    validation_split : float, default = 0.0
        Float between 0 and 1. Fraction of the training data to be used
        as validation data. The generator will set apart this fraction
        of the training data, will not generate this data unless
        the `validation` flag is set to True when the class is called.
    graph_scale : float, default = 1.0
        Float between 0 and 1. A factor to scale the edge
        confidence map values to y * edge_scale.
        The default is 1.0 which does not scale the confidence
        values. This is useful for preventing the edge channels
        from dominating the error when training a smaller network.
        This arg is not used when `use_graph` is set to False.
    random_seed : int, default = None
        set random seed for selecting validation data
    &#34;&#34;&#34;

    def __init__(
        self,
        generator,
        downsample_factor=2,
        use_graph=True,
        augmenter=None,
        shuffle=True,
        sigma=5,
        validation_split=0.0,
        graph_scale=1.0,
        random_seed=None,
    ):

        self.random_seed = random_seed
        if self.random_seed:
            np.random.seed(self.random_seed)

        self.shuffle = shuffle

        if isinstance(downsample_factor, int):
            if downsample_factor &gt;= 0:
                self.downsample_factor = downsample_factor
            else:
                raise ValueError(&#34;&#34;&#34;downsample factor must be &gt;= 0&#34;&#34;&#34;)
        else:
            raise TypeError(&#34;&#34;&#34;downsample_factor must be type int&#34;&#34;&#34;)
        self.sigma = sigma
        self.output_sigma = sigma / 2.0 ** downsample_factor
        self.batch_size = 32
        self.n_outputs = 1
        self.use_graph = use_graph
        self.graph_scale = graph_scale

        if 0 &lt;= validation_split &lt; 1:
            self.validation_split = validation_split
        else:
            raise ValueError(&#34;`validation_split` must be &gt;=0 and &lt;1&#34;)
        self.validation = False
        self.confidence = True
        self._init_augmenter(augmenter)
        self._init_data(generator)
        self.on_epoch_end()

    def _init_augmenter(self, augmenter):
        if isinstance(augmenter, type(None)):
            self.augmenter = augmenter
        elif isinstance(augmenter, iaa.Augmenter):
            self.augmenter = augmenter
        elif isinstance(augmenter, list):
            if isinstance(augmenter[0], iaa.Augmenter):
                self.augmenter = iaa.Sequential(augmenter)
            else:
                raise TypeError(
                    &#34;&#34;&#34;`augmenter` must be class Augmenter
                            (imgaug.augmenters.Augmenter)
                            or list of Augmenters&#34;&#34;&#34;
                )
        else:
            raise ValueError(
                &#34;&#34;&#34;augmenter must be class
                             Augmenter, list of Augmenters, or None&#34;&#34;&#34;
            )

    def _init_data(self, generator):

        if isinstance(generator, BaseGenerator):
            self.generator = generator
        else:
            raise TypeError(
                &#34;`generator` must be a subclass of `deepposekit.io.BaseGenerator`&#34;
                &#34; such as `deepposekit.io.DataGenerator` or `deepposekit.io.DLCDataGenerator`.&#34;
            )
        self.n_samples = len(self.generator)
        if self.n_samples &lt;= 0:
            raise AttributeError(
                &#34;`n_samples` is 0. `datapath` or `dataset` appears to be empty&#34;
            )

        # Get image attributes and
        # define output shape
        self.height = self.generator.image_shape[0]
        self.width = self.generator.image_shape[1]
        self.n_channels = self.generator.image_shape[2]

        self.output_shape = (
            self.height // 2 ** self.downsample_factor,
            self.width // 2 ** self.downsample_factor,
        )

        # Training/validation split
        # indices for validation set in sample_index
        self.index = np.arange(self.n_samples)
        self.n_validation = int(self.validation_split * self.n_samples)
        if self.n_validation is 0:
            warnings.warn(
                &#34;`n_validation` is 0. Increase `validation_split` to use a validation set.&#34;
            )

        val_index = np.random.choice(self.index, self.n_validation, replace=False)
        self.val_index = self.index[val_index]
        # indices for training set in  sample_index
        train_index = np.invert(np.isin(self.index, self.val_index))
        self.train_index = self.index[train_index]
        self.n_train = len(self.train_index)
        self.n_keypoints = self.generator.keypoints_shape[0]

        # Initialize skeleton attributes
        self.graph = self.generator.graph
        self.swap_index = self.generator.swap_index

        self.on_epoch_end()
        X, y = self.__getitem__(0)
        self.n_output_channels = y.shape[-1]

    def __len__(self):
        &#34;&#34;&#34;The number of batches per epoch&#34;&#34;&#34;
        if self.validation:
            return self.n_validation // self.batch_size
        else:
            return self.n_train // self.batch_size

    def __call__(self, n_outputs=1, batch_size=32, validation=False, confidence=True):
        &#34;&#34;&#34; Sets the number of outputs and the batch size

        Parameters
        ----------
        n_outputs : int, default = 1
            The number of outputs to generate.
            This is needed for applying intermediate supervision
            to a network with multiple output layers.
        batch_size : int, default = 32
            Number of samples in each batch
        validation: bool, default False
            If set to True, will generate the validation set.
            Otherwise, generates the training set.
        confidence: bool, default True
            If set to True, will generate confidence maps.
            Otherwise, generates keypoints.

        &#34;&#34;&#34;
        self.n_outputs = n_outputs
        self.batch_size = batch_size
        if validation:
            if self.n_validation is 0 and self.validation_split is 0:
                warnings.warn(
                    &#34;`validation_split` is 0, so there will be no validation step. &#34;
                    &#34;callbacks that rely on `val_loss` should be switched to `loss` or removed.&#34;
                )
            if self.n_validation is 0 and self.validation_split is not 0:
                warnings.warn(
                    &#34;`validation_split` is too small, so there will be no validation step. &#34;
                    &#34;`validation_split` should be increased or &#34;
                    &#34;callbacks that rely on `val_loss` should be switched to &#39;loss&#39; or removed.&#34;
                )

        self.validation = validation
        self.confidence = confidence
        self.on_epoch_end()
        self_copy = copy.deepcopy(self)
        if self.augmenter:
            self_copy.augmenter.reseed()
        return self_copy

    def __getitem__(self, index):
        &#34;&#34;&#34;Generate one batch of data&#34;&#34;&#34;
        # Generate indexes of the batch
        idx0 = index * self.batch_size
        idx1 = (index + 1) * self.batch_size
        if self.validation:
            indexes = self.val_range[idx0:idx1]
        else:
            indexes = self.train_range[idx0:idx1]

        # Generate data
        X, y = self.generate_batch(indexes)

        return X, y

    def on_epoch_end(self):
        &#34;&#34;&#34;Updates indexes after each epoch&#34;&#34;&#34;
        self.train_range = np.arange(self.n_train)
        self.val_range = np.arange(self.n_validation)
        if self.shuffle:
            np.random.shuffle(self.train_range)
            np.random.shuffle(self.val_range)

    def load_batch(self, indexes):
        if self.validation:
            batch_index = self.val_index[indexes]
        else:
            batch_index = self.train_index[indexes]
        return self.generator[batch_index]

    def augment(self, images, keypoints):
        images_aug = []
        keypoints_aug = []
        for idx in range(images.shape[0]):
            images_idx = images[idx, None]
            keypoints_idx = keypoints[idx, None]
            augmented_idx = self.augmenter(images=images_idx, keypoints=keypoints_idx)
            images_aug_idx, keypoints_aug_idx = augmented_idx
            images_aug.append(images_aug_idx)
            keypoints_aug.append(keypoints_aug_idx)

        images_aug = np.concatenate(images_aug)
        keypoints_aug = np.concatenate(keypoints_aug)
        return images_aug, keypoints_aug

    def generate_batch(self, indexes):
        &#34;&#34;&#34;Generates data containing batch_size samples&#34;&#34;&#34;
        X, y = self.load_batch(indexes)
        if self.augmenter and not self.validation:
            X, y = self.augment(X, y)
        if self.confidence:
            y = draw_confidence_maps(
                images=X,
                keypoints=y,
                graph=self.graph,
                output_shape=self.output_shape,
                use_graph=self.use_graph,
                sigma=self.output_sigma,
            )
            y *= 255
            if self.use_graph:
                y[..., self.n_keypoints :] *= self.graph_scale
        if self.n_outputs &gt; 1:
            y = [y for idx in range(self.n_outputs)]

        return X, y

    def get_config(self):
        if self.augmenter:
            augmenter = True
        else:
            augmenter = False
        config = {
            &#34;n_train&#34;: self.n_train,
            &#34;n_validation&#34;: self.n_validation,
            &#34;validation_split&#34;: self.validation_split,
            &#34;downsample_factor&#34;: self.downsample_factor,
            &#34;output_shape&#34;: self.output_shape,
            &#34;n_output_channels&#34;: self.n_output_channels,
            &#34;shuffle&#34;: self.shuffle,
            &#34;sigma&#34;: self.sigma,
            &#34;output_sigma&#34;: self.output_sigma,
            &#34;use_graph&#34;: self.use_graph,
            &#34;graph_scale&#34;: self.graph_scale,
            &#34;random_seed&#34;: self.random_seed,
            &#34;augmenter&#34;: augmenter,
        }
        base_config = self.generator.get_config()
        return dict(list(config.items()) + list(base_config.items()))</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="deepposekit.io.TrainingGenerator.TrainingGenerator"><code class="flex name class">
<span>class <span class="ident">TrainingGenerator</span></span>
<span>(</span><span>generator, downsample_factor=2, use_graph=True, augmenter=None, shuffle=True, sigma=5, validation_split=0.0, graph_scale=1.0, random_seed=None)</span>
</code></dt>
<dd>
<section class="desc"><p>Generates data for training a model.</p>
<p>Automatically loads annotated data and produces
augmented images and confidence maps for each keypoint.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>generator</code></strong> :&ensp;<a title="deepposekit.io.BaseGenerator" href="BaseGenerator.html"><code>deepposekit.io.BaseGenerator</code></a></dt>
<dd>An instance of BaseGenerator (deepposekit.io.BaseGenerator) object.
The output of the generator must be <code>(images, keypoints)</code>, where images
are a numpy array of shape (n_images, height, width, channels), and
keypoints are a numpy array of shape (n_images, n_keypoints, 2), where
2 is the row, column coordinates of the keypoints in each image.</dd>
<dt><strong><code>downsample_factor</code></strong> :&ensp;<code>int</code>, default = <code>0</code></dt>
<dd>The factor for determining the output shape of the confidence
maps for estimating keypoints. This is determined as
shape // 2**downsample_factor. The default is 0, which
produces confidence maps that are the same shape
as the input images.</dd>
<dt><strong><code>use_graph</code></strong> :&ensp;<code>bool</code>, default = <code>True</code></dt>
<dd>Whether to generate confidence maps for the parent graph
as lines drawn between connected keypoints. This can help reduce
keypoint estimation error when training the network.</dd>
<dt><strong><code>augmenter</code></strong> :&ensp;<code>class</code> or <code>list</code>, default = <code>None</code></dt>
<dd>A imgaug.Augmenter, or list of imgaug.Augmenter
for applying augmentations to images and keypoints.
Default is None, which applies no augmentations.</dd>
<dt><strong><code>shuffle</code></strong> :&ensp;<code>bool</code>, default = <code>True</code></dt>
<dd>Whether to randomly shuffle the data.</dd>
<dt><strong><code>sigma</code></strong> :&ensp;<code>float</code>, default = <code>3</code></dt>
<dd>The standard deviation of the Gaussian confidence peaks.
This is scaled to sigma // 2**downsample_factor.</dd>
<dt><strong><code>validation_split</code></strong> :&ensp;<code>float</code>, default = <code>0.0</code></dt>
<dd>Float between 0 and 1. Fraction of the training data to be used
as validation data. The generator will set apart this fraction
of the training data, will not generate this data unless
the <code>validation</code> flag is set to True when the class is called.</dd>
<dt><strong><code>graph_scale</code></strong> :&ensp;<code>float</code>, default = <code>1.0</code></dt>
<dd>Float between 0 and 1. A factor to scale the edge
confidence map values to y * edge_scale.
The default is 1.0 which does not scale the confidence
values. This is useful for preventing the edge channels
from dominating the error when training a smaller network.
This arg is not used when <code>use_graph</code> is set to False.</dd>
<dt><strong><code>random_seed</code></strong> :&ensp;<code>int</code>, default = <code>None</code></dt>
<dd>set random seed for selecting validation data</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class TrainingGenerator(Sequence):
    &#34;&#34;&#34;
    Generates data for training a model.
    
    Automatically loads annotated data and produces
    augmented images and confidence maps for each keypoint.

    Parameters
    ----------
    generator: deepposekit.io.BaseGenerator
        An instance of BaseGenerator (deepposekit.io.BaseGenerator) object.
        The output of the generator must be `(images, keypoints)`, where images
        are a numpy array of shape (n_images, height, width, channels), and 
        keypoints are a numpy array of shape (n_images, n_keypoints, 2), where
        2 is the row, column coordinates of the keypoints in each image.
    downsample_factor : int, default = 0
        The factor for determining the output shape of the confidence
        maps for estimating keypoints. This is determined as
        shape // 2**downsample_factor. The default is 0, which
        produces confidence maps that are the same shape
        as the input images.
    use_graph : bool, default = True
        Whether to generate confidence maps for the parent graph
        as lines drawn between connected keypoints. This can help reduce
        keypoint estimation error when training the network.
    augmenter : class or list, default = None
        A imgaug.Augmenter, or list of imgaug.Augmenter
        for applying augmentations to images and keypoints.
        Default is None, which applies no augmentations.
    shuffle : bool, default = True
        Whether to randomly shuffle the data.
    sigma : float, default = 3
        The standard deviation of the Gaussian confidence peaks.
        This is scaled to sigma // 2**downsample_factor.
    validation_split : float, default = 0.0
        Float between 0 and 1. Fraction of the training data to be used
        as validation data. The generator will set apart this fraction
        of the training data, will not generate this data unless
        the `validation` flag is set to True when the class is called.
    graph_scale : float, default = 1.0
        Float between 0 and 1. A factor to scale the edge
        confidence map values to y * edge_scale.
        The default is 1.0 which does not scale the confidence
        values. This is useful for preventing the edge channels
        from dominating the error when training a smaller network.
        This arg is not used when `use_graph` is set to False.
    random_seed : int, default = None
        set random seed for selecting validation data
    &#34;&#34;&#34;

    def __init__(
        self,
        generator,
        downsample_factor=2,
        use_graph=True,
        augmenter=None,
        shuffle=True,
        sigma=5,
        validation_split=0.0,
        graph_scale=1.0,
        random_seed=None,
    ):

        self.random_seed = random_seed
        if self.random_seed:
            np.random.seed(self.random_seed)

        self.shuffle = shuffle

        if isinstance(downsample_factor, int):
            if downsample_factor &gt;= 0:
                self.downsample_factor = downsample_factor
            else:
                raise ValueError(&#34;&#34;&#34;downsample factor must be &gt;= 0&#34;&#34;&#34;)
        else:
            raise TypeError(&#34;&#34;&#34;downsample_factor must be type int&#34;&#34;&#34;)
        self.sigma = sigma
        self.output_sigma = sigma / 2.0 ** downsample_factor
        self.batch_size = 32
        self.n_outputs = 1
        self.use_graph = use_graph
        self.graph_scale = graph_scale

        if 0 &lt;= validation_split &lt; 1:
            self.validation_split = validation_split
        else:
            raise ValueError(&#34;`validation_split` must be &gt;=0 and &lt;1&#34;)
        self.validation = False
        self.confidence = True
        self._init_augmenter(augmenter)
        self._init_data(generator)
        self.on_epoch_end()

    def _init_augmenter(self, augmenter):
        if isinstance(augmenter, type(None)):
            self.augmenter = augmenter
        elif isinstance(augmenter, iaa.Augmenter):
            self.augmenter = augmenter
        elif isinstance(augmenter, list):
            if isinstance(augmenter[0], iaa.Augmenter):
                self.augmenter = iaa.Sequential(augmenter)
            else:
                raise TypeError(
                    &#34;&#34;&#34;`augmenter` must be class Augmenter
                            (imgaug.augmenters.Augmenter)
                            or list of Augmenters&#34;&#34;&#34;
                )
        else:
            raise ValueError(
                &#34;&#34;&#34;augmenter must be class
                             Augmenter, list of Augmenters, or None&#34;&#34;&#34;
            )

    def _init_data(self, generator):

        if isinstance(generator, BaseGenerator):
            self.generator = generator
        else:
            raise TypeError(
                &#34;`generator` must be a subclass of `deepposekit.io.BaseGenerator`&#34;
                &#34; such as `deepposekit.io.DataGenerator` or `deepposekit.io.DLCDataGenerator`.&#34;
            )
        self.n_samples = len(self.generator)
        if self.n_samples &lt;= 0:
            raise AttributeError(
                &#34;`n_samples` is 0. `datapath` or `dataset` appears to be empty&#34;
            )

        # Get image attributes and
        # define output shape
        self.height = self.generator.image_shape[0]
        self.width = self.generator.image_shape[1]
        self.n_channels = self.generator.image_shape[2]

        self.output_shape = (
            self.height // 2 ** self.downsample_factor,
            self.width // 2 ** self.downsample_factor,
        )

        # Training/validation split
        # indices for validation set in sample_index
        self.index = np.arange(self.n_samples)
        self.n_validation = int(self.validation_split * self.n_samples)
        if self.n_validation is 0:
            warnings.warn(
                &#34;`n_validation` is 0. Increase `validation_split` to use a validation set.&#34;
            )

        val_index = np.random.choice(self.index, self.n_validation, replace=False)
        self.val_index = self.index[val_index]
        # indices for training set in  sample_index
        train_index = np.invert(np.isin(self.index, self.val_index))
        self.train_index = self.index[train_index]
        self.n_train = len(self.train_index)
        self.n_keypoints = self.generator.keypoints_shape[0]

        # Initialize skeleton attributes
        self.graph = self.generator.graph
        self.swap_index = self.generator.swap_index

        self.on_epoch_end()
        X, y = self.__getitem__(0)
        self.n_output_channels = y.shape[-1]

    def __len__(self):
        &#34;&#34;&#34;The number of batches per epoch&#34;&#34;&#34;
        if self.validation:
            return self.n_validation // self.batch_size
        else:
            return self.n_train // self.batch_size

    def __call__(self, n_outputs=1, batch_size=32, validation=False, confidence=True):
        &#34;&#34;&#34; Sets the number of outputs and the batch size

        Parameters
        ----------
        n_outputs : int, default = 1
            The number of outputs to generate.
            This is needed for applying intermediate supervision
            to a network with multiple output layers.
        batch_size : int, default = 32
            Number of samples in each batch
        validation: bool, default False
            If set to True, will generate the validation set.
            Otherwise, generates the training set.
        confidence: bool, default True
            If set to True, will generate confidence maps.
            Otherwise, generates keypoints.

        &#34;&#34;&#34;
        self.n_outputs = n_outputs
        self.batch_size = batch_size
        if validation:
            if self.n_validation is 0 and self.validation_split is 0:
                warnings.warn(
                    &#34;`validation_split` is 0, so there will be no validation step. &#34;
                    &#34;callbacks that rely on `val_loss` should be switched to `loss` or removed.&#34;
                )
            if self.n_validation is 0 and self.validation_split is not 0:
                warnings.warn(
                    &#34;`validation_split` is too small, so there will be no validation step. &#34;
                    &#34;`validation_split` should be increased or &#34;
                    &#34;callbacks that rely on `val_loss` should be switched to &#39;loss&#39; or removed.&#34;
                )

        self.validation = validation
        self.confidence = confidence
        self.on_epoch_end()
        self_copy = copy.deepcopy(self)
        if self.augmenter:
            self_copy.augmenter.reseed()
        return self_copy

    def __getitem__(self, index):
        &#34;&#34;&#34;Generate one batch of data&#34;&#34;&#34;
        # Generate indexes of the batch
        idx0 = index * self.batch_size
        idx1 = (index + 1) * self.batch_size
        if self.validation:
            indexes = self.val_range[idx0:idx1]
        else:
            indexes = self.train_range[idx0:idx1]

        # Generate data
        X, y = self.generate_batch(indexes)

        return X, y

    def on_epoch_end(self):
        &#34;&#34;&#34;Updates indexes after each epoch&#34;&#34;&#34;
        self.train_range = np.arange(self.n_train)
        self.val_range = np.arange(self.n_validation)
        if self.shuffle:
            np.random.shuffle(self.train_range)
            np.random.shuffle(self.val_range)

    def load_batch(self, indexes):
        if self.validation:
            batch_index = self.val_index[indexes]
        else:
            batch_index = self.train_index[indexes]
        return self.generator[batch_index]

    def augment(self, images, keypoints):
        images_aug = []
        keypoints_aug = []
        for idx in range(images.shape[0]):
            images_idx = images[idx, None]
            keypoints_idx = keypoints[idx, None]
            augmented_idx = self.augmenter(images=images_idx, keypoints=keypoints_idx)
            images_aug_idx, keypoints_aug_idx = augmented_idx
            images_aug.append(images_aug_idx)
            keypoints_aug.append(keypoints_aug_idx)

        images_aug = np.concatenate(images_aug)
        keypoints_aug = np.concatenate(keypoints_aug)
        return images_aug, keypoints_aug

    def generate_batch(self, indexes):
        &#34;&#34;&#34;Generates data containing batch_size samples&#34;&#34;&#34;
        X, y = self.load_batch(indexes)
        if self.augmenter and not self.validation:
            X, y = self.augment(X, y)
        if self.confidence:
            y = draw_confidence_maps(
                images=X,
                keypoints=y,
                graph=self.graph,
                output_shape=self.output_shape,
                use_graph=self.use_graph,
                sigma=self.output_sigma,
            )
            y *= 255
            if self.use_graph:
                y[..., self.n_keypoints :] *= self.graph_scale
        if self.n_outputs &gt; 1:
            y = [y for idx in range(self.n_outputs)]

        return X, y

    def get_config(self):
        if self.augmenter:
            augmenter = True
        else:
            augmenter = False
        config = {
            &#34;n_train&#34;: self.n_train,
            &#34;n_validation&#34;: self.n_validation,
            &#34;validation_split&#34;: self.validation_split,
            &#34;downsample_factor&#34;: self.downsample_factor,
            &#34;output_shape&#34;: self.output_shape,
            &#34;n_output_channels&#34;: self.n_output_channels,
            &#34;shuffle&#34;: self.shuffle,
            &#34;sigma&#34;: self.sigma,
            &#34;output_sigma&#34;: self.output_sigma,
            &#34;use_graph&#34;: self.use_graph,
            &#34;graph_scale&#34;: self.graph_scale,
            &#34;random_seed&#34;: self.random_seed,
            &#34;augmenter&#34;: augmenter,
        }
        base_config = self.generator.get_config()
        return dict(list(config.items()) + list(base_config.items()))</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>tensorflow.python.keras.utils.data_utils.Sequence</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="deepposekit.io.TrainingGenerator.TrainingGenerator.augment"><code class="name flex">
<span>def <span class="ident">augment</span></span>(<span>self, images, keypoints)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def augment(self, images, keypoints):
    images_aug = []
    keypoints_aug = []
    for idx in range(images.shape[0]):
        images_idx = images[idx, None]
        keypoints_idx = keypoints[idx, None]
        augmented_idx = self.augmenter(images=images_idx, keypoints=keypoints_idx)
        images_aug_idx, keypoints_aug_idx = augmented_idx
        images_aug.append(images_aug_idx)
        keypoints_aug.append(keypoints_aug_idx)

    images_aug = np.concatenate(images_aug)
    keypoints_aug = np.concatenate(keypoints_aug)
    return images_aug, keypoints_aug</code></pre>
</details>
</dd>
<dt id="deepposekit.io.TrainingGenerator.TrainingGenerator.generate_batch"><code class="name flex">
<span>def <span class="ident">generate_batch</span></span>(<span>self, indexes)</span>
</code></dt>
<dd>
<section class="desc"><p>Generates data containing batch_size samples</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def generate_batch(self, indexes):
    &#34;&#34;&#34;Generates data containing batch_size samples&#34;&#34;&#34;
    X, y = self.load_batch(indexes)
    if self.augmenter and not self.validation:
        X, y = self.augment(X, y)
    if self.confidence:
        y = draw_confidence_maps(
            images=X,
            keypoints=y,
            graph=self.graph,
            output_shape=self.output_shape,
            use_graph=self.use_graph,
            sigma=self.output_sigma,
        )
        y *= 255
        if self.use_graph:
            y[..., self.n_keypoints :] *= self.graph_scale
    if self.n_outputs &gt; 1:
        y = [y for idx in range(self.n_outputs)]

    return X, y</code></pre>
</details>
</dd>
<dt id="deepposekit.io.TrainingGenerator.TrainingGenerator.get_config"><code class="name flex">
<span>def <span class="ident">get_config</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_config(self):
    if self.augmenter:
        augmenter = True
    else:
        augmenter = False
    config = {
        &#34;n_train&#34;: self.n_train,
        &#34;n_validation&#34;: self.n_validation,
        &#34;validation_split&#34;: self.validation_split,
        &#34;downsample_factor&#34;: self.downsample_factor,
        &#34;output_shape&#34;: self.output_shape,
        &#34;n_output_channels&#34;: self.n_output_channels,
        &#34;shuffle&#34;: self.shuffle,
        &#34;sigma&#34;: self.sigma,
        &#34;output_sigma&#34;: self.output_sigma,
        &#34;use_graph&#34;: self.use_graph,
        &#34;graph_scale&#34;: self.graph_scale,
        &#34;random_seed&#34;: self.random_seed,
        &#34;augmenter&#34;: augmenter,
    }
    base_config = self.generator.get_config()
    return dict(list(config.items()) + list(base_config.items()))</code></pre>
</details>
</dd>
<dt id="deepposekit.io.TrainingGenerator.TrainingGenerator.load_batch"><code class="name flex">
<span>def <span class="ident">load_batch</span></span>(<span>self, indexes)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_batch(self, indexes):
    if self.validation:
        batch_index = self.val_index[indexes]
    else:
        batch_index = self.train_index[indexes]
    return self.generator[batch_index]</code></pre>
</details>
</dd>
<dt id="deepposekit.io.TrainingGenerator.TrainingGenerator.on_epoch_end"><code class="name flex">
<span>def <span class="ident">on_epoch_end</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Updates indexes after each epoch</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def on_epoch_end(self):
    &#34;&#34;&#34;Updates indexes after each epoch&#34;&#34;&#34;
    self.train_range = np.arange(self.n_train)
    self.val_range = np.arange(self.n_validation)
    if self.shuffle:
        np.random.shuffle(self.train_range)
        np.random.shuffle(self.val_range)</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="deepposekit.io" href="index.html">deepposekit.io</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="deepposekit.io.TrainingGenerator.TrainingGenerator" href="#deepposekit.io.TrainingGenerator.TrainingGenerator">TrainingGenerator</a></code></h4>
<ul class="">
<li><code><a title="deepposekit.io.TrainingGenerator.TrainingGenerator.augment" href="#deepposekit.io.TrainingGenerator.TrainingGenerator.augment">augment</a></code></li>
<li><code><a title="deepposekit.io.TrainingGenerator.TrainingGenerator.generate_batch" href="#deepposekit.io.TrainingGenerator.TrainingGenerator.generate_batch">generate_batch</a></code></li>
<li><code><a title="deepposekit.io.TrainingGenerator.TrainingGenerator.get_config" href="#deepposekit.io.TrainingGenerator.TrainingGenerator.get_config">get_config</a></code></li>
<li><code><a title="deepposekit.io.TrainingGenerator.TrainingGenerator.load_batch" href="#deepposekit.io.TrainingGenerator.TrainingGenerator.load_batch">load_batch</a></code></li>
<li><code><a title="deepposekit.io.TrainingGenerator.TrainingGenerator.on_epoch_end" href="#deepposekit.io.TrainingGenerator.TrainingGenerator.on_epoch_end">on_epoch_end</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.7.0</a>.</p>
</footer>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad()</script>
</body>
</html>
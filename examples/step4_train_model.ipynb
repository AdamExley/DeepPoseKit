{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepPoseKit Step 4 - Train a model\n",
    "\n",
    "This is step 4 of the example notebooks for using DeepPoseKit. This notebook shows you how to use your annotated data to train a deep learning model using data augmentation and callbacks for logging the training process and saving the best model during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you haven't already installed DeepPoseKit and downloaded the example datasets you can run the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'deepposekit-data' already exists and is not an empty directory.\n",
      "Collecting git+https://github.com/jgraving/deepposekit-annotator\n",
      "  Cloning https://github.com/jgraving/deepposekit-annotator to /private/var/folders/st/hhx75tj167g4qfsmb3rt8r7r0000gn/T/pip-req-build-m583q7gy\n",
      "  Running command git clone -q https://github.com/jgraving/deepposekit-annotator /private/var/folders/st/hhx75tj167g4qfsmb3rt8r7r0000gn/T/pip-req-build-m583q7gy\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/jgraving/deepposekit-data\n",
    "\n",
    "import sys\n",
    "!{sys.executable} -m pip install \\\n",
    "git+https://github.com/jgraving/deepposekit-annotator \\\n",
    "git+https://github.com/jgraving/deepposekit-annotator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "from deepposekit import TrainingGenerator\n",
    "from deepposekit.augment import FlipAxis\n",
    "import imgaug.augmenters as iaa\n",
    "import imgaug as ia\n",
    "\n",
    "from deepposekit.models import (StackedDenseNet,\n",
    "                                DeepLabCut,\n",
    "                                StackedHourglass,\n",
    "                                LEAP)\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from deepposekit.callbacks import Logger, ModelCheckpoint\n",
    "\n",
    "import time\n",
    "from os.path import expanduser\n",
    "HOME = expanduser(\"~\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/jake/deepposekit-data/datasets/fly/annotation_data_release.h5',\n",
       " '/home/jake/deepposekit-data/datasets/fly/best_model_densenet.h5',\n",
       " '/home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5',\n",
       " '/home/jake/deepposekit-data/datasets/fly/example_annotation_set.h5',\n",
       " '/home/jake/deepposekit-data/datasets/fly/log_densenet.h5',\n",
       " '/home/jake/deepposekit-data/datasets/fly/log_fly_densenet.h5']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations = sorted(glob.glob(HOME + '/deepposekit-data/datasets/fly/*.h5'))\n",
    "annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create an augmentation pipeline\n",
    "DeepPoseKit works with augmenters from the [imgaug package](https://github.com/aleju/imgaug).\n",
    "This is a short example using spatial augmentations with axis flipping and affine transforms\n",
    "See https://github.com/aleju/imgaug for more documentation on augmenters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmenter = []\n",
    "\n",
    "# FlipAxis only works if the data are rotationally aligned on the central body axis\n",
    "augmenter.append(FlipAxis(annotations[0], axis=0))  # flip image up-down\n",
    "augmenter.append(FlipAxis(annotations[0], axis=1))  # flip image left-right \n",
    "\n",
    "sometimes = []\n",
    "sometimes.append(iaa.Affine(scale={\"x\": (0.95, 1.05), \"y\": (0.95, 1.05)},\n",
    "                            translate_percent={'x': (-0.05, 0.05), 'y': (-0.05, 0.05)},\n",
    "                            shear=(-8, 8),\n",
    "                            order=ia.ALL,\n",
    "                            cval=ia.ALL,\n",
    "                            mode=ia.ALL)\n",
    "                 )\n",
    "sometimes.append(iaa.Affine(scale=(0.8, 1.2),\n",
    "                            mode=ia.ALL,\n",
    "                            order=ia.ALL,\n",
    "                            cval=ia.ALL)\n",
    "                 )\n",
    "augmenter.append(iaa.Sometimes(0.75, sometimes))\n",
    "augmenter.append(iaa.Affine(rotate=(-180, 180),\n",
    "                            mode=ia.ALL,\n",
    "                            order=ia.ALL,\n",
    "                            cval=ia.ALL)\n",
    "                 )\n",
    "augmenter = iaa.Sequential(augmenter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a training data generator\n",
    "This creates a data generator for training the model with annotated data. If you are using `LEAP` you should set the `downsample_factor` to 0. You can also look at the doc string for more explanation:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainingGenerator?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jake/.local/lib/python3.6/site-packages/h5py/_hl/dataset.py:313: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  \"Use dataset[()] instead.\", H5pyDeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'augmenter': True,\n",
       " 'datapath': '/home/jake/deepposekit-data/datasets/fly/annotation_data_release.h5',\n",
       " 'dataset': 'images',\n",
       " 'downsample_factor': 2,\n",
       " 'graph_scale': 0.1,\n",
       " 'n_keypoints': 32,\n",
       " 'n_output_channels': 66,\n",
       " 'n_validation': 150,\n",
       " 'output_shape': (48, 48),\n",
       " 'random_seed': 1,\n",
       " 'shuffle': True,\n",
       " 'sigma': 5,\n",
       " 'use_graph': True,\n",
       " 'validation_split': 0.1}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator = TrainingGenerator(datapath=annotations[0],\n",
    "                                    downsample_factor=2,\n",
    "                                    augmenter=augmenter,\n",
    "                                    sigma=5,\n",
    "                                    validation_split=0.1,\n",
    "                                    use_graph=True,\n",
    "                                    random_seed=1,\n",
    "                                    graph_scale=0.1)\n",
    "train_generator.get_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the augmentation output\n",
    "This plots the training data output from the `TrainingGenerator` to ensure that the augmentation is working, rerun this cell to see random augmentations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_keypoints = train_generator.n_keypoints\n",
    "batch = train_generator(batch_size=1, validation=False)[0]\n",
    "inputs = batch[0]\n",
    "outputs = batch[1]\n",
    "\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(10,10))\n",
    "ax1.imshow(inputs[0,...,0], cmap='gray', vmin=0, vmax=255)\n",
    "ax2.imshow(outputs[0,...,n_keypoints:-1].max(-1))\n",
    "ax3.imshow(outputs[0,...,:n_keypoints].max(-1))\n",
    "ax4.imshow(outputs[0,...,-1], vmin=0)\n",
    "plt.show()\n",
    "\n",
    "train_generator.on_epoch_end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define a model\n",
    "Here you can define a model to train with your data. You can use our `StackedDenseNet` model, `StackedHourglass` model, `DeepLabCut` model, or the `LEAP` model. The default settings for each model should work well for most datasets, but you can customize the model architecture. Look at the doc strings for more information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "StackedDenseNet?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'selu',\n",
       " 'augmenter': True,\n",
       " 'batchnorm': False,\n",
       " 'bottleneck_factor': 1,\n",
       " 'compression_factor': 0.5,\n",
       " 'datapath': '/home/jake/deepposekit-data/datasets/fly/annotation_data_release.h5',\n",
       " 'dataset': 'images',\n",
       " 'downsample_factor': 2,\n",
       " 'graph_scale': 0.1,\n",
       " 'growth_rate': 48,\n",
       " 'initializer': 'lecun_normal',\n",
       " 'interpolation': 'subpixel',\n",
       " 'n_keypoints': 32,\n",
       " 'n_layers': 1,\n",
       " 'n_output_channels': 66,\n",
       " 'n_stacks': 2,\n",
       " 'n_transitions': 5,\n",
       " 'n_validation': 150,\n",
       " 'name': 'StackedDenseNet',\n",
       " 'output_shape': (48, 48),\n",
       " 'pooling': 'max',\n",
       " 'random_seed': 1,\n",
       " 'separable': False,\n",
       " 'shuffle': True,\n",
       " 'sigma': 5,\n",
       " 'squeeze_excite': False,\n",
       " 'subpixel': True,\n",
       " 'use_bias': True,\n",
       " 'use_graph': True,\n",
       " 'validation_split': 0.1}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = StackedDenseNet(data_generator=train_generator, n_stacks=2)\n",
    "# model = DeepLabCut(train_generator)\n",
    "# model = LEAP(train_generator)\n",
    "# model = StackedHourglass(train_generator)\n",
    "model.get_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can examine the model architecture to see the model's layers and number of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 192, 192, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "float_1 (Float)                 (None, 192, 192, 1)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "image_normalization_1 (ImageNor (None, 192, 192, 1)  0           float_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 96, 96, 48)   2400        image_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 96, 96, 1)    0           image_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 96, 96, 48)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 96, 96, 49)   0           max_pooling2d_1[0][0]            \n",
      "                                                                 activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 96, 96, 48)   2400        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 96, 96, 48)   0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 96, 96, 48)   20784       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 96, 96, 48)   0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 96, 96, 97)   0           concatenate_1[0][0]              \n",
      "                                                                 activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 48, 48, 97)   0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 48, 48, 48)   4704        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 48, 48, 48)   0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 48, 48, 48)   20784       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 48, 48, 48)   0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 48, 48, 96)   0           activation_4[0][0]               \n",
      "                                                                 activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 24, 24, 96)   0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 24, 24, 48)   4656        max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 24, 24, 48)   0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 24, 24, 48)   20784       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 24, 24, 48)   0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 24, 24, 96)   0           activation_6[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 12, 12, 96)   0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 12, 12, 48)   4656        max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 12, 12, 48)   0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 12, 12, 48)   20784       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 12, 12, 48)   0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 12, 12, 96)   0           activation_8[0][0]               \n",
      "                                                                 activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 6, 6, 96)     0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 6, 6, 48)     4656        max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 6, 6, 48)     0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 6, 6, 48)     20784       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 6, 6, 48)     0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 12, 12, 96)   0           activation_8[0][0]               \n",
      "                                                                 activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 6, 6, 96)     0           activation_10[0][0]              \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 12, 12, 48)   4656        concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "sub_pixel_upscaling_1 (SubPixel (None, 12, 12, 24)   0           concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 12, 12, 48)   0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 12, 12, 72)   0           sub_pixel_upscaling_1[0][0]      \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 12, 12, 48)   3504        concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 12, 12, 48)   0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 12, 12, 48)   20784       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 12, 12, 48)   0           conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 24, 24, 96)   0           activation_6[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 12, 12, 120)  0           concatenate_8[0][0]              \n",
      "                                                                 activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 24, 24, 48)   4656        concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "sub_pixel_upscaling_2 (SubPixel (None, 24, 24, 30)   0           concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 24, 24, 48)   0           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 24, 24, 78)   0           sub_pixel_upscaling_2[0][0]      \n",
      "                                                                 activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 24, 24, 48)   3792        concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 24, 24, 48)   0           conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 24, 24, 48)   20784       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 24, 24, 48)   0           conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 24, 24, 126)  0           concatenate_11[0][0]             \n",
      "                                                                 activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 96, 96, 146)  0           max_pooling2d_1[0][0]            \n",
      "                                                                 activation_1[0][0]               \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 24, 24, 124)  15748       concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 48, 48, 96)   0           activation_4[0][0]               \n",
      "                                                                 activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 48, 48, 146)  0           concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 48, 48, 96)   0           activation_4[0][0]               \n",
      "                                                                 activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 24, 24, 124)  0           conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 48, 48, 48)   4656        concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 48, 48, 73)   10731       max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 48, 48, 48)   4656        concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "sub_pixel_upscaling_3 (SubPixel (None, 48, 48, 31)   0           activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 48, 48, 48)   0           conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 48, 48, 1)    0           image_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 48, 48, 73)   0           conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 48, 48, 48)   0           conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 48, 48, 201)  0           sub_pixel_upscaling_3[0][0]      \n",
      "                                                                 activation_19[0][0]              \n",
      "                                                                 max_pooling2d_6[0][0]            \n",
      "                                                                 activation_20[0][0]              \n",
      "                                                                 activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 48, 48, 48)   9696        concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 48, 48, 48)   0           conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 48, 48, 48)   20784       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 48, 48, 48)   0           conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 48, 48, 249)  0           concatenate_16[0][0]             \n",
      "                                                                 activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 48, 48, 124)  31000       concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 48, 48, 124)  0           conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output_0 (Conv2D)               (None, 48, 48, 66)   8250        activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "image_normalization_2 (ImageNor (None, 48, 48, 66)   0           output_0[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 48, 48, 190)  0           activation_24[0][0]              \n",
      "                                                                 image_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 48, 48, 48)   9168        concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 48, 48, 48)   0           conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 48, 48, 48)   20784       activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 48, 48, 48)   0           conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 48, 48, 238)  0           concatenate_18[0][0]             \n",
      "                                                                 activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 48, 48, 48)   11472       concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 48, 48, 48)   0           conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 48, 48, 48)   20784       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 48, 48, 48)   0           conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)    (None, 48, 48, 286)  0           concatenate_19[0][0]             \n",
      "                                                                 activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 48, 48, 48)   13776       concatenate_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 48, 48, 48)   0           conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 48, 48, 48)   20784       activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 48, 48, 48)   0           conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)    (None, 48, 48, 334)  0           concatenate_20[0][0]             \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 24, 24, 334)  0           concatenate_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 24, 24, 167)  55945       max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 24, 24, 167)  0           conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 24, 24, 48)   8064        activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 24, 24, 48)   0           conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 24, 24, 48)   20784       activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 24, 24, 48)   0           conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)    (None, 24, 24, 215)  0           activation_32[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 24, 24, 48)   10368       concatenate_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 24, 24, 48)   0           conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 24, 24, 48)   20784       activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 24, 24, 48)   0           conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)    (None, 24, 24, 263)  0           concatenate_22[0][0]             \n",
      "                                                                 activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 24, 24, 48)   12672       concatenate_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 24, 24, 48)   0           conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 24, 24, 48)   20784       activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 24, 24, 48)   0           conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_24 (Concatenate)    (None, 24, 24, 311)  0           concatenate_23[0][0]             \n",
      "                                                                 activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 12, 12, 311)  0           concatenate_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 12, 12, 156)  48672       max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 12, 12, 156)  0           conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 12, 12, 48)   7536        activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 12, 12, 48)   0           conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 12, 12, 48)   20784       activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 12, 12, 48)   0           conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_25 (Concatenate)    (None, 12, 12, 204)  0           activation_39[0][0]              \n",
      "                                                                 activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 12, 12, 48)   9840        concatenate_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 12, 12, 48)   0           conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 12, 12, 48)   20784       activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 12, 12, 48)   0           conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_26 (Concatenate)    (None, 12, 12, 252)  0           concatenate_25[0][0]             \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 12, 12, 48)   12144       concatenate_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 12, 12, 48)   0           conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 12, 12, 48)   20784       activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 12, 12, 48)   0           conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_27 (Concatenate)    (None, 12, 12, 300)  0           concatenate_26[0][0]             \n",
      "                                                                 activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 6, 6, 300)    0           concatenate_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 6, 6, 150)    45150       max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 6, 6, 150)    0           conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 6, 6, 48)     7248        activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 6, 6, 48)     0           conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 6, 6, 48)     20784       activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 6, 6, 48)     0           conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_28 (Concatenate)    (None, 6, 6, 198)    0           activation_46[0][0]              \n",
      "                                                                 activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 6, 6, 48)     9552        concatenate_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 6, 6, 48)     0           conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 6, 6, 48)     20784       activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 6, 6, 48)     0           conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_29 (Concatenate)    (None, 6, 6, 246)    0           concatenate_28[0][0]             \n",
      "                                                                 activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 6, 6, 48)     11856       concatenate_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 6, 6, 48)     0           conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 6, 6, 48)     20784       activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 6, 6, 48)     0           conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_30 (Concatenate)    (None, 6, 6, 294)    0           concatenate_29[0][0]             \n",
      "                                                                 activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 6, 6, 292)    86140       concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_31 (Concatenate)    (None, 12, 12, 300)  0           concatenate_26[0][0]             \n",
      "                                                                 activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 6, 6, 292)    0           conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 12, 12, 150)  45150       concatenate_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "sub_pixel_upscaling_4 (SubPixel (None, 12, 12, 73)   0           activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 12, 12, 150)  0           conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_32 (Concatenate)    (None, 12, 12, 223)  0           sub_pixel_upscaling_4[0][0]      \n",
      "                                                                 activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 12, 12, 48)   10752       concatenate_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 12, 12, 48)   0           conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 12, 12, 48)   20784       activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 12, 12, 48)   0           conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_33 (Concatenate)    (None, 12, 12, 271)  0           concatenate_32[0][0]             \n",
      "                                                                 activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 12, 12, 48)   13056       concatenate_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 12, 12, 48)   0           conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 12, 12, 48)   20784       activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 12, 12, 48)   0           conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_34 (Concatenate)    (None, 12, 12, 319)  0           concatenate_33[0][0]             \n",
      "                                                                 activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 12, 12, 320)  102400      concatenate_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_35 (Concatenate)    (None, 24, 24, 311)  0           concatenate_23[0][0]             \n",
      "                                                                 activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 12, 12, 320)  0           conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 24, 24, 156)  48672       concatenate_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "sub_pixel_upscaling_5 (SubPixel (None, 24, 24, 80)   0           activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 24, 24, 156)  0           conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_36 (Concatenate)    (None, 24, 24, 236)  0           sub_pixel_upscaling_5[0][0]      \n",
      "                                                                 activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 24, 24, 48)   11376       concatenate_36[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 24, 24, 48)   0           conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 24, 24, 48)   20784       activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 24, 24, 48)   0           conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_38 (Concatenate)    (None, 48, 48, 334)  0           concatenate_20[0][0]             \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_39 (Concatenate)    (None, 48, 48, 334)  0           concatenate_20[0][0]             \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_37 (Concatenate)    (None, 24, 24, 284)  0           concatenate_36[0][0]             \n",
      "                                                                 activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 48, 48, 167)  55945       concatenate_38[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 48, 48, 167)  55945       concatenate_39[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "sub_pixel_upscaling_6 (SubPixel (None, 48, 48, 71)   0           concatenate_37[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 48, 48, 167)  0           conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 48, 48, 167)  0           conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_40 (Concatenate)    (None, 48, 48, 405)  0           sub_pixel_upscaling_6[0][0]      \n",
      "                                                                 activation_63[0][0]              \n",
      "                                                                 activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 48, 48, 48)   19488       concatenate_40[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 48, 48, 48)   0           conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 48, 48, 48)   20784       activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 48, 48, 48)   0           conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_41 (Concatenate)    (None, 48, 48, 453)  0           concatenate_40[0][0]             \n",
      "                                                                 activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 48, 48, 226)  102604      concatenate_41[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 48, 48, 226)  0           conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output_1 (Conv2D)               (None, 48, 48, 66)   14982       activation_67[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,463,606\n",
      "Trainable params: 1,463,606\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.train_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the prediction speed\n",
    "This generates a random set of input images for the model to test how fast the model can predict keypoint locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size = (10000,\n",
    "             train_generator.height,\n",
    "             train_generator.width, \n",
    "             train_generator.n_channels)\n",
    "x = np.random.randint(0, 255, data_size, dtype='uint8')\n",
    "t0 = time.time()\n",
    "y = model.predict(x, batch_size=100, verbose=1)\n",
    "t1 = time.time()\n",
    "print(x.shape[0]/(t1-t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define callbacks to enhance model training\n",
    "Here you can define callbacks to pass to the model for use during training\n",
    "\n",
    "\n",
    "`Logger` evaluates the validation set at the end of each epoch and saves the evaluation data to a HDF5 log file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = Logger(HOME + '/deepposekit-data/datasets/fly/log_densenet.h5',\n",
    "                validation_batch_size=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ReduceLROnPlateau` automatically reduces the learning rate of the optimizer when the validation loss stops improving. This helps the model to reach a better optimum at the end of training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau('val_loss',\n",
    "                              factor=0.2,\n",
    "                              verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ModelCheckpoint` automatically saves the model when the validation loss improves at the end of each epoch. This allows you to automatically save the best performing model during training, without having to evaluate the performance manually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = ModelCheckpoint(HOME + '/deepposekit-data/datasets/fly/best_model_densenet.h5',\n",
    "                                   monitor='val_loss',\n",
    "                                   verbose=1,\n",
    "                                   save_best_only=True,\n",
    "                                   optimizer=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`EarlyStopping` automatically stops the training session when the validation loss stops improving for a set number of epochs, which is set with the `patience` argument. This allows you to save time when training your model if there's not more improvment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping('val_loss',\n",
    "                           min_delta=0.001,\n",
    "                           patience=50,\n",
    "                           verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a list of callbacks to pass to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [logger, early_stop, reduce_lr, model_checkpoint]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit the model\n",
    "\n",
    "This fits the model for a set number of epochs with small batches of data. If you have a small dataset initially you can set `batch_size` to a small value and manually set `steps_per_epoch` to some large value, e.g. 500, to increase the number of batches per epoch, otherwise this is automatically determined by the size of the dataset. See the doc string for details:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "84/84 [==============================] - 45s 540ms/step - loss: 141.5929 - output_0_loss: 71.9562 - output_1_loss: 69.6367 - val_loss: 127.7636 - val_output_0_loss: 65.9062 - val_output_1_loss: 61.8574\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 20.8619 13.9248 (1.5311, 74.3796) - mae: 12.8411 9.3500 (0.9800, 45.2200) - mse: 410.8777 97.0960 (1.1721, 2766.1602) - rmse: 14.7516 9.8464 (1.0826, 52.5943)\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 127.76356, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 2/1000\n",
      "84/84 [==============================] - 35s 411ms/step - loss: 123.4802 - output_0_loss: 65.3742 - output_1_loss: 58.1060 - val_loss: 114.6841 - val_output_0_loss: 63.1798 - val_output_1_loss: 51.5043\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 20.0451 14.3249 (1.0671, 72.1541) - mae: 11.5309 9.2665 (0.6600, 40.3005) - mse: 414.4482 103.0886 (0.5694, 2603.1043) - rmse: 14.1740 10.1292 (0.7546, 51.0206)\n",
      "\n",
      "Epoch 00002: val_loss improved from 127.76356 to 114.68405, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 3/1000\n",
      "84/84 [==============================] - 36s 433ms/step - loss: 108.1311 - output_0_loss: 61.4599 - output_1_loss: 46.6712 - val_loss: 97.7990 - val_output_0_loss: 58.4986 - val_output_1_loss: 39.3004\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 10.3509 4.2044 (0.6596, 72.4485) - mae: 6.1413 2.6748 (0.4199, 39.8000) - mse: 205.2073 8.8410 (0.2175, 2624.3938) - rmse: 7.3192 2.9730 (0.4664, 51.2288)\n",
      "\n",
      "Epoch 00003: val_loss improved from 114.68405 to 97.79897, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 4/1000\n",
      "84/84 [==============================] - 38s 447ms/step - loss: 91.8964 - output_0_loss: 57.5500 - output_1_loss: 34.3465 - val_loss: 83.5508 - val_output_0_loss: 54.7832 - val_output_1_loss: 28.7676\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 5.9511 2.6944 (0.5123, 37.3852) - mae: 3.7003 1.7288 (0.3200, 23.9294) - mse: 83.5868 3.6304 (0.1312, 698.8257) - rmse: 4.2081 1.9052 (0.3622, 26.4353)\n",
      "\n",
      "Epoch 00004: val_loss improved from 97.79897 to 83.55084, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 5/1000\n",
      "84/84 [==============================] - 37s 442ms/step - loss: 80.6402 - output_0_loss: 53.8462 - output_1_loss: 26.7940 - val_loss: 75.2245 - val_output_0_loss: 51.3208 - val_output_1_loss: 23.9037\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 5.2108 2.5024 (0.4948, 29.9731) - mae: 3.2574 1.6300 (0.3000, 19.4830) - mse: 58.6598 3.1309 (0.1224, 449.1946) - rmse: 3.6846 1.7694 (0.3499, 21.1942)\n",
      "\n",
      "Epoch 00005: val_loss improved from 83.55084 to 75.22447, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 6/1000\n",
      "84/84 [==============================] - 36s 426ms/step - loss: 74.4513 - output_0_loss: 50.7298 - output_1_loss: 23.7215 - val_loss: 68.6243 - val_output_0_loss: 48.0636 - val_output_1_loss: 20.5607\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 3.9513 2.1145 (0.4561, 19.8573) - mae: 2.5297 1.3350 (0.2800, 13.1607) - mse: 29.2464 2.2361 (0.1040, 197.1576) - rmse: 2.7940 1.4952 (0.3225, 14.0413)\n",
      "\n",
      "Epoch 00006: val_loss improved from 75.22447 to 68.62431, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 7/1000\n",
      "84/84 [==============================] - 37s 437ms/step - loss: 69.4985 - output_0_loss: 48.0178 - output_1_loss: 21.4808 - val_loss: 63.6569 - val_output_0_loss: 45.2328 - val_output_1_loss: 18.4241\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 3.5782 1.9324 (0.3418, 18.6150) - mae: 2.2873 1.2000 (0.2200, 12.1834) - mse: 25.7538 1.8672 (0.0584, 173.2588) - rmse: 2.5302 1.3664 (0.2417, 13.1628)\n",
      "\n",
      "Epoch 00007: val_loss improved from 68.62431 to 63.65687, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 8/1000\n",
      "84/84 [==============================] - 36s 434ms/step - loss: 64.3544 - output_0_loss: 44.2102 - output_1_loss: 20.1442 - val_loss: 56.9272 - val_output_0_loss: 39.4944 - val_output_1_loss: 17.4328\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 3.5603 1.8922 (0.3299, 19.3273) - mae: 2.2851 1.1850 (0.2200, 12.5924) - mse: 24.7474 1.7903 (0.0544, 186.7723) - rmse: 2.5175 1.3380 (0.2332, 13.6665)\n",
      "\n",
      "Epoch 00008: val_loss improved from 63.65687 to 56.92722, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 9/1000\n",
      "84/84 [==============================] - 36s 434ms/step - loss: 56.6931 - output_0_loss: 37.5027 - output_1_loss: 19.1903 - val_loss: 50.0952 - val_output_0_loss: 33.2904 - val_output_1_loss: 16.8048\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 3.2350 1.7412 (0.3394, 17.0024) - mae: 2.0617 1.0877 (0.2000, 10.5552) - mse: 20.6909 1.5160 (0.0576, 144.5402) - rmse: 2.2875 1.2312 (0.2400, 12.0225)\n",
      "\n",
      "Epoch 00009: val_loss improved from 56.92722 to 50.09522, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 10/1000\n",
      "84/84 [==============================] - 37s 437ms/step - loss: 50.8308 - output_0_loss: 32.8036 - output_1_loss: 18.0272 - val_loss: 46.2102 - val_output_0_loss: 30.2164 - val_output_1_loss: 15.9938\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 3.0652 1.6768 (0.3225, 14.9659) - mae: 1.9475 1.0650 (0.2000, 9.3430) - mse: 17.7118 1.4058 (0.0520, 111.9912) - rmse: 2.1674 1.1856 (0.2280, 10.5825)\n",
      "\n",
      "Epoch 00010: val_loss improved from 50.09522 to 46.21015, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 11/1000\n",
      "84/84 [==============================] - 36s 432ms/step - loss: 47.8430 - output_0_loss: 30.4918 - output_1_loss: 17.3512 - val_loss: 42.8479 - val_output_0_loss: 27.3875 - val_output_1_loss: 15.4604\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 3.2000 1.8886 (0.3688, 16.3841) - mae: 2.0503 1.2000 (0.2291, 10.1815) - mse: 17.8535 1.7846 (0.0680, 134.2189) - rmse: 2.2627 1.3354 (0.2608, 11.5853)\n",
      "\n",
      "Epoch 00011: val_loss improved from 46.21015 to 42.84786, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 12/1000\n",
      "84/84 [==============================] - 37s 436ms/step - loss: 45.0239 - output_0_loss: 28.6180 - output_1_loss: 16.4059 - val_loss: 43.5580 - val_output_0_loss: 27.0284 - val_output_1_loss: 16.5295\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 3.2874 2.1538 (0.4252, 14.8791) - mae: 2.1099 1.3700 (0.2600, 9.7410) - mse: 16.5771 2.3200 (0.0904, 110.6937) - rmse: 2.3245 1.5229 (0.3007, 10.5211)\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 42.84786\n",
      "Epoch 13/1000\n",
      "84/84 [==============================] - 36s 433ms/step - loss: 43.1670 - output_0_loss: 27.3763 - output_1_loss: 15.7908 - val_loss: 40.9062 - val_output_0_loss: 25.9638 - val_output_1_loss: 14.9424\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 3.1372 1.8886 (0.4000, 14.5262) - mae: 1.9975 1.1900 (0.2400, 9.1019) - mse: 16.9359 1.7846 (0.0800, 105.5052) - rmse: 2.2183 1.3354 (0.2828, 10.2716)\n",
      "\n",
      "Epoch 00013: val_loss improved from 42.84786 to 40.90618, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 14/1000\n",
      "84/84 [==============================] - 37s 444ms/step - loss: 41.0488 - output_0_loss: 26.1454 - output_1_loss: 14.9034 - val_loss: 37.9238 - val_output_0_loss: 24.4767 - val_output_1_loss: 13.4471\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.8428 1.6904 (0.3225, 13.0821) - mae: 1.8170 1.1050 (0.2000, 8.1653) - mse: 15.3661 1.4288 (0.0520, 85.5708) - rmse: 2.0102 1.1953 (0.2280, 9.2504)\n",
      "\n",
      "Epoch 00014: val_loss improved from 40.90618 to 37.92379, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 15/1000\n",
      "84/84 [==============================] - 37s 436ms/step - loss: 39.6973 - output_0_loss: 25.3932 - output_1_loss: 14.3041 - val_loss: 37.3492 - val_output_0_loss: 23.6238 - val_output_1_loss: 13.7253\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.8574 1.8835 (0.3688, 12.1269) - mae: 1.8219 1.1800 (0.2400, 7.4911) - mse: 12.7364 1.7738 (0.0680, 73.5315) - rmse: 2.0205 1.3318 (0.2608, 8.5750)\n",
      "\n",
      "Epoch 00015: val_loss improved from 37.92379 to 37.34920, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 16/1000\n",
      "84/84 [==============================] - 36s 434ms/step - loss: 38.5882 - output_0_loss: 24.7468 - output_1_loss: 13.8414 - val_loss: 35.4326 - val_output_0_loss: 22.9502 - val_output_1_loss: 12.4824\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.7322 1.5391 (0.3298, 13.0069) - mae: 1.7435 0.9900 (0.2000, 8.3829) - mse: 14.3818 1.1847 (0.0544, 84.5908) - rmse: 1.9320 1.0883 (0.2332, 9.1973)\n",
      "\n",
      "Epoch 00016: val_loss improved from 37.34920 to 35.43258, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 17/1000\n",
      "84/84 [==============================] - 36s 428ms/step - loss: 37.8794 - output_0_loss: 24.2916 - output_1_loss: 13.5877 - val_loss: 34.7290 - val_output_0_loss: 22.4048 - val_output_1_loss: 12.3242\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.5869 1.6321 (0.3124, 11.5736) - mae: 1.6475 1.0300 (0.1898, 7.5010) - mse: 11.4246 1.3339 (0.0488, 66.9746) - rmse: 1.8292 1.1541 (0.2209, 8.1838)\n",
      "\n",
      "Epoch 00017: val_loss improved from 35.43258 to 34.72899, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 18/1000\n",
      "84/84 [==============================] - 38s 456ms/step - loss: 36.8937 - output_0_loss: 23.7255 - output_1_loss: 13.1682 - val_loss: 34.2345 - val_output_0_loss: 22.1591 - val_output_1_loss: 12.0754\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.5680 1.7379 (0.3200, 10.6994) - mae: 1.6337 1.1100 (0.2000, 6.6084) - mse: 12.2533 1.5102 (0.0512, 57.2381) - rmse: 1.8158 1.2289 (0.2263, 7.5656)\n",
      "\n",
      "Epoch 00018: val_loss improved from 34.72899 to 34.23453, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 19/1000\n",
      "84/84 [==============================] - 35s 422ms/step - loss: 36.2280 - output_0_loss: 23.3008 - output_1_loss: 12.9272 - val_loss: 33.5475 - val_output_0_loss: 21.6257 - val_output_1_loss: 11.9219\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.4675 1.6888 (0.3599, 9.2493) - mae: 1.5676 1.0760 (0.2200, 5.8615) - mse: 9.2089 1.4262 (0.0648, 42.7744) - rmse: 1.7448 1.1942 (0.2545, 6.5402)\n",
      "\n",
      "Epoch 00019: val_loss improved from 34.23453 to 33.54755, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 20/1000\n",
      "84/84 [==============================] - 37s 438ms/step - loss: 35.4976 - output_0_loss: 22.8384 - output_1_loss: 12.6592 - val_loss: 31.7553 - val_output_0_loss: 20.7555 - val_output_1_loss: 10.9998\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.3572 1.5869 (0.2828, 10.2201) - mae: 1.4985 0.9700 (0.1800, 6.4003) - mse: 9.0123 1.2593 (0.0400, 52.2248) - rmse: 1.6668 1.1221 (0.2000, 7.2267)\n",
      "\n",
      "Epoch 00020: val_loss improved from 33.54755 to 31.75530, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 21/1000\n",
      "84/84 [==============================] - 36s 432ms/step - loss: 34.6835 - output_0_loss: 22.3039 - output_1_loss: 12.3796 - val_loss: 31.5623 - val_output_0_loss: 20.7261 - val_output_1_loss: 10.8361\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.3812 1.5126 (0.2680, 10.1522) - mae: 1.5199 0.9850 (0.1600, 6.3802) - mse: 9.8236 1.1442 (0.0359, 51.5332) - rmse: 1.6838 1.0696 (0.1895, 7.1787)\n",
      "\n",
      "Epoch 00021: val_loss improved from 31.75530 to 31.56227, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 22/1000\n",
      "84/84 [==============================] - 38s 451ms/step - loss: 34.4331 - output_0_loss: 22.1382 - output_1_loss: 12.2949 - val_loss: 33.7011 - val_output_0_loss: 21.2255 - val_output_1_loss: 12.4756\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.6841 1.9687 (0.4337, 9.6959) - mae: 1.7089 1.2636 (0.2600, 6.3152) - mse: 10.0134 1.9382 (0.0940, 47.0054) - rmse: 1.8980 1.3921 (0.3066, 6.8560)\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 31.56227\n",
      "Epoch 23/1000\n",
      "84/84 [==============================] - 36s 432ms/step - loss: 33.4564 - output_0_loss: 21.6183 - output_1_loss: 11.8381 - val_loss: 32.2479 - val_output_0_loss: 21.1458 - val_output_1_loss: 11.1021\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.4591 1.5720 (0.3574, 10.1499) - mae: 1.5582 1.0100 (0.2200, 6.4312) - mse: 10.2904 1.2356 (0.0639, 51.5107) - rmse: 1.7388 1.1116 (0.2527, 7.1771)\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 31.56227\n",
      "Epoch 24/1000\n",
      "84/84 [==============================] - 39s 460ms/step - loss: 32.8300 - output_0_loss: 21.2371 - output_1_loss: 11.5928 - val_loss: 31.0438 - val_output_0_loss: 19.8836 - val_output_1_loss: 11.1602\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.4771 1.7904 (0.3578, 9.7997) - mae: 1.5775 1.1300 (0.2200, 6.3867) - mse: 9.8173 1.6034 (0.0640, 48.0173) - rmse: 1.7516 1.2660 (0.2530, 6.9295)\n",
      "\n",
      "Epoch 00024: val_loss improved from 31.56227 to 31.04382, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 25/1000\n",
      "84/84 [==============================] - 36s 433ms/step - loss: 32.7696 - output_0_loss: 21.0972 - output_1_loss: 11.6724 - val_loss: 31.2296 - val_output_0_loss: 20.1222 - val_output_1_loss: 11.1074\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.5044 1.7067 (0.3578, 9.4923) - mae: 1.5896 1.0650 (0.2200, 6.1189) - mse: 11.3086 1.4568 (0.0640, 45.0523) - rmse: 1.7709 1.2068 (0.2530, 6.7121)\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 31.04382\n",
      "Epoch 26/1000\n",
      "84/84 [==============================] - 38s 448ms/step - loss: 32.0395 - output_0_loss: 20.7407 - output_1_loss: 11.2987 - val_loss: 30.3471 - val_output_0_loss: 19.8620 - val_output_1_loss: 10.4851\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.2988 1.5510 (0.2800, 9.3042) - mae: 1.4648 0.9600 (0.1600, 5.9230) - mse: 9.8792 1.2030 (0.0392, 43.2838) - rmse: 1.6255 1.0967 (0.1980, 6.5790)\n",
      "\n",
      "Epoch 00026: val_loss improved from 31.04382 to 30.34709, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 27/1000\n",
      "84/84 [==============================] - 37s 436ms/step - loss: 31.9804 - output_0_loss: 20.6739 - output_1_loss: 11.3065 - val_loss: 29.5350 - val_output_0_loss: 19.3067 - val_output_1_loss: 10.2283\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.3520 1.6384 (0.3019, 9.1816) - mae: 1.4912 1.0200 (0.1934, 5.8805) - mse: 9.5087 1.3422 (0.0456, 42.1506) - rmse: 1.6631 1.1585 (0.2135, 6.4923)\n",
      "\n",
      "Epoch 00027: val_loss improved from 30.34709 to 29.53500, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 28/1000\n",
      "84/84 [==============================] - 36s 433ms/step - loss: 31.4567 - output_0_loss: 20.2615 - output_1_loss: 11.1952 - val_loss: 29.7951 - val_output_0_loss: 19.2182 - val_output_1_loss: 10.5769\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.4159 1.7000 (0.3688, 9.3529) - mae: 1.5340 1.0524 (0.2246, 5.9261) - mse: 9.2212 1.4450 (0.0680, 43.7382) - rmse: 1.7083 1.2021 (0.2608, 6.6135)\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 29.53500\n",
      "Epoch 29/1000\n",
      "84/84 [==============================] - 37s 439ms/step - loss: 30.8867 - output_0_loss: 19.9155 - output_1_loss: 10.9712 - val_loss: 27.9875 - val_output_0_loss: 17.9795 - val_output_1_loss: 10.0080\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.3088 1.4228 (0.2561, 9.9297) - mae: 1.4655 0.8750 (0.1600, 6.1777) - mse: 10.3172 1.0128 (0.0328, 49.2995) - rmse: 1.6326 1.0061 (0.1811, 7.0214)\n",
      "\n",
      "Epoch 00029: val_loss improved from 29.53500 to 27.98748, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 30/1000\n",
      "84/84 [==============================] - 36s 431ms/step - loss: 30.5568 - output_0_loss: 19.5680 - output_1_loss: 10.9887 - val_loss: 29.2291 - val_output_0_loss: 18.2186 - val_output_1_loss: 11.0105\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.4682 1.8510 (0.4078, 9.3251) - mae: 1.5708 1.1288 (0.2600, 5.8609) - mse: 8.6105 1.7134 (0.0831, 43.4784) - rmse: 1.7453 1.3089 (0.2883, 6.5938)\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 27.98748\n",
      "Epoch 31/1000\n",
      "84/84 [==============================] - 37s 439ms/step - loss: 30.3501 - output_0_loss: 19.3069 - output_1_loss: 11.0432 - val_loss: 28.3343 - val_output_0_loss: 18.0650 - val_output_1_loss: 10.2693\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.3604 1.6818 (0.3688, 8.4739) - mae: 1.4967 1.0650 (0.2200, 5.4556) - mse: 8.4616 1.4146 (0.0680, 35.9034) - rmse: 1.6690 1.1892 (0.2608, 5.9919)\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 27.98748\n",
      "Epoch 32/1000\n",
      "84/84 [==============================] - 36s 433ms/step - loss: 29.3488 - output_0_loss: 18.6776 - output_1_loss: 10.6712 - val_loss: 27.2635 - val_output_0_loss: 17.1144 - val_output_1_loss: 10.1492\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.3183 1.6729 (0.3794, 8.6848) - mae: 1.4721 1.0300 (0.2400, 5.5602) - mse: 7.9809 1.3994 (0.0720, 37.7126) - rmse: 1.6393 1.1829 (0.2683, 6.1411)\n",
      "\n",
      "Epoch 00032: val_loss improved from 27.98748 to 27.26354, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 33/1000\n",
      "84/84 [==============================] - 36s 427ms/step - loss: 28.7776 - output_0_loss: 18.3406 - output_1_loss: 10.4369 - val_loss: 25.8893 - val_output_0_loss: 16.4950 - val_output_1_loss: 9.3944\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1377 1.5077 (0.2828, 8.0232) - mae: 1.3503 0.9300 (0.1800, 5.0089) - mse: 6.7004 1.1366 (0.0400, 32.1863) - rmse: 1.5116 1.0661 (0.2000, 5.6733)\n",
      "\n",
      "Epoch 00033: val_loss improved from 27.26354 to 25.88934, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 34/1000\n",
      "84/84 [==============================] - 37s 440ms/step - loss: 28.7866 - output_0_loss: 18.2213 - output_1_loss: 10.5654 - val_loss: 26.8944 - val_output_0_loss: 16.8720 - val_output_1_loss: 10.0224\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.2792 1.6146 (0.3124, 8.7828) - mae: 1.4508 1.0232 (0.2000, 5.6163) - mse: 7.3323 1.3036 (0.0488, 38.5689) - rmse: 1.6116 1.1417 (0.2209, 6.2104)\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 25.88934\n",
      "Epoch 35/1000\n",
      "84/84 [==============================] - 36s 430ms/step - loss: 28.2948 - output_0_loss: 17.8997 - output_1_loss: 10.3951 - val_loss: 25.8282 - val_output_0_loss: 16.1785 - val_output_1_loss: 9.6497\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.2717 1.5446 (0.3225, 8.9360) - mae: 1.4466 0.9650 (0.2000, 5.8210) - mse: 9.0839 1.1930 (0.0520, 39.9267) - rmse: 1.6064 1.0922 (0.2280, 6.3187)\n",
      "\n",
      "Epoch 00035: val_loss improved from 25.88934 to 25.82818, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 36/1000\n",
      "84/84 [==============================] - 37s 437ms/step - loss: 28.0417 - output_0_loss: 17.8107 - output_1_loss: 10.2310 - val_loss: 27.1758 - val_output_0_loss: 17.0971 - val_output_1_loss: 10.0787\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.3641 1.6627 (0.3298, 9.3636) - mae: 1.5036 1.0550 (0.2002, 5.8570) - mse: 10.4434 1.3824 (0.0544, 43.8382) - rmse: 1.6716 1.1757 (0.2332, 6.6210)\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 25.82818\n",
      "Epoch 37/1000\n",
      "84/84 [==============================] - 37s 436ms/step - loss: 27.7761 - output_0_loss: 17.6275 - output_1_loss: 10.1487 - val_loss: 25.9174 - val_output_0_loss: 16.2299 - val_output_1_loss: 9.6875\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.2649 1.5122 (0.3418, 8.4805) - mae: 1.4378 0.9598 (0.2200, 5.4369) - mse: 7.6866 1.1438 (0.0584, 35.9597) - rmse: 1.6015 1.0693 (0.2417, 5.9966)\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 25.82818\n",
      "Epoch 38/1000\n",
      "84/84 [==============================] - 37s 435ms/step - loss: 27.7834 - output_0_loss: 17.5491 - output_1_loss: 10.2343 - val_loss: 26.3035 - val_output_0_loss: 16.1929 - val_output_1_loss: 10.1106\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.3693 1.7248 (0.4000, 9.0377) - mae: 1.5009 1.1100 (0.2600, 5.5607) - mse: 8.2670 1.4874 (0.0800, 40.8405) - rmse: 1.6754 1.2196 (0.2828, 6.3906)\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 25.82818\n",
      "Epoch 39/1000\n",
      "84/84 [==============================] - 36s 431ms/step - loss: 27.0519 - output_0_loss: 17.1430 - output_1_loss: 9.9089 - val_loss: 24.9869 - val_output_0_loss: 15.7215 - val_output_1_loss: 9.2654\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1999 1.4296 (0.2561, 8.7746) - mae: 1.3970 0.8900 (0.1600, 5.8204) - mse: 8.3837 1.0219 (0.0328, 38.4968) - rmse: 1.5556 1.0109 (0.1811, 6.2046)\n",
      "\n",
      "Epoch 00039: val_loss improved from 25.82818 to 24.98689, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 40/1000\n",
      "84/84 [==============================] - 36s 425ms/step - loss: 26.7758 - output_0_loss: 16.8934 - output_1_loss: 9.8824 - val_loss: 25.1324 - val_output_0_loss: 15.5244 - val_output_1_loss: 9.6080\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.2387 1.5925 (0.3298, 8.6371) - mae: 1.4217 1.0050 (0.2000, 5.5239) - mse: 7.7559 1.2684 (0.0544, 37.2994) - rmse: 1.5830 1.1261 (0.2332, 6.1073)\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 24.98689\n",
      "Epoch 41/1000\n",
      "84/84 [==============================] - 37s 436ms/step - loss: 27.0517 - output_0_loss: 17.0191 - output_1_loss: 10.0327 - val_loss: 25.6311 - val_output_0_loss: 15.7648 - val_output_1_loss: 9.8663\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.3161 1.6895 (0.3688, 8.6807) - mae: 1.4777 1.0600 (0.2400, 5.4763) - mse: 8.0801 1.4275 (0.0680, 37.6771) - rmse: 1.6377 1.1947 (0.2608, 6.1382)\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 24.98689\n",
      "Epoch 42/1000\n",
      "84/84 [==============================] - 36s 430ms/step - loss: 26.3593 - output_0_loss: 16.6328 - output_1_loss: 9.7265 - val_loss: 25.4601 - val_output_0_loss: 15.7807 - val_output_1_loss: 9.6794\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.2864 1.6483 (0.3771, 8.7076) - mae: 1.4512 1.0600 (0.2400, 5.5352) - mse: 7.4931 1.3590 (0.0711, 37.9109) - rmse: 1.6167 1.1655 (0.2667, 6.1572)\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 24.98689\n",
      "Epoch 43/1000\n",
      "84/84 [==============================] - 37s 437ms/step - loss: 26.1169 - output_0_loss: 16.4863 - output_1_loss: 9.6306 - val_loss: 24.1999 - val_output_0_loss: 15.1075 - val_output_1_loss: 9.0924\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1454 1.5793 (0.3299, 8.1887) - mae: 1.3618 0.9950 (0.2000, 5.0903) - mse: 6.7527 1.2472 (0.0544, 33.5275) - rmse: 1.5171 1.1168 (0.2332, 5.7903)\n",
      "\n",
      "Epoch 00043: val_loss improved from 24.98689 to 24.19985, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 44/1000\n",
      "84/84 [==============================] - 37s 437ms/step - loss: 26.1351 - output_0_loss: 16.4880 - output_1_loss: 9.6471 - val_loss: 24.6663 - val_output_0_loss: 15.2169 - val_output_1_loss: 9.4494\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.2662 1.5930 (0.3441, 9.0216) - mae: 1.4416 1.0000 (0.2200, 5.3801) - mse: 9.4024 1.2688 (0.0592, 40.6944) - rmse: 1.6025 1.1264 (0.2433, 6.3792)\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 24.19985\n",
      "Epoch 45/1000\n",
      "84/84 [==============================] - 36s 426ms/step - loss: 26.1036 - output_0_loss: 16.4691 - output_1_loss: 9.6344 - val_loss: 24.0527 - val_output_0_loss: 14.9412 - val_output_1_loss: 9.1115\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1609 1.5443 (0.2885, 8.4917) - mae: 1.3703 0.9750 (0.1800, 5.1454) - mse: 7.0354 1.1924 (0.0416, 36.0546) - rmse: 1.5280 1.0920 (0.2040, 6.0046)\n",
      "\n",
      "Epoch 00045: val_loss improved from 24.19985 to 24.05269, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 46/1000\n",
      "84/84 [==============================] - 36s 431ms/step - loss: 25.4013 - output_0_loss: 16.0410 - output_1_loss: 9.3603 - val_loss: 25.3949 - val_output_0_loss: 15.6740 - val_output_1_loss: 9.7208\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.3342 1.7185 (0.3599, 8.3114) - mae: 1.4827 1.1000 (0.2200, 5.2387) - mse: 9.4777 1.4766 (0.0648, 34.5395) - rmse: 1.6505 1.2151 (0.2545, 5.8770)\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 24.05269\n",
      "Epoch 47/1000\n",
      "84/84 [==============================] - 37s 445ms/step - loss: 25.5021 - output_0_loss: 16.0803 - output_1_loss: 9.4218 - val_loss: 24.1083 - val_output_0_loss: 14.9174 - val_output_1_loss: 9.1909\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1553 1.5892 (0.3418, 8.0893) - mae: 1.3719 1.0000 (0.2102, 5.0540) - mse: 6.5669 1.2630 (0.0584, 32.7184) - rmse: 1.5240 1.1238 (0.2417, 5.7200)\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 24.05269\n",
      "Epoch 48/1000\n",
      "84/84 [==============================] - 37s 438ms/step - loss: 25.5172 - output_0_loss: 16.0328 - output_1_loss: 9.4844 - val_loss: 23.1121 - val_output_0_loss: 14.3926 - val_output_1_loss: 8.7195\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0971 1.4919 (0.3225, 8.3684) - mae: 1.3320 0.9400 (0.2000, 5.1044) - mse: 7.0043 1.1130 (0.0520, 35.0153) - rmse: 1.4829 1.0549 (0.2280, 5.9174)\n",
      "\n",
      "Epoch 00048: val_loss improved from 24.05269 to 23.11213, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 49/1000\n",
      "84/84 [==============================] - 37s 442ms/step - loss: 25.0371 - output_0_loss: 15.7235 - output_1_loss: 9.3136 - val_loss: 24.1281 - val_output_0_loss: 14.7389 - val_output_1_loss: 9.3892\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.2604 1.6745 (0.3686, 8.8023) - mae: 1.4326 1.0700 (0.2200, 5.4898) - mse: 8.2241 1.4020 (0.0679, 38.7402) - rmse: 1.5983 1.1840 (0.2606, 6.2242)\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 23.11213\n",
      "Epoch 50/1000\n",
      "84/84 [==============================] - 38s 453ms/step - loss: 25.3023 - output_0_loss: 15.8816 - output_1_loss: 9.4206 - val_loss: 23.5782 - val_output_0_loss: 14.6633 - val_output_1_loss: 8.9150\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1346 1.4894 (0.2912, 8.5451) - mae: 1.3561 0.9450 (0.1800, 5.2940) - mse: 7.8894 1.1092 (0.0424, 36.5095) - rmse: 1.5094 1.0532 (0.2059, 6.0423)\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 23.11213\n",
      "Epoch 51/1000\n",
      "84/84 [==============================] - 36s 430ms/step - loss: 24.6325 - output_0_loss: 15.4597 - output_1_loss: 9.1728 - val_loss: 23.9902 - val_output_0_loss: 14.9290 - val_output_1_loss: 9.0612\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.2603 1.4258 (0.3043, 9.6832) - mae: 1.4386 0.9050 (0.1800, 6.2555) - mse: 10.8905 1.0164 (0.0463, 46.8818) - rmse: 1.5983 1.0082 (0.2152, 6.8470)\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 23.11213\n",
      "Epoch 52/1000\n",
      "84/84 [==============================] - 36s 429ms/step - loss: 24.5932 - output_0_loss: 15.4139 - output_1_loss: 9.1793 - val_loss: 23.3211 - val_output_0_loss: 14.5146 - val_output_1_loss: 8.8066\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1051 1.4979 (0.3298, 7.9410) - mae: 1.3375 0.9500 (0.2200, 5.0805) - mse: 6.2994 1.1230 (0.0544, 31.5298) - rmse: 1.4886 1.0592 (0.2332, 5.6151)\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 23.11213\n",
      "Epoch 53/1000\n",
      "84/84 [==============================] - 37s 439ms/step - loss: 24.4972 - output_0_loss: 15.3395 - output_1_loss: 9.1577 - val_loss: 23.3745 - val_output_0_loss: 14.4302 - val_output_1_loss: 8.9444\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1963 1.5329 (0.3225, 8.5852) - mae: 1.3976 0.9764 (0.2000, 5.1800) - mse: 8.5287 1.1750 (0.0520, 36.8528) - rmse: 1.5530 1.0839 (0.2280, 6.0706)\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 23.11213\n",
      "Epoch 54/1000\n",
      "84/84 [==============================] - 37s 439ms/step - loss: 24.2490 - output_0_loss: 15.1862 - output_1_loss: 9.0628 - val_loss: 23.0001 - val_output_0_loss: 14.4470 - val_output_1_loss: 8.5530\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0674 1.3797 (0.3225, 8.3340) - mae: 1.3123 0.8800 (0.2000, 5.2952) - mse: 7.1019 0.9518 (0.0520, 34.7281) - rmse: 1.4619 0.9756 (0.2280, 5.8931)\n",
      "\n",
      "Epoch 00054: val_loss improved from 23.11213 to 23.00005, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 55/1000\n",
      "84/84 [==============================] - 36s 431ms/step - loss: 24.1420 - output_0_loss: 15.1348 - output_1_loss: 9.0072 - val_loss: 23.3374 - val_output_0_loss: 14.3737 - val_output_1_loss: 8.9637\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1930 1.5028 (0.2828, 8.9387) - mae: 1.4058 0.9450 (0.1800, 5.6410) - mse: 9.5300 1.1301 (0.0400, 39.9500) - rmse: 1.5507 1.0627 (0.2000, 6.3206)\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 23.00005\n",
      "Epoch 56/1000\n",
      "84/84 [==============================] - 36s 431ms/step - loss: 24.3240 - output_0_loss: 15.1555 - output_1_loss: 9.1685 - val_loss: 22.1473 - val_output_0_loss: 13.7772 - val_output_1_loss: 8.3701\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0417 1.4050 (0.2828, 8.0775) - mae: 1.3005 0.8920 (0.1800, 5.1405) - mse: 6.9901 0.9878 (0.0400, 32.6227) - rmse: 1.4437 0.9935 (0.1999, 5.7116)\n",
      "\n",
      "Epoch 00056: val_loss improved from 23.00005 to 22.14727, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 57/1000\n",
      "84/84 [==============================] - 37s 443ms/step - loss: 23.8181 - output_0_loss: 14.9160 - output_1_loss: 8.9021 - val_loss: 21.8968 - val_output_0_loss: 13.7181 - val_output_1_loss: 8.1787\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0142 1.3802 (0.2530, 8.2194) - mae: 1.2852 0.8750 (0.1600, 5.3408) - mse: 7.0189 0.9530 (0.0320, 33.7800) - rmse: 1.4243 0.9760 (0.1789, 5.8120)\n",
      "\n",
      "Epoch 00057: val_loss improved from 22.14727 to 21.89685, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 58/1000\n",
      "84/84 [==============================] - 37s 441ms/step - loss: 23.8923 - output_0_loss: 14.9164 - output_1_loss: 8.9760 - val_loss: 23.3203 - val_output_0_loss: 14.3906 - val_output_1_loss: 8.9297\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.2115 1.6453 (0.3774, 7.8507) - mae: 1.4076 1.0400 (0.2400, 5.1202) - mse: 7.6644 1.3536 (0.0712, 30.8171) - rmse: 1.5638 1.1634 (0.2668, 5.5513)\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 21.89685\n",
      "Epoch 59/1000\n",
      "84/84 [==============================] - 36s 429ms/step - loss: 23.6902 - output_0_loss: 14.7419 - output_1_loss: 8.9483 - val_loss: 21.3828 - val_output_0_loss: 13.4360 - val_output_1_loss: 7.9467\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9952 1.4070 (0.2883, 7.9155) - mae: 1.2698 0.8950 (0.1800, 5.0208) - mse: 6.9062 0.9908 (0.0416, 31.3273) - rmse: 1.4108 0.9949 (0.2039, 5.5971)\n",
      "\n",
      "Epoch 00059: val_loss improved from 21.89685 to 21.38276, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 60/1000\n",
      "84/84 [==============================] - 36s 433ms/step - loss: 23.8840 - output_0_loss: 14.8495 - output_1_loss: 9.0345 - val_loss: 22.3370 - val_output_0_loss: 13.5681 - val_output_1_loss: 8.7689\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1069 1.5415 (0.3225, 7.9597) - mae: 1.3432 0.9800 (0.2000, 5.0019) - mse: 6.2964 1.1889 (0.0520, 31.6786) - rmse: 1.4898 1.0900 (0.2280, 5.6284)\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 21.38276\n",
      "Epoch 61/1000\n",
      "84/84 [==============================] - 36s 431ms/step - loss: 23.5599 - output_0_loss: 14.6243 - output_1_loss: 8.9356 - val_loss: 22.5179 - val_output_0_loss: 13.6904 - val_output_1_loss: 8.8275\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1389 1.4857 (0.3225, 8.2284) - mae: 1.3602 0.9450 (0.2000, 5.1255) - mse: 6.8528 1.1038 (0.0520, 33.8533) - rmse: 1.5124 1.0506 (0.2280, 5.8184)\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 21.38276\n",
      "Epoch 62/1000\n",
      "84/84 [==============================] - 36s 426ms/step - loss: 23.2600 - output_0_loss: 14.4451 - output_1_loss: 8.8148 - val_loss: 22.5158 - val_output_0_loss: 13.7257 - val_output_1_loss: 8.7902\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1719 1.6186 (0.3578, 8.4451) - mae: 1.3789 1.0099 (0.2200, 5.2005) - mse: 6.9185 1.3100 (0.0640, 35.6595) - rmse: 1.5358 1.1445 (0.2530, 5.9716)\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 21.38276\n",
      "Epoch 63/1000\n",
      "84/84 [==============================] - 36s 429ms/step - loss: 23.2859 - output_0_loss: 14.4457 - output_1_loss: 8.8403 - val_loss: 22.4812 - val_output_0_loss: 13.6144 - val_output_1_loss: 8.8668\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1842 1.5479 (0.3288, 8.6467) - mae: 1.3907 0.9600 (0.2000, 5.4806) - mse: 8.2117 1.1980 (0.0541, 37.3829) - rmse: 1.5445 1.0945 (0.2325, 6.1142)\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 21.38276\n",
      "Epoch 64/1000\n",
      "84/84 [==============================] - 37s 437ms/step - loss: 23.2301 - output_0_loss: 14.3938 - output_1_loss: 8.8364 - val_loss: 22.6211 - val_output_0_loss: 13.6931 - val_output_1_loss: 8.9280\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1820 1.5436 (0.3392, 7.9860) - mae: 1.3890 0.9700 (0.2102, 5.2005) - mse: 8.8466 1.1914 (0.0575, 31.8881) - rmse: 1.5429 1.0915 (0.2398, 5.6470)\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 21.38276\n",
      "Epoch 65/1000\n",
      "84/84 [==============================] - 37s 435ms/step - loss: 23.1962 - output_0_loss: 14.4127 - output_1_loss: 8.7835 - val_loss: 21.7911 - val_output_0_loss: 13.2051 - val_output_1_loss: 8.5860\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1448 1.5359 (0.3200, 8.1133) - mae: 1.3671 0.9800 (0.2000, 5.1141) - mse: 8.0415 1.1794 (0.0512, 32.9131) - rmse: 1.5166 1.0860 (0.2263, 5.7370)\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 21.38276\n",
      "Epoch 66/1000\n",
      "84/84 [==============================] - 37s 436ms/step - loss: 23.0572 - output_0_loss: 14.3043 - output_1_loss: 8.7528 - val_loss: 21.6831 - val_output_0_loss: 13.2582 - val_output_1_loss: 8.4249\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1150 1.4080 (0.2912, 8.8736) - mae: 1.3483 0.8800 (0.1800, 5.6167) - mse: 8.0206 0.9912 (0.0424, 39.3708) - rmse: 1.4955 0.9956 (0.2059, 6.2746)\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 21.38276\n",
      "Epoch 67/1000\n",
      "84/84 [==============================] - 37s 436ms/step - loss: 23.1063 - output_0_loss: 14.2693 - output_1_loss: 8.8369 - val_loss: 21.9234 - val_output_0_loss: 13.3561 - val_output_1_loss: 8.5673\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1693 1.5441 (0.3124, 7.9288) - mae: 1.3785 0.9699 (0.2000, 5.1207) - mse: 8.2048 1.1922 (0.0488, 31.4331) - rmse: 1.5339 1.0919 (0.2209, 5.6065)\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 21.38276\n",
      "Epoch 68/1000\n",
      "84/84 [==============================] - 37s 442ms/step - loss: 22.4958 - output_0_loss: 13.9027 - output_1_loss: 8.5931 - val_loss: 24.8953 - val_output_0_loss: 14.3747 - val_output_1_loss: 10.5205\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.5135 1.9181 (0.4833, 8.6142) - mae: 1.5871 1.1550 (0.3000, 5.5298) - mse: 8.3189 1.8404 (0.1168, 37.1026) - rmse: 1.7773 1.3563 (0.3417, 6.0912)\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 21.38276\n",
      "Epoch 69/1000\n",
      "84/84 [==============================] - 36s 430ms/step - loss: 22.7062 - output_0_loss: 14.0784 - output_1_loss: 8.6278 - val_loss: 20.8831 - val_output_0_loss: 12.9359 - val_output_1_loss: 7.9472\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9535 1.3367 (0.2912, 7.8769) - mae: 1.2418 0.8550 (0.1800, 4.9226) - mse: 5.8035 0.8938 (0.0424, 31.0228) - rmse: 1.3813 0.9452 (0.2059, 5.5698)\n",
      "\n",
      "Epoch 00069: val_loss improved from 21.38276 to 20.88308, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 70/1000\n",
      "84/84 [==============================] - 36s 434ms/step - loss: 22.3257 - output_0_loss: 13.8838 - output_1_loss: 8.4419 - val_loss: 21.3218 - val_output_0_loss: 13.1119 - val_output_1_loss: 8.2099\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0392 1.4641 (0.2912, 8.1208) - mae: 1.3013 0.9250 (0.2000, 5.1000) - mse: 7.4080 1.0718 (0.0424, 32.9739) - rmse: 1.4419 1.0353 (0.2059, 5.7423)\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 20.88308\n",
      "Epoch 71/1000\n",
      "84/84 [==============================] - 37s 439ms/step - loss: 22.2405 - output_0_loss: 13.7427 - output_1_loss: 8.4977 - val_loss: 21.1677 - val_output_0_loss: 12.9617 - val_output_1_loss: 8.2060\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0442 1.4375 (0.3046, 8.1711) - mae: 1.3001 0.9200 (0.2000, 5.1565) - mse: 6.5090 1.0338 (0.0464, 33.3838) - rmse: 1.4455 1.0165 (0.2154, 5.7779)\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 20.88308\n",
      "Epoch 72/1000\n",
      "84/84 [==============================] - 36s 432ms/step - loss: 22.1561 - output_0_loss: 13.6844 - output_1_loss: 8.4717 - val_loss: 20.9412 - val_output_0_loss: 12.6946 - val_output_1_loss: 8.2466\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0374 1.4445 (0.3046, 7.8858) - mae: 1.2931 0.9250 (0.1800, 4.8600) - mse: 6.1455 1.0434 (0.0464, 31.0931) - rmse: 1.4407 1.0214 (0.2154, 5.5761)\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 20.88308\n",
      "Epoch 73/1000\n",
      "84/84 [==============================] - 36s 431ms/step - loss: 22.1052 - output_0_loss: 13.6626 - output_1_loss: 8.4427 - val_loss: 20.3141 - val_output_0_loss: 12.3355 - val_output_1_loss: 7.9786\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0235 1.3186 (0.2797, 8.1756) - mae: 1.2847 0.8332 (0.1695, 5.3200) - mse: 7.6112 0.8694 (0.0391, 33.4201) - rmse: 1.4308 0.9324 (0.1978, 5.7810)\n",
      "\n",
      "Epoch 00073: val_loss improved from 20.88308 to 20.31411, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 74/1000\n",
      "84/84 [==============================] - 37s 435ms/step - loss: 21.9997 - output_0_loss: 13.6314 - output_1_loss: 8.3683 - val_loss: 21.7080 - val_output_0_loss: 12.9913 - val_output_1_loss: 8.7167\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1872 1.6536 (0.3298, 8.0845) - mae: 1.3870 1.0075 (0.2152, 5.0452) - mse: 6.5914 1.3673 (0.0544, 32.6799) - rmse: 1.5466 1.1692 (0.2332, 5.7166)\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 20.31411\n",
      "Epoch 75/1000\n",
      "84/84 [==============================] - 37s 437ms/step - loss: 21.9789 - output_0_loss: 13.5444 - output_1_loss: 8.4345 - val_loss: 20.1367 - val_output_0_loss: 12.3034 - val_output_1_loss: 7.8333\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0299 1.3677 (0.2883, 7.8613) - mae: 1.2938 0.8800 (0.1800, 4.9803) - mse: 8.3472 0.9354 (0.0416, 30.8997) - rmse: 1.4354 0.9671 (0.2039, 5.5587)\n",
      "\n",
      "Epoch 00075: val_loss improved from 20.31411 to 20.13670, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 76/1000\n",
      "84/84 [==============================] - 38s 447ms/step - loss: 21.9571 - output_0_loss: 13.6262 - output_1_loss: 8.3309 - val_loss: 22.4082 - val_output_0_loss: 13.3903 - val_output_1_loss: 9.0179\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.2622 1.6416 (0.3940, 8.7279) - mae: 1.4340 1.0300 (0.2400, 5.5422) - mse: 8.5892 1.3474 (0.0776, 38.0884) - rmse: 1.5996 1.1608 (0.2786, 6.1716)\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 20.13670\n",
      "Epoch 77/1000\n",
      "84/84 [==============================] - 37s 437ms/step - loss: 21.6988 - output_0_loss: 13.3888 - output_1_loss: 8.3101 - val_loss: 20.8603 - val_output_0_loss: 12.6163 - val_output_1_loss: 8.2439\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0925 1.4289 (0.2683, 8.3448) - mae: 1.3324 0.9050 (0.1800, 5.2536) - mse: 7.4967 1.0216 (0.0360, 34.8182) - rmse: 1.4796 1.0104 (0.1897, 5.9007)\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 20.13670\n",
      "Epoch 78/1000\n",
      "84/84 [==============================] - 37s 441ms/step - loss: 21.8760 - output_0_loss: 13.4284 - output_1_loss: 8.4476 - val_loss: 20.9109 - val_output_0_loss: 12.6246 - val_output_1_loss: 8.2863\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0659 1.4888 (0.2884, 8.4326) - mae: 1.3126 0.9500 (0.1800, 5.2812) - mse: 7.0569 1.1082 (0.0416, 35.5551) - rmse: 1.4608 1.0527 (0.2040, 5.9628)\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 20.13670\n",
      "Epoch 79/1000\n",
      "84/84 [==============================] - 37s 438ms/step - loss: 21.6533 - output_0_loss: 13.3155 - output_1_loss: 8.3379 - val_loss: 21.2207 - val_output_0_loss: 12.6144 - val_output_1_loss: 8.6062\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1465 1.5165 (0.3225, 8.0063) - mae: 1.3607 0.9600 (0.2100, 5.2146) - mse: 6.9474 1.1502 (0.0520, 32.0501) - rmse: 1.5178 1.0723 (0.2280, 5.6613)\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 20.13670\n",
      "Epoch 80/1000\n",
      "84/84 [==============================] - 38s 448ms/step - loss: 21.6879 - output_0_loss: 13.3568 - output_1_loss: 8.3311 - val_loss: 20.0740 - val_output_0_loss: 12.2135 - val_output_1_loss: 7.8605\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9974 1.3392 (0.2800, 7.9045) - mae: 1.2757 0.8500 (0.1800, 5.0015) - mse: 7.0633 0.8968 (0.0392, 31.2407) - rmse: 1.4124 0.9470 (0.1980, 5.5893)\n",
      "\n",
      "Epoch 00080: val_loss improved from 20.13670 to 20.07396, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 81/1000\n",
      "84/84 [==============================] - 36s 431ms/step - loss: 21.4028 - output_0_loss: 13.1408 - output_1_loss: 8.2620 - val_loss: 20.5629 - val_output_0_loss: 12.3049 - val_output_1_loss: 8.2580\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1141 1.4257 (0.2828, 8.4598) - mae: 1.3479 0.8888 (0.1800, 5.3406) - mse: 9.2452 1.0164 (0.0400, 35.7839) - rmse: 1.4949 1.0081 (0.2000, 5.9820)\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 20.07396\n",
      "Epoch 82/1000\n",
      "84/84 [==============================] - 37s 444ms/step - loss: 21.4506 - output_0_loss: 13.1473 - output_1_loss: 8.3032 - val_loss: 20.7358 - val_output_0_loss: 12.4380 - val_output_1_loss: 8.2979\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1006 1.5444 (0.3200, 8.2573) - mae: 1.3394 0.9450 (0.2000, 5.2864) - mse: 7.3512 1.1927 (0.0512, 34.0912) - rmse: 1.4853 1.0921 (0.2263, 5.8388)\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 20.07396\n",
      "Epoch 83/1000\n",
      "84/84 [==============================] - 36s 434ms/step - loss: 21.2519 - output_0_loss: 13.0418 - output_1_loss: 8.2101 - val_loss: 20.9195 - val_output_0_loss: 12.5711 - val_output_1_loss: 8.3485\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0924 1.5880 (0.3578, 8.0864) - mae: 1.3259 1.0318 (0.2200, 5.1663) - mse: 6.2332 1.2622 (0.0640, 32.6949) - rmse: 1.4796 1.1229 (0.2530, 5.7179)\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 20.07396\n",
      "Epoch 84/1000\n",
      "84/84 [==============================] - 38s 455ms/step - loss: 21.2660 - output_0_loss: 13.0358 - output_1_loss: 8.2303 - val_loss: 20.6113 - val_output_0_loss: 12.1088 - val_output_1_loss: 8.5025\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1832 1.5752 (0.3297, 7.9988) - mae: 1.3823 0.9950 (0.2200, 5.2000) - mse: 8.7444 1.2408 (0.0543, 31.9907) - rmse: 1.5438 1.1138 (0.2331, 5.6560)\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 20.07396\n",
      "Epoch 85/1000\n",
      "84/84 [==============================] - 37s 436ms/step - loss: 21.1764 - output_0_loss: 13.0023 - output_1_loss: 8.1741 - val_loss: 21.7001 - val_output_0_loss: 12.8387 - val_output_1_loss: 8.8614\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.2403 1.6123 (0.3688, 8.7561) - mae: 1.4238 0.9900 (0.2400, 5.5128) - mse: 7.9807 1.2998 (0.0680, 38.3348) - rmse: 1.5841 1.1401 (0.2608, 6.1915)\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 20.07396\n",
      "Epoch 86/1000\n",
      "84/84 [==============================] - 37s 444ms/step - loss: 21.3305 - output_0_loss: 13.0735 - output_1_loss: 8.2571 - val_loss: 20.9975 - val_output_0_loss: 12.5892 - val_output_1_loss: 8.4083\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1471 1.5419 (0.3574, 7.7213) - mae: 1.3679 0.9800 (0.2200, 5.0010) - mse: 8.4241 1.1888 (0.0639, 29.8089) - rmse: 1.5182 1.0903 (0.2527, 5.4598)\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 20.07396\n",
      "Epoch 87/1000\n",
      "84/84 [==============================] - 36s 429ms/step - loss: 20.9098 - output_0_loss: 12.8076 - output_1_loss: 8.1022 - val_loss: 22.0480 - val_output_0_loss: 13.2128 - val_output_1_loss: 8.8352\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.2069 1.7587 (0.3225, 7.8746) - mae: 1.3997 1.0800 (0.2149, 4.9004) - mse: 7.4796 1.5468 (0.0520, 31.0044) - rmse: 1.5605 1.2436 (0.2280, 5.5682)\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 20.07396\n",
      "Epoch 88/1000\n",
      "84/84 [==============================] - 37s 445ms/step - loss: 20.7822 - output_0_loss: 12.7123 - output_1_loss: 8.0698 - val_loss: 20.1143 - val_output_0_loss: 11.9454 - val_output_1_loss: 8.1689\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0421 1.4607 (0.2884, 8.2327) - mae: 1.3019 0.9338 (0.1800, 5.2607) - mse: 7.1107 1.0668 (0.0416, 33.8891) - rmse: 1.4440 1.0328 (0.2040, 5.8214)\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 20.07396\n",
      "Epoch 89/1000\n",
      "84/84 [==============================] - 37s 442ms/step - loss: 20.9069 - output_0_loss: 12.7939 - output_1_loss: 8.1130 - val_loss: 19.7480 - val_output_0_loss: 11.8679 - val_output_1_loss: 7.8801\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0334 1.4377 (0.3046, 7.9336) - mae: 1.2979 0.9200 (0.1800, 5.1406) - mse: 7.6111 1.0336 (0.0464, 31.4712) - rmse: 1.4378 1.0166 (0.2154, 5.6099)\n",
      "\n",
      "Epoch 00089: val_loss improved from 20.07396 to 19.74802, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 90/1000\n",
      "84/84 [==============================] - 36s 431ms/step - loss: 20.7913 - output_0_loss: 12.7393 - output_1_loss: 8.0520 - val_loss: 21.3771 - val_output_0_loss: 12.5899 - val_output_1_loss: 8.7872\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1698 1.5766 (0.3688, 7.7702) - mae: 1.3767 0.9950 (0.2304, 5.1614) - mse: 7.3713 1.2434 (0.0680, 30.1881) - rmse: 1.5343 1.1148 (0.2608, 5.4944)\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 19.74802\n",
      "Epoch 91/1000\n",
      "84/84 [==============================] - 37s 440ms/step - loss: 20.9527 - output_0_loss: 12.7633 - output_1_loss: 8.1894 - val_loss: 20.4598 - val_output_0_loss: 11.9614 - val_output_1_loss: 8.4985\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1036 1.5255 (0.3046, 7.9250) - mae: 1.3437 0.9413 (0.2000, 5.0470) - mse: 7.5137 1.1636 (0.0464, 31.4025) - rmse: 1.4875 1.0787 (0.2154, 5.6038)\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 19.74802\n",
      "Epoch 92/1000\n",
      "84/84 [==============================] - 36s 430ms/step - loss: 21.0494 - output_0_loss: 12.7849 - output_1_loss: 8.2645 - val_loss: 19.9020 - val_output_0_loss: 11.7999 - val_output_1_loss: 8.1020\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1028 1.5142 (0.3200, 7.7502) - mae: 1.3412 0.9200 (0.2000, 4.7600) - mse: 8.1409 1.1464 (0.0512, 30.0326) - rmse: 1.4869 1.0707 (0.2263, 5.4802)\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 19.74802\n",
      "Epoch 93/1000\n",
      "84/84 [==============================] - 37s 440ms/step - loss: 20.4810 - output_0_loss: 12.5279 - output_1_loss: 7.9531 - val_loss: 21.2771 - val_output_0_loss: 12.3474 - val_output_1_loss: 8.9297\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.2498 1.7108 (0.4118, 7.7579) - mae: 1.4229 1.0600 (0.2600, 4.9404) - mse: 7.4708 1.4644 (0.0848, 30.0925) - rmse: 1.5909 1.2097 (0.2912, 5.4857)\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 19.74802\n",
      "Epoch 94/1000\n",
      "84/84 [==============================] - 38s 448ms/step - loss: 20.1621 - output_0_loss: 12.3245 - output_1_loss: 7.8376 - val_loss: 20.1539 - val_output_0_loss: 12.0184 - val_output_1_loss: 8.1354\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0727 1.3801 (0.2683, 8.2700) - mae: 1.3190 0.8800 (0.1800, 5.2005) - mse: 7.6990 0.9524 (0.0360, 34.1972) - rmse: 1.4656 0.9759 (0.1897, 5.8478)\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 19.74802\n",
      "Epoch 95/1000\n",
      "84/84 [==============================] - 38s 451ms/step - loss: 20.5240 - output_0_loss: 12.5081 - output_1_loss: 8.0160 - val_loss: 19.6974 - val_output_0_loss: 11.5514 - val_output_1_loss: 8.1459\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1298 1.4441 (0.3046, 8.4614) - mae: 1.3593 0.9050 (0.2000, 5.4529) - mse: 9.2720 1.0428 (0.0464, 35.7979) - rmse: 1.5060 1.0212 (0.2154, 5.9831)\n",
      "\n",
      "Epoch 00095: val_loss improved from 19.74802 to 19.69737, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 96/1000\n",
      "84/84 [==============================] - 36s 431ms/step - loss: 20.2563 - output_0_loss: 12.3657 - output_1_loss: 7.8906 - val_loss: 19.3080 - val_output_0_loss: 11.4439 - val_output_1_loss: 7.8641\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0528 1.4796 (0.3046, 7.9770) - mae: 1.3103 0.9003 (0.2000, 5.0811) - mse: 8.4231 1.0947 (0.0464, 31.8163) - rmse: 1.4516 1.0462 (0.2154, 5.6406)\n",
      "\n",
      "Epoch 00096: val_loss improved from 19.69737 to 19.30804, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 97/1000\n",
      "84/84 [==============================] - 37s 445ms/step - loss: 20.2197 - output_0_loss: 12.3288 - output_1_loss: 7.8909 - val_loss: 19.3001 - val_output_0_loss: 11.3684 - val_output_1_loss: 7.9317\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0892 1.4591 (0.3124, 8.2614) - mae: 1.3338 0.9100 (0.2000, 5.1610) - mse: 9.2298 1.0646 (0.0488, 34.1253) - rmse: 1.4773 1.0317 (0.2209, 5.8417)\n",
      "\n",
      "Epoch 00097: val_loss improved from 19.30804 to 19.30013, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 98/1000\n",
      "84/84 [==============================] - 36s 432ms/step - loss: 20.1704 - output_0_loss: 12.2713 - output_1_loss: 7.8991 - val_loss: 18.9900 - val_output_0_loss: 11.2956 - val_output_1_loss: 7.6944\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9571 1.2827 (0.2561, 8.2571) - mae: 1.2472 0.8000 (0.1600, 5.1600) - mse: 6.8539 0.8228 (0.0328, 34.0903) - rmse: 1.3839 0.9070 (0.1811, 5.8387)\n",
      "\n",
      "Epoch 00098: val_loss improved from 19.30013 to 18.98999, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 99/1000\n",
      "84/84 [==============================] - 37s 442ms/step - loss: 20.4063 - output_0_loss: 12.4325 - output_1_loss: 7.9738 - val_loss: 18.9671 - val_output_0_loss: 11.2732 - val_output_1_loss: 7.6939\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0150 1.3277 (0.2560, 8.6439) - mae: 1.2841 0.8400 (0.1600, 5.5015) - mse: 8.1402 0.8814 (0.0328, 37.3587) - rmse: 1.4248 0.9388 (0.1811, 6.1122)\n",
      "\n",
      "Epoch 00099: val_loss improved from 18.98999 to 18.96707, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 100/1000\n",
      "84/84 [==============================] - 37s 441ms/step - loss: 20.5583 - output_0_loss: 12.4616 - output_1_loss: 8.0967 - val_loss: 18.9155 - val_output_0_loss: 11.2551 - val_output_1_loss: 7.6604\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9398 1.4021 (0.2883, 7.5563) - mae: 1.2334 0.9000 (0.1800, 4.8425) - mse: 6.1102 0.9830 (0.0416, 28.5489) - rmse: 1.3717 0.9914 (0.2039, 5.3431)\n",
      "\n",
      "Epoch 00100: val_loss improved from 18.96707 to 18.91548, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 101/1000\n",
      "84/84 [==============================] - 36s 432ms/step - loss: 20.3342 - output_0_loss: 12.3658 - output_1_loss: 7.9684 - val_loss: 19.9672 - val_output_0_loss: 11.8191 - val_output_1_loss: 8.1481\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0967 1.5042 (0.2828, 8.5503) - mae: 1.3415 0.9500 (0.1800, 5.4210) - mse: 8.6163 1.1314 (0.0400, 36.5539) - rmse: 1.4826 1.0636 (0.2000, 6.0460)\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 18.91548\n",
      "Epoch 102/1000\n",
      "84/84 [==============================] - 37s 439ms/step - loss: 19.9768 - output_0_loss: 12.1334 - output_1_loss: 7.8434 - val_loss: 19.0769 - val_output_0_loss: 11.3566 - val_output_1_loss: 7.7203\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0089 1.4096 (0.3046, 7.8476) - mae: 1.2831 0.9000 (0.1800, 5.0223) - mse: 6.6820 0.9936 (0.0464, 30.7927) - rmse: 1.4205 0.9968 (0.2154, 5.5491)\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 18.91548\n",
      "Epoch 103/1000\n",
      "84/84 [==============================] - 37s 436ms/step - loss: 19.9961 - output_0_loss: 12.1594 - output_1_loss: 7.8367 - val_loss: 18.7981 - val_output_0_loss: 11.2354 - val_output_1_loss: 7.5628\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9400 1.3097 (0.2828, 7.5769) - mae: 1.2324 0.8100 (0.1646, 4.8535) - mse: 6.3017 0.8578 (0.0400, 28.7052) - rmse: 1.3718 0.9261 (0.1999, 5.3577)\n",
      "\n",
      "Epoch 00103: val_loss improved from 18.91548 to 18.79814, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 104/1000\n",
      "84/84 [==============================] - 37s 442ms/step - loss: 19.9901 - output_0_loss: 12.1448 - output_1_loss: 7.8453 - val_loss: 19.6498 - val_output_0_loss: 11.6987 - val_output_1_loss: 7.9511\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0444 1.4320 (0.3122, 7.6594) - mae: 1.3058 0.8950 (0.2000, 5.0209) - mse: 7.4263 1.0254 (0.0487, 29.3336) - rmse: 1.4456 1.0126 (0.2208, 5.4160)\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 18.79814\n",
      "Epoch 105/1000\n",
      "84/84 [==============================] - 36s 430ms/step - loss: 20.1101 - output_0_loss: 12.2266 - output_1_loss: 7.8834 - val_loss: 18.5231 - val_output_0_loss: 11.0644 - val_output_1_loss: 7.4587\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9427 1.3139 (0.2683, 7.7308) - mae: 1.2395 0.8350 (0.1600, 4.9415) - mse: 6.7571 0.8632 (0.0360, 29.8827) - rmse: 1.3737 0.9290 (0.1897, 5.4665)\n",
      "\n",
      "Epoch 00105: val_loss improved from 18.79814 to 18.52313, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 106/1000\n",
      "84/84 [==============================] - 36s 433ms/step - loss: 19.9156 - output_0_loss: 12.0116 - output_1_loss: 7.9040 - val_loss: 18.8338 - val_output_0_loss: 11.0412 - val_output_1_loss: 7.7926\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0376 1.4461 (0.3124, 8.0848) - mae: 1.3006 0.9050 (0.2000, 5.1239) - mse: 8.1521 1.0456 (0.0488, 32.6822) - rmse: 1.4408 1.0225 (0.2209, 5.7168)\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 18.52313\n",
      "Epoch 107/1000\n",
      "84/84 [==============================] - 37s 444ms/step - loss: 20.0076 - output_0_loss: 12.1290 - output_1_loss: 7.8786 - val_loss: 17.8683 - val_output_0_loss: 10.6620 - val_output_1_loss: 7.2062\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.8687 1.2637 (0.2400, 7.5677) - mae: 1.1891 0.8076 (0.1400, 4.9241) - mse: 6.5470 0.7987 (0.0288, 28.6348) - rmse: 1.3214 0.8936 (0.1697, 5.3511)\n",
      "\n",
      "Epoch 00107: val_loss improved from 18.52313 to 17.86829, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 108/1000\n",
      "84/84 [==============================] - 36s 434ms/step - loss: 19.7728 - output_0_loss: 12.0028 - output_1_loss: 7.7699 - val_loss: 18.3621 - val_output_0_loss: 10.8499 - val_output_1_loss: 7.5122\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9446 1.3253 (0.2884, 7.8063) - mae: 1.2372 0.8449 (0.1800, 4.9157) - mse: 6.2849 0.8786 (0.0416, 30.4689) - rmse: 1.3751 0.9371 (0.2040, 5.5199)\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 17.86829\n",
      "Epoch 109/1000\n",
      "84/84 [==============================] - 37s 436ms/step - loss: 19.5876 - output_0_loss: 11.8894 - output_1_loss: 7.6982 - val_loss: 19.4944 - val_output_0_loss: 11.7085 - val_output_1_loss: 7.7859\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9791 1.3632 (0.3043, 7.6935) - mae: 1.2626 0.8597 (0.1800, 4.8292) - mse: 6.3165 0.9292 (0.0463, 29.5953) - rmse: 1.3994 0.9639 (0.2152, 5.4402)\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 17.86829\n",
      "Epoch 110/1000\n",
      "84/84 [==============================] - 37s 440ms/step - loss: 19.8355 - output_0_loss: 12.1068 - output_1_loss: 7.7286 - val_loss: 19.7977 - val_output_0_loss: 11.6883 - val_output_1_loss: 8.1095\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0920 1.5178 (0.3440, 8.0357) - mae: 1.3220 0.9600 (0.2106, 5.1001) - mse: 6.2516 1.1518 (0.0592, 32.2863) - rmse: 1.4793 1.0732 (0.2432, 5.6821)\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 17.86829\n",
      "Epoch 111/1000\n",
      "84/84 [==============================] - 37s 437ms/step - loss: 19.4159 - output_0_loss: 11.7736 - output_1_loss: 7.6423 - val_loss: 19.8075 - val_output_0_loss: 11.4943 - val_output_1_loss: 8.3132\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1135 1.5724 (0.3399, 7.6777) - mae: 1.3423 0.9700 (0.2200, 5.0003) - mse: 6.3938 1.2368 (0.0578, 29.4738) - rmse: 1.4944 1.1119 (0.2403, 5.4290)\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 17.86829\n",
      "Epoch 112/1000\n",
      "84/84 [==============================] - 37s 440ms/step - loss: 19.5716 - output_0_loss: 11.8509 - output_1_loss: 7.7207 - val_loss: 18.2271 - val_output_0_loss: 10.7366 - val_output_1_loss: 7.4905\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9623 1.3992 (0.2884, 7.3955) - mae: 1.2480 0.8550 (0.1800, 4.7003) - mse: 6.9255 0.9789 (0.0416, 27.3463) - rmse: 1.3876 0.9894 (0.2040, 5.2294)\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 17.86829\n",
      "Epoch 113/1000\n",
      "84/84 [==============================] - 36s 433ms/step - loss: 19.5378 - output_0_loss: 11.7896 - output_1_loss: 7.7482 - val_loss: 18.4619 - val_output_0_loss: 10.8295 - val_output_1_loss: 7.6324\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9741 1.4081 (0.2884, 7.6821) - mae: 1.2524 0.8749 (0.1800, 4.7936) - mse: 6.0438 0.9913 (0.0416, 29.5076) - rmse: 1.3959 0.9956 (0.2040, 5.4321)\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 17.86829\n",
      "Epoch 114/1000\n",
      "84/84 [==============================] - 37s 440ms/step - loss: 19.1712 - output_0_loss: 11.6557 - output_1_loss: 7.5155 - val_loss: 17.7747 - val_output_0_loss: 10.4638 - val_output_1_loss: 7.3109\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9180 1.3665 (0.3046, 7.3117) - mae: 1.2193 0.8450 (0.1800, 4.7204) - mse: 6.1948 0.9336 (0.0464, 26.7306) - rmse: 1.3562 0.9662 (0.2154, 5.1702)\n",
      "\n",
      "Epoch 00114: val_loss improved from 17.86829 to 17.77473, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 115/1000\n",
      "84/84 [==============================] - 37s 446ms/step - loss: 19.4763 - output_0_loss: 11.7891 - output_1_loss: 7.6872 - val_loss: 19.5289 - val_output_0_loss: 11.2604 - val_output_1_loss: 8.2685\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1015 1.5137 (0.3418, 7.7220) - mae: 1.3321 0.9450 (0.2200, 4.9605) - mse: 6.2420 1.1457 (0.0584, 29.8146) - rmse: 1.4860 1.0703 (0.2417, 5.4603)\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 17.77473\n",
      "Epoch 116/1000\n",
      "84/84 [==============================] - 36s 430ms/step - loss: 19.4713 - output_0_loss: 11.7603 - output_1_loss: 7.7109 - val_loss: 18.3361 - val_output_0_loss: 10.6376 - val_output_1_loss: 7.6986\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9993 1.4500 (0.3224, 7.3741) - mae: 1.2702 0.9200 (0.2000, 4.8679) - mse: 6.9610 1.0512 (0.0520, 27.1885) - rmse: 1.4137 1.0253 (0.2280, 5.2143)\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 17.77473\n",
      "Epoch 117/1000\n",
      "84/84 [==============================] - 36s 434ms/step - loss: 19.1999 - output_0_loss: 11.5896 - output_1_loss: 7.6103 - val_loss: 18.3242 - val_output_0_loss: 10.6985 - val_output_1_loss: 7.6256\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9877 1.3685 (0.2683, 7.6011) - mae: 1.2613 0.8750 (0.1600, 4.8400) - mse: 6.5507 0.9364 (0.0360, 28.8882) - rmse: 1.4055 0.9677 (0.1897, 5.3748)\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 17.77473\n",
      "Epoch 118/1000\n",
      "84/84 [==============================] - 37s 441ms/step - loss: 19.1021 - output_0_loss: 11.5433 - output_1_loss: 7.5588 - val_loss: 17.9142 - val_output_0_loss: 10.6731 - val_output_1_loss: 7.2411\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.8837 1.2493 (0.2263, 7.5628) - mae: 1.1985 0.7900 (0.1400, 4.7205) - mse: 6.3299 0.7804 (0.0256, 28.5982) - rmse: 1.3320 0.8834 (0.1600, 5.3477)\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 17.77473\n",
      "Epoch 119/1000\n",
      "84/84 [==============================] - 36s 424ms/step - loss: 18.9636 - output_0_loss: 11.4521 - output_1_loss: 7.5115 - val_loss: 19.4591 - val_output_0_loss: 11.2263 - val_output_1_loss: 8.2328\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0727 1.4875 (0.3260, 8.0660) - mae: 1.3160 0.9500 (0.2000, 5.2220) - mse: 6.3640 1.1064 (0.0531, 32.5303) - rmse: 1.4656 1.0518 (0.2305, 5.7035)\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 17.77473\n",
      "Epoch 120/1000\n",
      "84/84 [==============================] - 37s 441ms/step - loss: 18.8235 - output_0_loss: 11.3610 - output_1_loss: 7.4626 - val_loss: 18.6383 - val_output_0_loss: 10.9170 - val_output_1_loss: 7.7213\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0468 1.4295 (0.3124, 7.8413) - mae: 1.3009 0.9100 (0.2000, 5.0213) - mse: 7.6953 1.0218 (0.0488, 30.7432) - rmse: 1.4473 1.0108 (0.2209, 5.5447)\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 17.77473\n",
      "Epoch 121/1000\n",
      "84/84 [==============================] - 37s 440ms/step - loss: 18.9777 - output_0_loss: 11.4568 - output_1_loss: 7.5210 - val_loss: 18.6115 - val_output_0_loss: 10.8368 - val_output_1_loss: 7.7747\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0437 1.5126 (0.2885, 7.7410) - mae: 1.3036 0.9500 (0.1800, 4.8412) - mse: 7.3736 1.1440 (0.0416, 29.9612) - rmse: 1.4451 1.0695 (0.2040, 5.4737)\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 17.77473\n",
      "Epoch 122/1000\n",
      "84/84 [==============================] - 37s 435ms/step - loss: 19.2930 - output_0_loss: 11.6387 - output_1_loss: 7.6543 - val_loss: 17.6177 - val_output_0_loss: 10.4479 - val_output_1_loss: 7.1698\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.8910 1.2859 (0.2529, 7.7039) - mae: 1.2083 0.8150 (0.1600, 4.8401) - mse: 6.9061 0.8276 (0.0320, 29.6751) - rmse: 1.3372 0.9093 (0.1789, 5.4475)\n",
      "\n",
      "Epoch 00122: val_loss improved from 17.77473 to 17.61774, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 123/1000\n",
      "84/84 [==============================] - 37s 445ms/step - loss: 19.1263 - output_0_loss: 11.5082 - output_1_loss: 7.6182 - val_loss: 19.6752 - val_output_0_loss: 11.4114 - val_output_1_loss: 8.2639\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1305 1.6658 (0.3578, 7.2458) - mae: 1.3488 1.0250 (0.2200, 4.7812) - mse: 7.4038 1.3874 (0.0640, 26.2511) - rmse: 1.5065 1.1779 (0.2530, 5.1236)\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 17.61774\n",
      "Epoch 124/1000\n",
      "84/84 [==============================] - 36s 431ms/step - loss: 18.8846 - output_0_loss: 11.4035 - output_1_loss: 7.4810 - val_loss: 19.0156 - val_output_0_loss: 11.2316 - val_output_1_loss: 7.7840\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0339 1.4528 (0.3392, 7.4653) - mae: 1.2915 0.9200 (0.2200, 4.8414) - mse: 6.3887 1.0554 (0.0575, 27.8651) - rmse: 1.4382 1.0273 (0.2398, 5.2787)\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 17.61774\n",
      "Epoch 125/1000\n",
      "84/84 [==============================] - 37s 442ms/step - loss: 19.0953 - output_0_loss: 11.4594 - output_1_loss: 7.6359 - val_loss: 18.4038 - val_output_0_loss: 10.8654 - val_output_1_loss: 7.5384\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9067 1.3194 (0.2828, 7.7794) - mae: 1.2115 0.8206 (0.1800, 4.7259) - mse: 5.9452 0.8704 (0.0400, 30.2599) - rmse: 1.3482 0.9329 (0.2000, 5.5009)\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 17.61774\n",
      "Epoch 126/1000\n",
      "84/84 [==============================] - 37s 436ms/step - loss: 18.9713 - output_0_loss: 11.4024 - output_1_loss: 7.5688 - val_loss: 18.4361 - val_output_0_loss: 10.7933 - val_output_1_loss: 7.6428\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9854 1.3976 (0.2884, 7.6985) - mae: 1.2629 0.8862 (0.1800, 4.7807) - mse: 6.2725 0.9770 (0.0416, 29.6332) - rmse: 1.4039 0.9882 (0.2040, 5.4436)\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 17.61774\n",
      "Epoch 127/1000\n",
      "84/84 [==============================] - 37s 436ms/step - loss: 18.6961 - output_0_loss: 11.2703 - output_1_loss: 7.4258 - val_loss: 18.2229 - val_output_0_loss: 10.5576 - val_output_1_loss: 7.6653\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0159 1.3756 (0.2828, 7.9337) - mae: 1.2835 0.8600 (0.1800, 5.0863) - mse: 7.6235 0.9462 (0.0400, 31.4715) - rmse: 1.4254 0.9727 (0.2000, 5.6099)\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 17.61774\n",
      "Epoch 128/1000\n",
      "84/84 [==============================] - 36s 433ms/step - loss: 18.8355 - output_0_loss: 11.3510 - output_1_loss: 7.4845 - val_loss: 19.1017 - val_output_0_loss: 11.2245 - val_output_1_loss: 7.8771\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0405 1.4663 (0.3225, 7.2924) - mae: 1.2943 0.9100 (0.2000, 4.7400) - mse: 6.2669 1.0750 (0.0520, 26.5894) - rmse: 1.4428 1.0368 (0.2280, 5.1565)\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 17.61774\n",
      "Epoch 129/1000\n",
      "84/84 [==============================] - 37s 442ms/step - loss: 18.5501 - output_0_loss: 11.1622 - output_1_loss: 7.3879 - val_loss: 18.2628 - val_output_0_loss: 10.6381 - val_output_1_loss: 7.6247\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0028 1.4647 (0.2800, 8.0838) - mae: 1.2702 0.9100 (0.1600, 5.0401) - mse: 7.1816 1.0727 (0.0392, 32.6744) - rmse: 1.4162 1.0357 (0.1980, 5.7161)\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 17.61774\n",
      "Epoch 130/1000\n",
      "84/84 [==============================] - 37s 440ms/step - loss: 18.5550 - output_0_loss: 11.1670 - output_1_loss: 7.3880 - val_loss: 18.7347 - val_output_0_loss: 10.8021 - val_output_1_loss: 7.9326\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0775 1.4899 (0.3298, 7.7836) - mae: 1.3197 0.9223 (0.2200, 5.0142) - mse: 6.6828 1.1101 (0.0544, 30.2926) - rmse: 1.4690 1.0535 (0.2332, 5.5039)\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 17.61774\n",
      "Epoch 131/1000\n",
      "84/84 [==============================] - 36s 429ms/step - loss: 18.6593 - output_0_loss: 11.2637 - output_1_loss: 7.3957 - val_loss: 18.6886 - val_output_0_loss: 10.8533 - val_output_1_loss: 7.8353\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0243 1.4762 (0.3124, 7.1286) - mae: 1.2840 0.9300 (0.2000, 4.6600) - mse: 6.0509 1.0896 (0.0488, 25.4083) - rmse: 1.4314 1.0438 (0.2209, 5.0407)\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 17.61774\n",
      "Epoch 132/1000\n",
      "84/84 [==============================] - 37s 445ms/step - loss: 18.8238 - output_0_loss: 11.2995 - output_1_loss: 7.5243 - val_loss: 17.2709 - val_output_0_loss: 10.0751 - val_output_1_loss: 7.1958\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9035 1.2571 (0.2563, 7.5145) - mae: 1.2103 0.7900 (0.1600, 4.9003) - mse: 6.1526 0.7902 (0.0329, 28.2342) - rmse: 1.3460 0.8889 (0.1813, 5.3136)\n",
      "\n",
      "Epoch 00132: val_loss improved from 17.61774 to 17.27093, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 133/1000\n",
      "84/84 [==============================] - 36s 427ms/step - loss: 18.6867 - output_0_loss: 11.2437 - output_1_loss: 7.4431 - val_loss: 17.4259 - val_output_0_loss: 10.0561 - val_output_1_loss: 7.3697\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9895 1.3929 (0.3124, 7.4615) - mae: 1.2674 0.8950 (0.2000, 4.7777) - mse: 8.2742 0.9707 (0.0488, 27.8375) - rmse: 1.4068 0.9849 (0.2209, 5.2761)\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 17.27093\n",
      "Epoch 134/1000\n",
      "84/84 [==============================] - 38s 450ms/step - loss: 18.5105 - output_0_loss: 11.1415 - output_1_loss: 7.3690 - val_loss: 17.6123 - val_output_0_loss: 10.3385 - val_output_1_loss: 7.2738\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9186 1.3585 (0.2561, 7.8621) - mae: 1.2195 0.8600 (0.1600, 4.9748) - mse: 6.4130 0.9230 (0.0328, 30.9060) - rmse: 1.3567 0.9606 (0.1811, 5.5593)\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 17.27093\n",
      "Epoch 135/1000\n",
      "84/84 [==============================] - 36s 433ms/step - loss: 18.8058 - output_0_loss: 11.3479 - output_1_loss: 7.4579 - val_loss: 18.3242 - val_output_0_loss: 10.6211 - val_output_1_loss: 7.7030\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0169 1.4175 (0.3124, 7.5530) - mae: 1.2779 0.8950 (0.2000, 4.7960) - mse: 6.3374 1.0049 (0.0488, 28.5243) - rmse: 1.4261 1.0023 (0.2209, 5.3408)\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 17.27093\n",
      "Epoch 136/1000\n",
      "84/84 [==============================] - 36s 430ms/step - loss: 18.6076 - output_0_loss: 11.1575 - output_1_loss: 7.4500 - val_loss: 18.0593 - val_output_0_loss: 10.5355 - val_output_1_loss: 7.5238\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9937 1.2964 (0.2683, 7.8977) - mae: 1.2741 0.8350 (0.1600, 5.0290) - mse: 9.6560 0.8404 (0.0360, 31.1870) - rmse: 1.4097 0.9167 (0.1897, 5.5845)\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 17.27093\n",
      "Epoch 137/1000\n",
      "84/84 [==============================] - 38s 449ms/step - loss: 18.5748 - output_0_loss: 11.1195 - output_1_loss: 7.4553 - val_loss: 17.7208 - val_output_0_loss: 10.1821 - val_output_1_loss: 7.5387\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0379 1.4228 (0.2912, 8.1715) - mae: 1.2950 0.9150 (0.1800, 5.1070) - mse: 7.9229 1.0122 (0.0424, 33.3867) - rmse: 1.4410 1.0061 (0.2059, 5.7781)\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 17.27093\n",
      "Epoch 138/1000\n",
      "84/84 [==============================] - 37s 443ms/step - loss: 18.3279 - output_0_loss: 11.0292 - output_1_loss: 7.2988 - val_loss: 17.5464 - val_output_0_loss: 10.0485 - val_output_1_loss: 7.4978\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9673 1.3796 (0.2828, 7.5559) - mae: 1.2514 0.8775 (0.1800, 4.8407) - mse: 6.1858 0.9516 (0.0400, 28.5459) - rmse: 1.3911 0.9755 (0.2000, 5.3428)\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 17.27093\n",
      "Epoch 139/1000\n",
      "84/84 [==============================] - 37s 435ms/step - loss: 18.0988 - output_0_loss: 10.9074 - output_1_loss: 7.1914 - val_loss: 18.2142 - val_output_0_loss: 10.3091 - val_output_1_loss: 7.9050\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0719 1.4830 (0.3200, 8.0532) - mae: 1.3166 0.9300 (0.2000, 5.1546) - mse: 6.8915 1.0996 (0.0512, 32.4268) - rmse: 1.4651 1.0486 (0.2263, 5.6944)\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 17.27093\n",
      "Epoch 140/1000\n",
      "84/84 [==============================] - 37s 440ms/step - loss: 18.1708 - output_0_loss: 10.9244 - output_1_loss: 7.2464 - val_loss: 18.0637 - val_output_0_loss: 10.2464 - val_output_1_loss: 7.8172\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0700 1.3982 (0.3122, 8.0189) - mae: 1.3197 0.8886 (0.2000, 5.1604) - mse: 8.4628 0.9778 (0.0487, 32.1513) - rmse: 1.4637 0.9887 (0.2208, 5.6702)\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 17.27093\n",
      "Epoch 141/1000\n",
      "84/84 [==============================] - 37s 444ms/step - loss: 18.3064 - output_0_loss: 11.0083 - output_1_loss: 7.2981 - val_loss: 17.1573 - val_output_0_loss: 9.9293 - val_output_1_loss: 7.2280\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.8938 1.2390 (0.2332, 7.7467) - mae: 1.2054 0.7950 (0.1400, 5.1003) - mse: 6.3033 0.7677 (0.0272, 30.0060) - rmse: 1.3391 0.8761 (0.1649, 5.4778)\n",
      "\n",
      "Epoch 00141: val_loss improved from 17.27093 to 17.15728, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 142/1000\n",
      "84/84 [==============================] - 36s 427ms/step - loss: 18.1247 - output_0_loss: 10.8430 - output_1_loss: 7.2816 - val_loss: 18.8331 - val_output_0_loss: 10.7677 - val_output_1_loss: 8.0654\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1258 1.4810 (0.3225, 8.1507) - mae: 1.3498 0.9200 (0.2000, 5.2103) - mse: 8.2497 1.0970 (0.0520, 33.2173) - rmse: 1.5032 1.0473 (0.2280, 5.7634)\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 17.15728\n",
      "Epoch 143/1000\n",
      "84/84 [==============================] - 37s 441ms/step - loss: 18.2405 - output_0_loss: 10.9220 - output_1_loss: 7.3185 - val_loss: 19.0521 - val_output_0_loss: 10.8736 - val_output_1_loss: 8.1785\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0911 1.3887 (0.3225, 8.2223) - mae: 1.3327 0.8950 (0.2000, 5.3004) - mse: 8.1439 0.9644 (0.0520, 33.8032) - rmse: 1.4786 0.9820 (0.2280, 5.8140)\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 17.15728\n",
      "Epoch 144/1000\n",
      "84/84 [==============================] - 36s 430ms/step - loss: 18.3270 - output_0_loss: 10.9855 - output_1_loss: 7.3415 - val_loss: 19.3267 - val_output_0_loss: 10.9811 - val_output_1_loss: 8.3457\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1640 1.5378 (0.3688, 7.9377) - mae: 1.3735 0.9884 (0.2399, 5.1805) - mse: 6.8730 1.1824 (0.0680, 31.5039) - rmse: 1.5302 1.0874 (0.2608, 5.6128)\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 17.15728\n",
      "Epoch 145/1000\n",
      "84/84 [==============================] - 37s 442ms/step - loss: 18.0884 - output_0_loss: 10.8887 - output_1_loss: 7.1997 - val_loss: 18.5165 - val_output_0_loss: 10.4706 - val_output_1_loss: 8.0459\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0556 1.5431 (0.3124, 7.8105) - mae: 1.3019 0.9650 (0.2000, 5.1042) - mse: 6.3475 1.1906 (0.0488, 30.5018) - rmse: 1.4535 1.0911 (0.2209, 5.5228)\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 17.15728\n",
      "Epoch 146/1000\n",
      "84/84 [==============================] - 37s 435ms/step - loss: 18.2830 - output_0_loss: 10.9775 - output_1_loss: 7.3055 - val_loss: 17.5504 - val_output_0_loss: 10.1755 - val_output_1_loss: 7.3749\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9399 1.3237 (0.2828, 7.6663) - mae: 1.2327 0.8300 (0.1800, 4.7800) - mse: 6.1716 0.8762 (0.0400, 29.3859) - rmse: 1.3718 0.9360 (0.2000, 5.4209)\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 17.15728\n",
      "Epoch 147/1000\n",
      "84/84 [==============================] - 37s 441ms/step - loss: 18.3043 - output_0_loss: 10.9568 - output_1_loss: 7.3475 - val_loss: 17.0205 - val_output_0_loss: 9.9563 - val_output_1_loss: 7.0642\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9016 1.3075 (0.2560, 7.6492) - mae: 1.2126 0.8210 (0.1600, 4.7010) - mse: 6.9291 0.8550 (0.0328, 29.2551) - rmse: 1.3446 0.9245 (0.1811, 5.4088)\n",
      "\n",
      "Epoch 00147: val_loss improved from 17.15728 to 17.02047, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 148/1000\n",
      "84/84 [==============================] - 36s 434ms/step - loss: 18.1917 - output_0_loss: 10.8837 - output_1_loss: 7.3080 - val_loss: 18.0170 - val_output_0_loss: 10.4401 - val_output_1_loss: 7.5769\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0010 1.3537 (0.2828, 7.6941) - mae: 1.2746 0.8700 (0.1800, 4.8536) - mse: 6.8724 0.9166 (0.0400, 29.5994) - rmse: 1.4150 0.9572 (0.2000, 5.4405)\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 17.02047\n",
      "Epoch 149/1000\n",
      "84/84 [==============================] - 36s 434ms/step - loss: 18.0309 - output_0_loss: 10.8311 - output_1_loss: 7.1998 - val_loss: 17.3946 - val_output_0_loss: 10.2250 - val_output_1_loss: 7.1695\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9015 1.3245 (0.2683, 7.5964) - mae: 1.2112 0.8500 (0.1800, 4.7642) - mse: 6.0821 0.8772 (0.0360, 28.8529) - rmse: 1.3445 0.9366 (0.1897, 5.3715)\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 17.02047\n",
      "Epoch 150/1000\n",
      "84/84 [==============================] - 36s 426ms/step - loss: 18.2391 - output_0_loss: 10.9549 - output_1_loss: 7.2842 - val_loss: 16.9033 - val_output_0_loss: 9.7990 - val_output_1_loss: 7.1043\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.8477 1.2252 (0.2332, 7.6195) - mae: 1.1767 0.7700 (0.1400, 4.8718) - mse: 6.2723 0.7506 (0.0272, 29.0286) - rmse: 1.3065 0.8663 (0.1649, 5.3878)\n",
      "\n",
      "Epoch 00150: val_loss improved from 17.02047 to 16.90330, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 151/1000\n",
      "84/84 [==============================] - 38s 448ms/step - loss: 17.9121 - output_0_loss: 10.7375 - output_1_loss: 7.1746 - val_loss: 16.3669 - val_output_0_loss: 9.5148 - val_output_1_loss: 6.8521\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.8518 1.2590 (0.2332, 7.4034) - mae: 1.1778 0.7850 (0.1400, 4.7000) - mse: 6.8059 0.7926 (0.0272, 27.4056) - rmse: 1.3094 0.8902 (0.1649, 5.2350)\n",
      "\n",
      "Epoch 00151: val_loss improved from 16.90330 to 16.36692, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 152/1000\n",
      "84/84 [==============================] - 36s 431ms/step - loss: 18.0686 - output_0_loss: 10.8030 - output_1_loss: 7.2656 - val_loss: 17.8027 - val_output_0_loss: 10.1227 - val_output_1_loss: 7.6800\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9577 1.3205 (0.2561, 7.6488) - mae: 1.2470 0.8500 (0.1600, 4.7615) - mse: 6.3983 0.8718 (0.0328, 29.2518) - rmse: 1.3843 0.9337 (0.1811, 5.4085)\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 16.36692\n",
      "Epoch 153/1000\n",
      "84/84 [==============================] - 36s 434ms/step - loss: 17.7308 - output_0_loss: 10.6208 - output_1_loss: 7.1100 - val_loss: 17.5118 - val_output_0_loss: 10.0373 - val_output_1_loss: 7.4745\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9877 1.3320 (0.2828, 8.0994) - mae: 1.2641 0.8200 (0.1800, 5.0103) - mse: 7.7489 0.8872 (0.0400, 32.8002) - rmse: 1.4055 0.9419 (0.2000, 5.7271)\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 16.36692\n",
      "Epoch 154/1000\n",
      "84/84 [==============================] - 37s 445ms/step - loss: 17.7394 - output_0_loss: 10.6350 - output_1_loss: 7.1044 - val_loss: 17.3988 - val_output_0_loss: 10.0608 - val_output_1_loss: 7.3380\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9238 1.3386 (0.2683, 7.3610) - mae: 1.2245 0.8300 (0.1605, 4.7180) - mse: 6.0097 0.8962 (0.0360, 27.0922) - rmse: 1.3604 0.9465 (0.1897, 5.2050)\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 16.36692\n",
      "Epoch 155/1000\n",
      "84/84 [==============================] - 37s 445ms/step - loss: 17.7673 - output_0_loss: 10.6441 - output_1_loss: 7.1232 - val_loss: 17.7212 - val_output_0_loss: 10.2070 - val_output_1_loss: 7.5142\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9491 1.3632 (0.2828, 7.5309) - mae: 1.2420 0.8510 (0.1800, 4.8205) - mse: 6.2017 0.9295 (0.0400, 28.3574) - rmse: 1.3782 0.9639 (0.2000, 5.3252)\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 16.36692\n",
      "Epoch 156/1000\n",
      "84/84 [==============================] - 36s 434ms/step - loss: 17.9703 - output_0_loss: 10.7510 - output_1_loss: 7.2194 - val_loss: 18.9668 - val_output_0_loss: 10.6888 - val_output_1_loss: 8.2779\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1314 1.6236 (0.3622, 7.4811) - mae: 1.3509 1.0100 (0.2400, 4.7605) - mse: 6.0327 1.3180 (0.0656, 27.9832) - rmse: 1.5071 1.1480 (0.2561, 5.2899)\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 16.36692\n",
      "Epoch 157/1000\n",
      "84/84 [==============================] - 36s 433ms/step - loss: 18.0488 - output_0_loss: 10.8532 - output_1_loss: 7.1957 - val_loss: 18.2214 - val_output_0_loss: 10.5433 - val_output_1_loss: 7.6781\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0023 1.4667 (0.3225, 7.8224) - mae: 1.2693 0.9350 (0.2000, 4.9489) - mse: 6.1301 1.0756 (0.0520, 30.5953) - rmse: 1.4158 1.0371 (0.2280, 5.5313)\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 16.36692\n",
      "Epoch 158/1000\n",
      "84/84 [==============================] - 38s 447ms/step - loss: 17.6482 - output_0_loss: 10.6091 - output_1_loss: 7.0390 - val_loss: 16.5291 - val_output_0_loss: 9.5057 - val_output_1_loss: 7.0234\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.8589 1.2992 (0.2561, 7.2877) - mae: 1.1811 0.8050 (0.1600, 4.6810) - mse: 5.7731 0.8450 (0.0328, 26.5553) - rmse: 1.3144 0.9187 (0.1811, 5.1532)\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 16.36692\n",
      "Epoch 159/1000\n",
      "84/84 [==============================] - 36s 425ms/step - loss: 17.8104 - output_0_loss: 10.6287 - output_1_loss: 7.1817 - val_loss: 16.5957 - val_output_0_loss: 9.7110 - val_output_1_loss: 6.8847\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.8194 1.1973 (0.2527, 7.3642) - mae: 1.1584 0.7450 (0.1600, 4.7947) - mse: 5.3068 0.7168 (0.0319, 27.1157) - rmse: 1.2865 0.8466 (0.1787, 5.2073)\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 16.36692\n",
      "Epoch 160/1000\n",
      "84/84 [==============================] - 36s 433ms/step - loss: 17.8381 - output_0_loss: 10.6767 - output_1_loss: 7.1614 - val_loss: 16.4807 - val_output_0_loss: 9.6110 - val_output_1_loss: 6.8697\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.8002 1.2463 (0.2415, 7.1658) - mae: 1.1455 0.7727 (0.1600, 4.5820) - mse: 5.2939 0.7768 (0.0292, 25.6746) - rmse: 1.2729 0.8813 (0.1707, 5.0670)\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 16.36692\n",
      "Epoch 161/1000\n",
      "84/84 [==============================] - 38s 450ms/step - loss: 17.4912 - output_0_loss: 10.5111 - output_1_loss: 6.9802 - val_loss: 18.8790 - val_output_0_loss: 10.6039 - val_output_1_loss: 8.2751\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1556 1.6138 (0.3688, 7.4844) - mae: 1.3648 1.0000 (0.2339, 4.7400) - mse: 7.4969 1.3024 (0.0680, 28.0084) - rmse: 1.5243 1.1411 (0.2608, 5.2923)\n",
      "\n",
      "Epoch 00161: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 16.36692\n",
      "Epoch 162/1000\n",
      "84/84 [==============================] - 35s 423ms/step - loss: 16.4513 - output_0_loss: 9.9220 - output_1_loss: 6.5293 - val_loss: 15.9561 - val_output_0_loss: 9.1780 - val_output_1_loss: 6.7781\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.8688 1.2812 (0.2683, 7.0882) - mae: 1.1899 0.8150 (0.1600, 4.5743) - mse: 6.7681 0.8211 (0.0360, 25.1214) - rmse: 1.3214 0.9059 (0.1897, 5.0121)\n",
      "\n",
      "Epoch 00162: val_loss improved from 16.36692 to 15.95612, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 163/1000\n",
      "84/84 [==============================] - 37s 439ms/step - loss: 16.1812 - output_0_loss: 9.8074 - output_1_loss: 6.3738 - val_loss: 16.4528 - val_output_0_loss: 9.3978 - val_output_1_loss: 7.0551\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9318 1.3756 (0.3046, 7.0756) - mae: 1.2261 0.8600 (0.1800, 4.6220) - mse: 6.8862 0.9462 (0.0464, 25.0323) - rmse: 1.3660 0.9727 (0.2154, 5.0032)\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 15.95612\n",
      "Epoch 164/1000\n",
      "84/84 [==============================] - 37s 439ms/step - loss: 16.0173 - output_0_loss: 9.7008 - output_1_loss: 6.3166 - val_loss: 16.1213 - val_output_0_loss: 9.2879 - val_output_1_loss: 6.8334\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.8629 1.3016 (0.2706, 6.8485) - mae: 1.1800 0.8250 (0.1700, 4.4400) - mse: 5.4783 0.8472 (0.0366, 23.4507) - rmse: 1.3173 0.9204 (0.1913, 4.8426)\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 15.95612\n",
      "Epoch 165/1000\n",
      "84/84 [==============================] - 37s 439ms/step - loss: 16.2336 - output_0_loss: 9.8543 - output_1_loss: 6.3793 - val_loss: 16.2107 - val_output_0_loss: 9.2447 - val_output_1_loss: 6.9660\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.8972 1.3302 (0.2883, 7.2586) - mae: 1.2028 0.8427 (0.1800, 4.6005) - mse: 5.5974 0.8848 (0.0416, 26.3437) - rmse: 1.3415 0.9406 (0.2039, 5.1326)\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 15.95612\n",
      "Epoch 166/1000\n",
      "84/84 [==============================] - 37s 444ms/step - loss: 15.9537 - output_0_loss: 9.7154 - output_1_loss: 6.2383 - val_loss: 16.6804 - val_output_0_loss: 9.4688 - val_output_1_loss: 7.2116\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9689 1.4205 (0.3200, 7.2772) - mae: 1.2483 0.8900 (0.2000, 4.6825) - mse: 6.4461 1.0090 (0.0512, 26.4787) - rmse: 1.3922 1.0044 (0.2263, 5.1457)\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 15.95612\n",
      "Epoch 167/1000\n",
      "84/84 [==============================] - 37s 436ms/step - loss: 15.7123 - output_0_loss: 9.5528 - output_1_loss: 6.1595 - val_loss: 15.5528 - val_output_0_loss: 8.9756 - val_output_1_loss: 6.5772\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.8028 1.2181 (0.2561, 7.1931) - mae: 1.1456 0.7600 (0.1600, 4.6417) - mse: 5.5291 0.7420 (0.0328, 25.8701) - rmse: 1.2748 0.8614 (0.1811, 5.0863)\n",
      "\n",
      "Epoch 00167: val_loss improved from 15.95612 to 15.55280, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 168/1000\n",
      "84/84 [==============================] - 37s 438ms/step - loss: 15.9103 - output_0_loss: 9.6882 - output_1_loss: 6.2221 - val_loss: 15.9039 - val_output_0_loss: 9.0859 - val_output_1_loss: 6.8180\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.8640 1.3155 (0.2683, 7.1404) - mae: 1.1846 0.8200 (0.1705, 4.5610) - mse: 5.8338 0.8653 (0.0360, 25.4929) - rmse: 1.3181 0.9302 (0.1897, 5.0491)\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 15.55280\n",
      "Epoch 169/1000\n",
      "84/84 [==============================] - 39s 465ms/step - loss: 15.8140 - output_0_loss: 9.6447 - output_1_loss: 6.1694 - val_loss: 15.8128 - val_output_0_loss: 9.0794 - val_output_1_loss: 6.7334\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.8538 1.2885 (0.2561, 7.2419) - mae: 1.1785 0.7900 (0.1600, 4.6610) - mse: 5.8164 0.8302 (0.0328, 26.2228) - rmse: 1.3108 0.9111 (0.1811, 5.1208)\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 15.55280\n",
      "Epoch 170/1000\n",
      "84/84 [==============================] - 37s 443ms/step - loss: 15.7737 - output_0_loss: 9.6196 - output_1_loss: 6.1540 - val_loss: 16.6083 - val_output_0_loss: 9.3930 - val_output_1_loss: 7.2153\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9734 1.4039 (0.3225, 7.3101) - mae: 1.2536 0.8738 (0.2000, 4.7200) - mse: 7.1324 0.9856 (0.0520, 26.7190) - rmse: 1.3954 0.9927 (0.2280, 5.1690)\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 15.55280\n",
      "Epoch 171/1000\n",
      "84/84 [==============================] - 37s 442ms/step - loss: 15.7107 - output_0_loss: 9.5674 - output_1_loss: 6.1433 - val_loss: 16.5120 - val_output_0_loss: 9.3880 - val_output_1_loss: 7.1240\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9668 1.3265 (0.2912, 7.5055) - mae: 1.2513 0.8400 (0.1800, 4.7414) - mse: 7.5838 0.8798 (0.0424, 28.1662) - rmse: 1.3907 0.9380 (0.2059, 5.3072)\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 15.55280\n",
      "Epoch 172/1000\n",
      "84/84 [==============================] - 37s 438ms/step - loss: 15.8893 - output_0_loss: 9.6673 - output_1_loss: 6.2220 - val_loss: 17.0201 - val_output_0_loss: 9.6110 - val_output_1_loss: 7.4090\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0103 1.4359 (0.3124, 7.4395) - mae: 1.2763 0.8986 (0.2000, 4.8605) - mse: 7.6567 1.0310 (0.0488, 27.6731) - rmse: 1.4215 1.0153 (0.2209, 5.2605)\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 15.55280\n",
      "Epoch 173/1000\n",
      "84/84 [==============================] - 36s 432ms/step - loss: 15.7164 - output_0_loss: 9.5844 - output_1_loss: 6.1321 - val_loss: 16.4453 - val_output_0_loss: 9.2695 - val_output_1_loss: 7.1757\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9658 1.3767 (0.2912, 7.2195) - mae: 1.2497 0.8800 (0.1800, 4.6800) - mse: 7.3577 0.9476 (0.0424, 26.0605) - rmse: 1.3900 0.9734 (0.2059, 5.1049)\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 15.55280\n",
      "Epoch 174/1000\n",
      "84/84 [==============================] - 37s 439ms/step - loss: 15.6719 - output_0_loss: 9.5503 - output_1_loss: 6.1216 - val_loss: 16.6043 - val_output_0_loss: 9.3367 - val_output_1_loss: 7.2676\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0130 1.3559 (0.3198, 7.4820) - mae: 1.2807 0.8550 (0.2000, 4.8577) - mse: 8.4015 0.9192 (0.0511, 27.9902) - rmse: 1.4234 0.9587 (0.2261, 5.2906)\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 15.55280\n",
      "Epoch 175/1000\n",
      "84/84 [==============================] - 36s 428ms/step - loss: 15.6581 - output_0_loss: 9.5709 - output_1_loss: 6.0872 - val_loss: 16.6561 - val_output_0_loss: 9.4070 - val_output_1_loss: 7.2491\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9918 1.3855 (0.3198, 7.3758) - mae: 1.2652 0.8800 (0.2000, 4.7816) - mse: 7.7385 0.9600 (0.0511, 27.2012) - rmse: 1.4084 0.9797 (0.2261, 5.2155)\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 15.55280\n",
      "Epoch 176/1000\n",
      "84/84 [==============================] - 37s 444ms/step - loss: 15.7383 - output_0_loss: 9.6230 - output_1_loss: 6.1153 - val_loss: 16.1210 - val_output_0_loss: 9.0865 - val_output_1_loss: 7.0345\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9436 1.3175 (0.2828, 7.6208) - mae: 1.2351 0.8300 (0.1800, 4.7210) - mse: 7.9888 0.8686 (0.0400, 29.0387) - rmse: 1.3743 0.9316 (0.2000, 5.3888)\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 15.55280\n",
      "Epoch 177/1000\n",
      "84/84 [==============================] - 37s 439ms/step - loss: 15.7513 - output_0_loss: 9.6413 - output_1_loss: 6.1101 - val_loss: 15.1176 - val_output_0_loss: 8.6558 - val_output_1_loss: 6.4618\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.8050 1.2250 (0.2400, 6.8926) - mae: 1.1486 0.7650 (0.1597, 4.3606) - mse: 7.0732 0.7504 (0.0288, 23.7542) - rmse: 1.2763 0.8662 (0.1697, 4.8738)\n",
      "\n",
      "Epoch 00177: val_loss improved from 15.55280 to 15.11760, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 178/1000\n",
      "84/84 [==============================] - 37s 438ms/step - loss: 15.6313 - output_0_loss: 9.5675 - output_1_loss: 6.0638 - val_loss: 16.1131 - val_output_0_loss: 9.1078 - val_output_1_loss: 7.0053\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9088 1.3383 (0.2884, 7.3635) - mae: 1.2095 0.8500 (0.1800, 4.6781) - mse: 6.1358 0.8956 (0.0416, 27.1108) - rmse: 1.3497 0.9464 (0.2040, 5.2068)\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 15.11760\n",
      "Epoch 179/1000\n",
      "84/84 [==============================] - 37s 439ms/step - loss: 15.4346 - output_0_loss: 9.4528 - output_1_loss: 5.9818 - val_loss: 15.8046 - val_output_0_loss: 8.8968 - val_output_1_loss: 6.9078\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.8877 1.3078 (0.2560, 7.4723) - mae: 1.1980 0.8250 (0.1600, 4.8563) - mse: 6.4249 0.8554 (0.0328, 27.9175) - rmse: 1.3348 0.9248 (0.1811, 5.2837)\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 15.11760\n",
      "Epoch 180/1000\n",
      "84/84 [==============================] - 37s 437ms/step - loss: 15.7179 - output_0_loss: 9.6206 - output_1_loss: 6.0974 - val_loss: 16.6428 - val_output_0_loss: 9.3532 - val_output_1_loss: 7.2896\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0066 1.3944 (0.2912, 7.4439) - mae: 1.2736 0.8650 (0.1800, 4.8800) - mse: 7.7369 0.9722 (0.0424, 27.7061) - rmse: 1.4189 0.9860 (0.2059, 5.2637)\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 15.11760\n",
      "Epoch 181/1000\n",
      "84/84 [==============================] - 37s 439ms/step - loss: 15.7093 - output_0_loss: 9.6063 - output_1_loss: 6.1030 - val_loss: 16.2839 - val_output_0_loss: 9.2132 - val_output_1_loss: 7.0707\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9535 1.3235 (0.2885, 7.5533) - mae: 1.2411 0.8300 (0.1800, 4.8410) - mse: 7.6278 0.8758 (0.0416, 28.5259) - rmse: 1.3813 0.9358 (0.2040, 5.3410)\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 15.11760\n",
      "Epoch 182/1000\n",
      "84/84 [==============================] - 37s 439ms/step - loss: 15.4754 - output_0_loss: 9.4911 - output_1_loss: 5.9843 - val_loss: 15.6355 - val_output_0_loss: 8.8892 - val_output_1_loss: 6.7462\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.8836 1.2361 (0.2530, 7.5613) - mae: 1.1963 0.7950 (0.1600, 4.8201) - mse: 7.2524 0.7640 (0.0320, 28.5869) - rmse: 1.3319 0.8741 (0.1789, 5.3467)\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 15.11760\n",
      "Epoch 183/1000\n",
      "84/84 [==============================] - 36s 432ms/step - loss: 15.5029 - output_0_loss: 9.4836 - output_1_loss: 6.0193 - val_loss: 15.9614 - val_output_0_loss: 9.0053 - val_output_1_loss: 6.9561\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9149 1.3209 (0.2911, 7.4674) - mae: 1.2135 0.8400 (0.1800, 4.8041) - mse: 6.4684 0.8724 (0.0424, 27.8812) - rmse: 1.3540 0.9340 (0.2059, 5.2803)\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 15.11760\n",
      "Epoch 184/1000\n",
      "84/84 [==============================] - 37s 436ms/step - loss: 15.6301 - output_0_loss: 9.5514 - output_1_loss: 6.0787 - val_loss: 16.4817 - val_output_0_loss: 9.1567 - val_output_1_loss: 7.3250\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0292 1.4222 (0.3224, 7.4695) - mae: 1.2884 0.8861 (0.2000, 4.8552) - mse: 8.3461 1.0114 (0.0520, 27.8964) - rmse: 1.4349 1.0057 (0.2280, 5.2817)\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 15.11760\n",
      "Epoch 185/1000\n",
      "84/84 [==============================] - 37s 439ms/step - loss: 15.5273 - output_0_loss: 9.5355 - output_1_loss: 5.9918 - val_loss: 15.3296 - val_output_0_loss: 8.6913 - val_output_1_loss: 6.6383\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.8328 1.2048 (0.2263, 7.2822) - mae: 1.1677 0.7673 (0.1400, 4.6186) - mse: 7.4346 0.7259 (0.0256, 26.5150) - rmse: 1.2960 0.8519 (0.1600, 5.1493)\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 15.11760\n",
      "Epoch 186/1000\n",
      "84/84 [==============================] - 38s 451ms/step - loss: 15.5003 - output_0_loss: 9.4982 - output_1_loss: 6.0021 - val_loss: 15.9646 - val_output_0_loss: 8.9379 - val_output_1_loss: 7.0266\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9155 1.3254 (0.2828, 7.3817) - mae: 1.2158 0.8300 (0.1800, 4.7204) - mse: 7.3729 0.8784 (0.0400, 27.2449) - rmse: 1.3545 0.9372 (0.2000, 5.2197)\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 15.11760\n",
      "Epoch 187/1000\n",
      "84/84 [==============================] - 37s 437ms/step - loss: 15.5129 - output_0_loss: 9.4874 - output_1_loss: 6.0255 - val_loss: 15.7517 - val_output_0_loss: 8.8721 - val_output_1_loss: 6.8796\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9065 1.3038 (0.2800, 7.4577) - mae: 1.2119 0.8400 (0.1600, 4.8210) - mse: 6.9166 0.8500 (0.0392, 27.8087) - rmse: 1.3481 0.9219 (0.1980, 5.2734)\n",
      "\n",
      "Epoch 00187: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 15.11760\n",
      "Epoch 188/1000\n",
      "84/84 [==============================] - 36s 430ms/step - loss: 15.2360 - output_0_loss: 9.3671 - output_1_loss: 5.8689 - val_loss: 15.8786 - val_output_0_loss: 8.9096 - val_output_1_loss: 6.9691\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9266 1.3096 (0.2884, 7.2539) - mae: 1.2243 0.8450 (0.1800, 4.7410) - mse: 7.4051 0.8576 (0.0416, 26.3094) - rmse: 1.3623 0.9261 (0.2040, 5.1293)\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 15.11760\n",
      "Epoch 189/1000\n",
      "84/84 [==============================] - 37s 441ms/step - loss: 15.1251 - output_0_loss: 9.2987 - output_1_loss: 5.8264 - val_loss: 15.6805 - val_output_0_loss: 8.8119 - val_output_1_loss: 6.8686\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9036 1.3154 (0.2800, 7.1583) - mae: 1.2106 0.8115 (0.1800, 4.6805) - mse: 7.4025 0.8652 (0.0392, 25.6210) - rmse: 1.3460 0.9301 (0.1980, 5.0617)\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 15.11760\n",
      "Epoch 190/1000\n",
      "84/84 [==============================] - 36s 433ms/step - loss: 15.2028 - output_0_loss: 9.3482 - output_1_loss: 5.8546 - val_loss: 15.8007 - val_output_0_loss: 8.8613 - val_output_1_loss: 6.9394\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9270 1.2943 (0.2883, 7.3335) - mae: 1.2247 0.8181 (0.1800, 4.7000) - mse: 7.5428 0.8376 (0.0416, 26.8899) - rmse: 1.3626 0.9152 (0.2039, 5.1855)\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 15.11760\n",
      "Epoch 191/1000\n",
      "84/84 [==============================] - 36s 434ms/step - loss: 14.9720 - output_0_loss: 9.2159 - output_1_loss: 5.7561 - val_loss: 15.8271 - val_output_0_loss: 8.9059 - val_output_1_loss: 6.9212\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9206 1.3116 (0.2912, 7.2643) - mae: 1.2209 0.8300 (0.1800, 4.7205) - mse: 7.3612 0.8601 (0.0424, 26.3848) - rmse: 1.3581 0.9274 (0.2059, 5.1366)\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 15.11760\n",
      "Epoch 192/1000\n",
      "84/84 [==============================] - 37s 445ms/step - loss: 15.0042 - output_0_loss: 9.2367 - output_1_loss: 5.7675 - val_loss: 15.6898 - val_output_0_loss: 8.8278 - val_output_1_loss: 6.8620\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9012 1.2886 (0.2560, 7.2027) - mae: 1.2091 0.8200 (0.1600, 4.7800) - mse: 7.4459 0.8302 (0.0328, 25.9396) - rmse: 1.3443 0.9112 (0.1811, 5.0931)\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 15.11760\n",
      "Epoch 193/1000\n",
      "84/84 [==============================] - 36s 428ms/step - loss: 14.8739 - output_0_loss: 9.1714 - output_1_loss: 5.7025 - val_loss: 16.0779 - val_output_0_loss: 8.9944 - val_output_1_loss: 7.0835\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9549 1.3405 (0.2912, 7.2936) - mae: 1.2416 0.8400 (0.1800, 4.7405) - mse: 7.6278 0.8985 (0.0424, 26.5980) - rmse: 1.3823 0.9478 (0.2059, 5.1573)\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 15.11760\n",
      "Epoch 194/1000\n",
      "84/84 [==============================] - 38s 448ms/step - loss: 15.1680 - output_0_loss: 9.3432 - output_1_loss: 5.8248 - val_loss: 15.4894 - val_output_0_loss: 8.7427 - val_output_1_loss: 6.7466\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.8840 1.2531 (0.2530, 7.2113) - mae: 1.1983 0.7950 (0.1600, 4.7405) - mse: 7.5753 0.7852 (0.0320, 26.0011) - rmse: 1.3322 0.8861 (0.1789, 5.0991)\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 15.11760\n",
      "Epoch 195/1000\n",
      "84/84 [==============================] - 37s 443ms/step - loss: 14.9933 - output_0_loss: 9.2309 - output_1_loss: 5.7624 - val_loss: 16.1501 - val_output_0_loss: 8.9970 - val_output_1_loss: 7.1531\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9729 1.3612 (0.3046, 7.3220) - mae: 1.2531 0.8600 (0.1800, 4.7810) - mse: 7.7241 0.9266 (0.0464, 26.8061) - rmse: 1.3951 0.9625 (0.2154, 5.1775)\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 15.11760\n",
      "Epoch 196/1000\n",
      "84/84 [==============================] - 37s 442ms/step - loss: 14.9824 - output_0_loss: 9.2462 - output_1_loss: 5.7361 - val_loss: 16.1100 - val_output_0_loss: 8.9616 - val_output_1_loss: 7.1484\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9792 1.3489 (0.2912, 7.4647) - mae: 1.2561 0.8599 (0.1800, 4.8422) - mse: 7.8566 0.9098 (0.0424, 27.8612) - rmse: 1.3995 0.9538 (0.2059, 5.2784)\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 15.11760\n",
      "Epoch 197/1000\n",
      "84/84 [==============================] - 37s 441ms/step - loss: 15.1712 - output_0_loss: 9.3472 - output_1_loss: 5.8240 - val_loss: 15.7402 - val_output_0_loss: 8.8095 - val_output_1_loss: 6.9307\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9098 1.2923 (0.2683, 7.3222) - mae: 1.2156 0.8170 (0.1800, 4.8165) - mse: 7.6156 0.8352 (0.0360, 26.8077) - rmse: 1.3504 0.9138 (0.1897, 5.1776)\n",
      "\n",
      "Epoch 00197: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 15.11760\n",
      "Epoch 198/1000\n",
      "84/84 [==============================] - 37s 445ms/step - loss: 15.0219 - output_0_loss: 9.2682 - output_1_loss: 5.7537 - val_loss: 15.6066 - val_output_0_loss: 8.7607 - val_output_1_loss: 6.8459\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.8973 1.2601 (0.2561, 7.3169) - mae: 1.2079 0.7950 (0.1600, 4.8200) - mse: 7.6684 0.7940 (0.0328, 26.7686) - rmse: 1.3416 0.8910 (0.1811, 5.1738)\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 15.11760\n",
      "Epoch 199/1000\n",
      "84/84 [==============================] - 37s 435ms/step - loss: 15.0350 - output_0_loss: 9.2678 - output_1_loss: 5.7672 - val_loss: 15.7208 - val_output_0_loss: 8.8174 - val_output_1_loss: 6.9034\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9077 1.2909 (0.2800, 7.3158) - mae: 1.2139 0.8100 (0.1600, 4.7772) - mse: 7.6264 0.8332 (0.0392, 26.7602) - rmse: 1.3490 0.9128 (0.1980, 5.1730)\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 15.11760\n",
      "Epoch 200/1000\n",
      "84/84 [==============================] - 37s 436ms/step - loss: 15.1071 - output_0_loss: 9.3165 - output_1_loss: 5.7906 - val_loss: 15.7601 - val_output_0_loss: 8.8451 - val_output_1_loss: 6.9149\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9137 1.2964 (0.2797, 7.3158) - mae: 1.2176 0.8100 (0.1600, 4.7176) - mse: 7.6511 0.8404 (0.0391, 26.7602) - rmse: 1.3532 0.9167 (0.1978, 5.1730)\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 15.11760\n",
      "Epoch 201/1000\n",
      "84/84 [==============================] - 36s 433ms/step - loss: 14.9828 - output_0_loss: 9.2402 - output_1_loss: 5.7426 - val_loss: 15.7547 - val_output_0_loss: 8.8389 - val_output_1_loss: 6.9159\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9149 1.2870 (0.2820, 7.2030) - mae: 1.2181 0.8150 (0.1800, 4.7064) - mse: 7.6302 0.8282 (0.0398, 25.9420) - rmse: 1.3540 0.9100 (0.1994, 5.0933)\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 15.11760\n",
      "Epoch 202/1000\n",
      "84/84 [==============================] - 37s 439ms/step - loss: 15.0291 - output_0_loss: 9.2558 - output_1_loss: 5.7733 - val_loss: 15.8200 - val_output_0_loss: 8.8799 - val_output_1_loss: 6.9402\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9216 1.2893 (0.2828, 7.2434) - mae: 1.2223 0.8300 (0.1800, 4.6869) - mse: 7.6392 0.8312 (0.0400, 26.2338) - rmse: 1.3588 0.9117 (0.2000, 5.1219)\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 15.11760\n",
      "Epoch 203/1000\n",
      "84/84 [==============================] - 36s 431ms/step - loss: 14.9835 - output_0_loss: 9.2472 - output_1_loss: 5.7363 - val_loss: 15.8383 - val_output_0_loss: 8.8884 - val_output_1_loss: 6.9499\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9256 1.3058 (0.2828, 7.2426) - mae: 1.2246 0.8200 (0.1800, 4.7019) - mse: 7.6603 0.8526 (0.0400, 26.2280) - rmse: 1.3616 0.9233 (0.1999, 5.1213)\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 15.11760\n",
      "Epoch 204/1000\n",
      "84/84 [==============================] - 37s 440ms/step - loss: 15.1204 - output_0_loss: 9.3256 - output_1_loss: 5.7948 - val_loss: 15.6746 - val_output_0_loss: 8.8137 - val_output_1_loss: 6.8610\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9030 1.2738 (0.2561, 7.2022) - mae: 1.2108 0.7997 (0.1600, 4.7774) - mse: 7.6331 0.8114 (0.0328, 25.9362) - rmse: 1.3457 0.9007 (0.1811, 5.0928)\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 15.11760\n",
      "Epoch 205/1000\n",
      "84/84 [==============================] - 36s 433ms/step - loss: 15.0256 - output_0_loss: 9.2752 - output_1_loss: 5.7504 - val_loss: 15.7599 - val_output_0_loss: 8.8561 - val_output_1_loss: 6.9039\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9143 1.2790 (0.2797, 7.2420) - mae: 1.2177 0.8050 (0.1800, 4.7415) - mse: 7.6522 0.8180 (0.0391, 26.2236) - rmse: 1.3536 0.9044 (0.1978, 5.1209)\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 15.11760\n",
      "Epoch 206/1000\n",
      "84/84 [==============================] - 36s 433ms/step - loss: 15.0829 - output_0_loss: 9.3006 - output_1_loss: 5.7823 - val_loss: 15.7761 - val_output_0_loss: 8.8569 - val_output_1_loss: 6.9192\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9195 1.2976 (0.2828, 7.2385) - mae: 1.2208 0.8200 (0.1800, 4.7404) - mse: 7.6481 0.8420 (0.0400, 26.1976) - rmse: 1.3573 0.9175 (0.2000, 5.1184)\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 15.11760\n",
      "Epoch 207/1000\n",
      "84/84 [==============================] - 38s 449ms/step - loss: 15.0057 - output_0_loss: 9.2584 - output_1_loss: 5.7473 - val_loss: 15.7993 - val_output_0_loss: 8.8613 - val_output_1_loss: 6.9380\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9230 1.3052 (0.2683, 7.2487) - mae: 1.2231 0.8150 (0.1799, 4.7005) - mse: 7.6584 0.8518 (0.0360, 26.2720) - rmse: 1.3598 0.9229 (0.1897, 5.1256)\n",
      "\n",
      "Epoch 00207: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 15.11760\n",
      "Epoch 208/1000\n",
      "84/84 [==============================] - 36s 431ms/step - loss: 14.9515 - output_0_loss: 9.2397 - output_1_loss: 5.7118 - val_loss: 15.7818 - val_output_0_loss: 8.8522 - val_output_1_loss: 6.9296\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9211 1.3008 (0.2828, 7.2415) - mae: 1.2217 0.8200 (0.1797, 4.7002) - mse: 7.6544 0.8460 (0.0400, 26.2195) - rmse: 1.3584 0.9198 (0.1999, 5.1205)\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 15.11760\n",
      "Epoch 209/1000\n",
      "84/84 [==============================] - 37s 435ms/step - loss: 15.0189 - output_0_loss: 9.2774 - output_1_loss: 5.7416 - val_loss: 15.8074 - val_output_0_loss: 8.8647 - val_output_1_loss: 6.9427\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9243 1.3008 (0.2769, 7.2497) - mae: 1.2237 0.8200 (0.1799, 4.7006) - mse: 7.6679 0.8460 (0.0383, 26.2789) - rmse: 1.3607 0.9198 (0.1958, 5.1263)\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 15.11760\n",
      "Epoch 210/1000\n",
      "84/84 [==============================] - 37s 442ms/step - loss: 15.0232 - output_0_loss: 9.2701 - output_1_loss: 5.7531 - val_loss: 15.8079 - val_output_0_loss: 8.8626 - val_output_1_loss: 6.9453\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9252 1.2997 (0.2683, 7.2607) - mae: 1.2242 0.8200 (0.1800, 4.7184) - mse: 7.6708 0.8446 (0.0360, 26.3591) - rmse: 1.3613 0.9190 (0.1897, 5.1341)\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 15.11760\n",
      "Epoch 211/1000\n",
      "84/84 [==============================] - 37s 441ms/step - loss: 15.0336 - output_0_loss: 9.2869 - output_1_loss: 5.7467 - val_loss: 15.7973 - val_output_0_loss: 8.8604 - val_output_1_loss: 6.9369\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9231 1.2997 (0.2797, 7.2607) - mae: 1.2229 0.8150 (0.1800, 4.6972) - mse: 7.6643 0.8446 (0.0391, 26.3591) - rmse: 1.3598 0.9190 (0.1978, 5.1341)\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 15.11760\n",
      "Epoch 212/1000\n",
      "84/84 [==============================] - 37s 438ms/step - loss: 15.0316 - output_0_loss: 9.2948 - output_1_loss: 5.7367 - val_loss: 15.8013 - val_output_0_loss: 8.8645 - val_output_1_loss: 6.9367\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9234 1.2997 (0.2683, 7.2812) - mae: 1.2231 0.8150 (0.1800, 4.7012) - mse: 7.6666 0.8446 (0.0360, 26.5076) - rmse: 1.3601 0.9190 (0.1897, 5.1486)\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 15.11760\n",
      "Epoch 213/1000\n",
      "84/84 [==============================] - 37s 439ms/step - loss: 14.9717 - output_0_loss: 9.2430 - output_1_loss: 5.7287 - val_loss: 15.8230 - val_output_0_loss: 8.8762 - val_output_1_loss: 6.9469\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9262 1.3045 (0.2828, 7.2818) - mae: 1.2248 0.8150 (0.1800, 4.7005) - mse: 7.6713 0.8508 (0.0400, 26.5125) - rmse: 1.3620 0.9224 (0.2000, 5.1490)\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 15.11760\n",
      "Epoch 214/1000\n",
      "84/84 [==============================] - 37s 440ms/step - loss: 14.9282 - output_0_loss: 9.2276 - output_1_loss: 5.7006 - val_loss: 15.8034 - val_output_0_loss: 8.8668 - val_output_1_loss: 6.9366\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9241 1.3093 (0.2828, 7.2616) - mae: 1.2235 0.8200 (0.1800, 4.7002) - mse: 7.6716 0.8572 (0.0400, 26.3652) - rmse: 1.3606 0.9258 (0.2000, 5.1347)\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 15.11760\n",
      "Epoch 215/1000\n",
      "84/84 [==============================] - 38s 447ms/step - loss: 15.0039 - output_0_loss: 9.2763 - output_1_loss: 5.7276 - val_loss: 15.8042 - val_output_0_loss: 8.8686 - val_output_1_loss: 6.9356\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9240 1.3046 (0.2828, 7.2989) - mae: 1.2235 0.8200 (0.1600, 4.6972) - mse: 7.6713 0.8510 (0.0400, 26.6373) - rmse: 1.3605 0.9225 (0.2000, 5.1611)\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 15.11760\n",
      "Epoch 216/1000\n",
      "84/84 [==============================] - 37s 437ms/step - loss: 15.0904 - output_0_loss: 9.3000 - output_1_loss: 5.7903 - val_loss: 15.8054 - val_output_0_loss: 8.8664 - val_output_1_loss: 6.9389\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9248 1.3014 (0.2828, 7.2948) - mae: 1.2239 0.8200 (0.1649, 4.6972) - mse: 7.6752 0.8468 (0.0400, 26.6071) - rmse: 1.3610 0.9202 (0.2000, 5.1582)\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 15.11760\n",
      "Epoch 217/1000\n",
      "84/84 [==============================] - 36s 433ms/step - loss: 14.9373 - output_0_loss: 9.2340 - output_1_loss: 5.7032 - val_loss: 15.7927 - val_output_0_loss: 8.8595 - val_output_1_loss: 6.9332\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9227 1.3046 (0.2828, 7.2948) - mae: 1.2227 0.8100 (0.1796, 4.6972) - mse: 7.6725 0.8510 (0.0400, 26.6071) - rmse: 1.3596 0.9225 (0.1999, 5.1582)\n",
      "\n",
      "Epoch 00217: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 15.11760\n",
      "Epoch 218/1000\n",
      "84/84 [==============================] - 37s 440ms/step - loss: 14.9090 - output_0_loss: 9.2098 - output_1_loss: 5.6992 - val_loss: 15.7919 - val_output_0_loss: 8.8594 - val_output_1_loss: 6.9326\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9227 1.3046 (0.2828, 7.2948) - mae: 1.2227 0.8100 (0.1600, 4.6972) - mse: 7.6719 0.8510 (0.0400, 26.6071) - rmse: 1.3595 0.9225 (0.2000, 5.1582)\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 15.11760\n",
      "Epoch 219/1000\n",
      "84/84 [==============================] - 36s 434ms/step - loss: 14.9145 - output_0_loss: 9.2232 - output_1_loss: 5.6913 - val_loss: 15.7935 - val_output_0_loss: 8.8600 - val_output_1_loss: 6.9335\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9229 1.3015 (0.2828, 7.2948) - mae: 1.2228 0.8100 (0.1796, 4.6972) - mse: 7.6728 0.8470 (0.0400, 26.6071) - rmse: 1.3597 0.9203 (0.2000, 5.1582)\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 15.11760\n",
      "Epoch 220/1000\n",
      "84/84 [==============================] - 37s 436ms/step - loss: 14.9246 - output_0_loss: 9.2164 - output_1_loss: 5.7081 - val_loss: 15.7941 - val_output_0_loss: 8.8607 - val_output_1_loss: 6.9334\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9230 1.3015 (0.2828, 7.2948) - mae: 1.2229 0.8100 (0.1800, 4.7002) - mse: 7.6735 0.8470 (0.0400, 26.6071) - rmse: 1.3598 0.9203 (0.2000, 5.1582)\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 15.11760\n",
      "Epoch 221/1000\n",
      "84/84 [==============================] - 38s 447ms/step - loss: 15.0775 - output_0_loss: 9.3013 - output_1_loss: 5.7762 - val_loss: 15.7973 - val_output_0_loss: 8.8624 - val_output_1_loss: 6.9349\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9233 1.3015 (0.2828, 7.2948) - mae: 1.2231 0.8100 (0.1800, 4.7002) - mse: 7.6744 0.8470 (0.0400, 26.6071) - rmse: 1.3600 0.9203 (0.2000, 5.1582)\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 15.11760\n",
      "Epoch 222/1000\n",
      "84/84 [==============================] - 36s 434ms/step - loss: 15.0834 - output_0_loss: 9.3146 - output_1_loss: 5.7688 - val_loss: 15.7942 - val_output_0_loss: 8.8609 - val_output_1_loss: 6.9332\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9231 1.3015 (0.2828, 7.2948) - mae: 1.2229 0.8100 (0.1600, 4.7002) - mse: 7.6727 0.8470 (0.0400, 26.6071) - rmse: 1.3598 0.9203 (0.2000, 5.1582)\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 15.11760\n",
      "Epoch 223/1000\n",
      "84/84 [==============================] - 37s 435ms/step - loss: 15.0595 - output_0_loss: 9.2995 - output_1_loss: 5.7600 - val_loss: 15.7935 - val_output_0_loss: 8.8609 - val_output_1_loss: 6.9326\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9228 1.3015 (0.2828, 7.2948) - mae: 1.2227 0.8100 (0.1600, 4.6972) - mse: 7.6722 0.8470 (0.0400, 26.6071) - rmse: 1.3596 0.9203 (0.2000, 5.1582)\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 15.11760\n",
      "Epoch 224/1000\n",
      "84/84 [==============================] - 37s 443ms/step - loss: 15.0290 - output_0_loss: 9.2797 - output_1_loss: 5.7494 - val_loss: 15.7968 - val_output_0_loss: 8.8624 - val_output_1_loss: 6.9343\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9230 1.3014 (0.2828, 7.2948) - mae: 1.2229 0.8100 (0.1600, 4.6972) - mse: 7.6709 0.8468 (0.0400, 26.6071) - rmse: 1.3598 0.9202 (0.2000, 5.1582)\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 15.11760\n",
      "Epoch 225/1000\n",
      "84/84 [==============================] - 37s 443ms/step - loss: 14.9376 - output_0_loss: 9.2147 - output_1_loss: 5.7229 - val_loss: 15.7853 - val_output_0_loss: 8.8575 - val_output_1_loss: 6.9278\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9217 1.3014 (0.2828, 7.2948) - mae: 1.2221 0.8100 (0.1649, 4.6972) - mse: 7.6692 0.8468 (0.0400, 26.6071) - rmse: 1.3589 0.9202 (0.2000, 5.1582)\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 15.11760\n",
      "Epoch 226/1000\n",
      "84/84 [==============================] - 37s 442ms/step - loss: 14.8560 - output_0_loss: 9.1930 - output_1_loss: 5.6630 - val_loss: 15.7822 - val_output_0_loss: 8.8557 - val_output_1_loss: 6.9265\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9212 1.3014 (0.2800, 7.2948) - mae: 1.2218 0.8050 (0.1600, 4.6972) - mse: 7.6688 0.8468 (0.0392, 26.6071) - rmse: 1.3585 0.9202 (0.1980, 5.1582)\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 15.11760\n",
      "Epoch 227/1000\n",
      "84/84 [==============================] - 37s 435ms/step - loss: 15.0417 - output_0_loss: 9.2848 - output_1_loss: 5.7569 - val_loss: 15.7758 - val_output_0_loss: 8.8535 - val_output_1_loss: 6.9222\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9204 1.3014 (0.2800, 7.2948) - mae: 1.2213 0.8050 (0.1600, 4.6972) - mse: 7.6679 0.8468 (0.0392, 26.6071) - rmse: 1.3579 0.9202 (0.1980, 5.1582)\n",
      "\n",
      "Epoch 00227: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 15.11760\n",
      "Epoch 00227: early stopping\n"
     ]
    }
   ],
   "source": [
    "model.fit(batch_size=16,\n",
    "          validation_batch_size=10,\n",
    "          callbacks=callbacks,\n",
    "          epochs=1000,\n",
    "          n_workers=8,\n",
    "          steps_per_epoch=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

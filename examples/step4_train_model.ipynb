{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/jgraving/deepposekit/blob/master/examples/step4_train_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepPoseKit Step 4 - Train a model\n",
    "\n",
    "This is step 4 of the example notebooks for using DeepPoseKit. This notebook shows you how to use your annotated data to train a deep learning model using data augmentation and callbacks for logging the training process and saving the best model during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you haven't already installed DeepPoseKit and downloaded the example datasets you can run the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/jgraving/deepposekit-data ~/\n",
    "\n",
    "import sys\n",
    "!{sys.executable} -m pip install \\\n",
    "git+https://github.com/jgraving/deepposekit \\\n",
    "git+https://github.com/jgraving/deepposekit-annotator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jake/Library/Python/3.7/lib/python/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/jake/Library/Python/3.7/lib/python/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/jake/Library/Python/3.7/lib/python/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/jake/Library/Python/3.7/lib/python/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/jake/Library/Python/3.7/lib/python/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/jake/Library/Python/3.7/lib/python/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/jake/Library/Python/3.7/lib/python/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/jake/Library/Python/3.7/lib/python/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/jake/Library/Python/3.7/lib/python/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/jake/Library/Python/3.7/lib/python/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/jake/Library/Python/3.7/lib/python/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/jake/Library/Python/3.7/lib/python/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "from deepposekit import TrainingGenerator\n",
    "from deepposekit.augment import FlipAxis\n",
    "import imgaug.augmenters as iaa\n",
    "import imgaug as ia\n",
    "\n",
    "from deepposekit.models import (StackedDenseNet,\n",
    "                                DeepLabCut,\n",
    "                                StackedHourglass,\n",
    "                                LEAP)\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from deepposekit.callbacks import Logger, ModelCheckpoint\n",
    "\n",
    "import time\n",
    "from os.path import expanduser\n",
    "\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "\n",
    "HOME = expanduser(\"~\") if not IN_COLAB else '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/jake/deepposekit-data/datasets/fly/annotation_data_release.h5',\n",
       " '/Users/jake/deepposekit-data/datasets/fly/best_model_densenet.h5',\n",
       " '/Users/jake/deepposekit-data/datasets/fly/example_annotation_set.h5',\n",
       " '/Users/jake/deepposekit-data/datasets/fly/log_densenet.h5']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations = sorted(glob.glob(HOME + '/deepposekit-data/datasets/fly/*.h5'))\n",
    "annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create an augmentation pipeline\n",
    "DeepPoseKit works with augmenters from the [imgaug package](https://github.com/aleju/imgaug).\n",
    "This is a short example using spatial augmentations with axis flipping and affine transforms\n",
    "See https://github.com/aleju/imgaug for more documentation on augmenters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmenter = []\n",
    "\n",
    "# FlipAxis only works if the data are rotationally aligned on the central body axis\n",
    "augmenter.append(FlipAxis(annotations[0], axis=0))  # flip image up-down\n",
    "augmenter.append(FlipAxis(annotations[0], axis=1))  # flip image left-right \n",
    "\n",
    "sometimes = []\n",
    "sometimes.append(iaa.Affine(scale={\"x\": (0.95, 1.05), \"y\": (0.95, 1.05)},\n",
    "                            translate_percent={'x': (-0.05, 0.05), 'y': (-0.05, 0.05)},\n",
    "                            shear=(-8, 8),\n",
    "                            order=ia.ALL,\n",
    "                            cval=ia.ALL,\n",
    "                            mode=ia.ALL)\n",
    "                 )\n",
    "sometimes.append(iaa.Affine(scale=(0.8, 1.2),\n",
    "                            mode=ia.ALL,\n",
    "                            order=ia.ALL,\n",
    "                            cval=ia.ALL)\n",
    "                 )\n",
    "augmenter.append(iaa.Sometimes(0.75, sometimes))\n",
    "augmenter.append(iaa.Affine(rotate=(-180, 180),\n",
    "                            mode=ia.ALL,\n",
    "                            order=ia.ALL,\n",
    "                            cval=ia.ALL)\n",
    "                 )\n",
    "augmenter = iaa.Sequential(augmenter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a training data generator\n",
    "This creates a data generator for training the model with annotated data. If you are using `LEAP` you should set the `downsample_factor` to 0. You can also look at the doc string for more explanation:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainingGenerator?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/h5py/_hl/dataset.py:313: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  \"Use dataset[()] instead.\", H5pyDeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'shuffle': True,\n",
       " 'downsample_factor': 2,\n",
       " 'sigma': 5,\n",
       " 'use_graph': True,\n",
       " 'graph_scale': 0.1,\n",
       " 'validation_split': 0.1,\n",
       " 'datapath': '/Users/jake/deepposekit-data/datasets/fly/annotation_data_release.h5',\n",
       " 'dataset': 'images',\n",
       " 'output_shape': (48, 48),\n",
       " 'n_train': 1350,\n",
       " 'n_validation': 150,\n",
       " 'random_seed': 1,\n",
       " 'n_output_channels': 66,\n",
       " 'augmenter': True,\n",
       " 'n_keypoints': 32}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator = TrainingGenerator(datapath=annotations[0],\n",
    "                                    downsample_factor=2,\n",
    "                                    augmenter=augmenter,\n",
    "                                    sigma=5,\n",
    "                                    validation_split=0.1,\n",
    "                                    use_graph=True,\n",
    "                                    random_seed=1,\n",
    "                                    graph_scale=0.1)\n",
    "train_generator.get_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the augmentation output\n",
    "This plots the training data output from the `TrainingGenerator` to ensure that the augmentation is working, rerun this cell to see random augmentations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_keypoints = train_generator.n_keypoints\n",
    "batch = train_generator(batch_size=1, validation=False)[0]\n",
    "inputs = batch[0]\n",
    "outputs = batch[1]\n",
    "\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(10,10))\n",
    "ax1.imshow(inputs[0,...,0], cmap='gray', vmin=0, vmax=255)\n",
    "ax2.imshow(outputs[0,...,n_keypoints:-1].max(-1))\n",
    "ax3.imshow(outputs[0,...,:n_keypoints].max(-1))\n",
    "ax4.imshow(outputs[0,...,-1], vmin=0)\n",
    "plt.show()\n",
    "\n",
    "train_generator.on_epoch_end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define a model\n",
    "Here you can define a model to train with your data. You can use our `StackedDenseNet` model, `StackedHourglass` model, `DeepLabCut` model, or the `LEAP` model. The default settings for each model should work well for most datasets, but you can customize the model architecture. Look at the doc strings for more information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "StackedDenseNet?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0924 17:29:23.786360 4342203840 deprecation.py:323] From /Users/jake/Library/Python/3.7/lib/python/site-packages/tensorflow/python/keras/backend.py:4075: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0924 17:29:24.258202 4342203840 deprecation.py:506] From /Users/jake/Library/Python/3.7/lib/python/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'StackedDenseNet',\n",
       " 'n_stacks': 2,\n",
       " 'n_transitions': 6,\n",
       " 'growth_rate': 48,\n",
       " 'bottleneck_factor': 1,\n",
       " 'compression_factor': 0.5,\n",
       " 'subpixel': True,\n",
       " 'shuffle': True,\n",
       " 'downsample_factor': 2,\n",
       " 'sigma': 5,\n",
       " 'use_graph': True,\n",
       " 'graph_scale': 0.1,\n",
       " 'validation_split': 0.1,\n",
       " 'datapath': '/Users/jake/deepposekit-data/datasets/fly/annotation_data_release.h5',\n",
       " 'dataset': 'images',\n",
       " 'output_shape': (48, 48),\n",
       " 'n_train': 1350,\n",
       " 'n_validation': 150,\n",
       " 'random_seed': 1,\n",
       " 'n_output_channels': 66,\n",
       " 'augmenter': True,\n",
       " 'n_keypoints': 32}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = StackedDenseNet(data_generator=train_generator, n_stacks=2)\n",
    "# model = DeepLabCut(train_generator)\n",
    "# model = LEAP(train_generator)\n",
    "# model = StackedHourglass(train_generator)\n",
    "model.get_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can examine the model architecture to see the model's layers and number of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"StackedDenseNet\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 192, 192, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "float (Float)                   (None, 192, 192, 1)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "image_normalization (ImageNorma (None, 192, 192, 1)  0           float[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "sub_pixel_downscaling (SubPixel (None, 96, 96, 4)    0           image_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 96, 96, 48)   2400        image_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 96, 96, 52)   0           sub_pixel_downscaling[0][0]      \n",
      "                                                                 conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 96, 96, 48)   2544        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 96, 96, 48)   20784       conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 96, 96, 100)  0           concatenate[0][0]                \n",
      "                                                                 conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 48, 48, 100)  0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 48, 48, 50)   5050        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 48, 48, 96)   4896        conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 48, 48, 100)  0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 48, 48, 96)   83040       conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 48, 48, 50)   5050        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 48, 48, 146)  0           conv2d_6[0][0]                   \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 48, 48, 25)   1275        conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 48, 48, 73)   10731       concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 48, 48, 98)   0           conv2d_7[0][0]                   \n",
      "                                                                 conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "output_0 (Conv2D)               (None, 48, 48, 66)   6534        concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 48, 48, 66)   264         output_0[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 48, 48, 164)  0           concatenate_9[0][0]              \n",
      "                                                                 batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 24, 24, 164)  0           concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 24, 24, 82)   13530       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 24, 24, 144)  11952       conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 24, 24, 144)  186768      conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_29 (Concatenate)    (None, 24, 24, 226)  0           conv2d_27[0][0]                  \n",
      "                                                                 conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 12, 12, 226)  0           concatenate_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 12, 12, 113)  25651       max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 12, 12, 144)  16416       conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 12, 12, 144)  186768      conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_30 (Concatenate)    (None, 12, 12, 257)  0           conv2d_28[0][0]                  \n",
      "                                                                 conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 6, 6, 257)    0           concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 6, 6, 128)    33024       max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 6, 6, 144)    18576       conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 6, 6, 144)    186768      conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_31 (Concatenate)    (None, 6, 6, 272)    0           conv2d_29[0][0]                  \n",
      "                                                                 conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 3, 3, 272)    0           concatenate_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 3, 3, 136)    37128       max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 3, 3, 96)     13152       conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 3, 3, 96)     83040       conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 3, 3, 68)     9316        conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)    (None, 3, 3, 300)    0           conv2d_30[0][0]                  \n",
      "                                                                 conv2d_16[0][0]                  \n",
      "                                                                 conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 3, 3, 144)    43344       concatenate_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 3, 3, 144)    186768      conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)    (None, 3, 3, 444)    0           concatenate_22[0][0]             \n",
      "                                                                 conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 3, 3, 220)    97900       concatenate_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "sub_pixel_upscaling (SubPixelUp (None, 6, 6, 55)     0           conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 6, 6, 136)    37128       concatenate_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)    (None, 6, 6, 191)    0           sub_pixel_upscaling[0][0]        \n",
      "                                                                 conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 6, 6, 144)    27648       concatenate_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 6, 6, 144)    186768      conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_24 (Concatenate)    (None, 6, 6, 335)    0           concatenate_21[0][0]             \n",
      "                                                                 conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 6, 6, 168)    56448       concatenate_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "sub_pixel_upscaling_1 (SubPixel (None, 12, 12, 42)   0           conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 12, 12, 128)  33024       concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)    (None, 12, 12, 170)  0           sub_pixel_upscaling_1[0][0]      \n",
      "                                                                 conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 12, 12, 144)  24624       concatenate_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 12, 12, 144)  186768      conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_25 (Concatenate)    (None, 12, 12, 314)  0           concatenate_20[0][0]             \n",
      "                                                                 conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 12, 12, 156)  49140       concatenate_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "sub_pixel_upscaling_2 (SubPixel (None, 24, 24, 39)   0           conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 24, 24, 113)  25651       concatenate_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 24, 24, 152)  0           sub_pixel_upscaling_2[0][0]      \n",
      "                                                                 conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 24, 24, 96)   14688       concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 24, 24, 96)   83040       conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_26 (Concatenate)    (None, 24, 24, 248)  0           concatenate_19[0][0]             \n",
      "                                                                 conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 24, 24, 124)  30876       concatenate_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_28 (Concatenate)    (None, 48, 48, 164)  0           concatenate_9[0][0]              \n",
      "                                                                 batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "sub_pixel_upscaling_3 (SubPixel (None, 48, 48, 31)   0           conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 48, 48, 82)   13530       concatenate_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_27 (Concatenate)    (None, 48, 48, 113)  0           sub_pixel_upscaling_3[0][0]      \n",
      "                                                                 conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 48, 48, 96)   10944       concatenate_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 48, 48, 96)   83040       conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_38 (Concatenate)    (None, 48, 48, 209)  0           concatenate_27[0][0]             \n",
      "                                                                 conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_39 (Concatenate)    (None, 48, 48, 164)  0           concatenate_9[0][0]              \n",
      "                                                                 batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 48, 48, 66)   264         output_0[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_41 (Concatenate)    (None, 48, 48, 439)  0           concatenate_38[0][0]             \n",
      "                                                                 concatenate_39[0][0]             \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 24, 24, 439)  0           concatenate_41[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 24, 24, 220)  96800       max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 24, 24, 144)  31824       conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 24, 24, 144)  186768      conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_59 (Concatenate)    (None, 24, 24, 364)  0           conv2d_58[0][0]                  \n",
      "                                                                 conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 12, 12, 364)  0           concatenate_59[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 12, 12, 182)  66430       max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 12, 12, 144)  26352       conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 12, 12, 144)  186768      conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_60 (Concatenate)    (None, 12, 12, 326)  0           conv2d_59[0][0]                  \n",
      "                                                                 conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 6, 6, 326)    0           concatenate_60[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 6, 6, 163)    53301       max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 6, 6, 144)    23616       conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 6, 6, 144)    186768      conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_61 (Concatenate)    (None, 6, 6, 307)    0           conv2d_60[0][0]                  \n",
      "                                                                 conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 3, 3, 307)    0           concatenate_61[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 3, 3, 154)    47432       max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 3, 3, 96)     14880       conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 3, 3, 96)     83040       conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 3, 3, 77)     11935       conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_52 (Concatenate)    (None, 3, 3, 327)    0           conv2d_61[0][0]                  \n",
      "                                                                 conv2d_47[0][0]                  \n",
      "                                                                 conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 3, 3, 144)    47232       concatenate_52[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 3, 3, 144)    186768      conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_53 (Concatenate)    (None, 3, 3, 471)    0           concatenate_52[0][0]             \n",
      "                                                                 conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 3, 3, 236)    111392      concatenate_53[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "sub_pixel_upscaling_4 (SubPixel (None, 6, 6, 59)     0           conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 6, 6, 154)    47432       concatenate_61[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_51 (Concatenate)    (None, 6, 6, 213)    0           sub_pixel_upscaling_4[0][0]      \n",
      "                                                                 conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 6, 6, 144)    30816       concatenate_51[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 6, 6, 144)    186768      conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_54 (Concatenate)    (None, 6, 6, 357)    0           concatenate_51[0][0]             \n",
      "                                                                 conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 6, 6, 176)    63008       concatenate_54[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "sub_pixel_upscaling_5 (SubPixel (None, 12, 12, 44)   0           conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 12, 12, 163)  53301       concatenate_60[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_50 (Concatenate)    (None, 12, 12, 207)  0           sub_pixel_upscaling_5[0][0]      \n",
      "                                                                 conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 12, 12, 144)  29952       concatenate_50[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 12, 12, 144)  186768      conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_55 (Concatenate)    (None, 12, 12, 351)  0           concatenate_50[0][0]             \n",
      "                                                                 conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 12, 12, 176)  61952       concatenate_55[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "sub_pixel_upscaling_6 (SubPixel (None, 24, 24, 44)   0           conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 24, 24, 182)  66430       concatenate_59[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_49 (Concatenate)    (None, 24, 24, 226)  0           sub_pixel_upscaling_6[0][0]      \n",
      "                                                                 conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 24, 24, 96)   21792       concatenate_49[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 24, 24, 96)   83040       conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_56 (Concatenate)    (None, 24, 24, 322)  0           concatenate_49[0][0]             \n",
      "                                                                 conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 24, 24, 160)  51680       concatenate_56[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_58 (Concatenate)    (None, 48, 48, 439)  0           concatenate_38[0][0]             \n",
      "                                                                 concatenate_39[0][0]             \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sub_pixel_upscaling_7 (SubPixel (None, 48, 48, 40)   0           conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 48, 48, 220)  96800       concatenate_58[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_57 (Concatenate)    (None, 48, 48, 260)  0           sub_pixel_upscaling_7[0][0]      \n",
      "                                                                 conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_40 (Concatenate)    (None, 48, 48, 439)  0           concatenate_38[0][0]             \n",
      "                                                                 concatenate_39[0][0]             \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 48, 48, 96)   25056       concatenate_57[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output_1 (Conv2D)               (None, 48, 48, 66)   29040       concatenate_40[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 48, 48, 96)   83040       conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_68 (Concatenate)    (None, 48, 48, 356)  0           concatenate_57[0][0]             \n",
      "                                                                 conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_69 (Concatenate)    (None, 48, 48, 164)  0           concatenate_9[0][0]              \n",
      "                                                                 batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 48, 48, 66)   264         output_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_70 (Concatenate)    (None, 48, 48, 586)  0           concatenate_68[0][0]             \n",
      "                                                                 concatenate_69[0][0]             \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "output_2 (Conv2D)               (None, 48, 48, 66)   38742       concatenate_70[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 4,673,437\n",
      "Trainable params: 4,673,041\n",
      "Non-trainable params: 396\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.train_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the prediction speed\n",
    "This generates a random set of input images for the model to test how fast the model can predict keypoint locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size = (10000,\n",
    "             train_generator.height,\n",
    "             train_generator.width, \n",
    "             train_generator.n_channels)\n",
    "x = np.random.randint(0, 255, data_size, dtype='uint8')\n",
    "t0 = time.time()\n",
    "y = model.predict(x, batch_size=100, verbose=1)\n",
    "t1 = time.time()\n",
    "print(x.shape[0]/(t1-t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define callbacks to enhance model training\n",
    "Here you can define callbacks to pass to the model for use during training\n",
    "\n",
    "\n",
    "`Logger` evaluates the validation set at the end of each epoch and saves the evaluation data to a HDF5 log file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = Logger(HOME + '/deepposekit-data/datasets/fly/log_densenet.h5',\n",
    "                validation_batch_size=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ReduceLROnPlateau` automatically reduces the learning rate of the optimizer when the validation loss stops improving. This helps the model to reach a better optimum at the end of training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau('val_loss',\n",
    "                              factor=0.2,\n",
    "                              verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ModelCheckpoint` automatically saves the model when the validation loss improves at the end of each epoch. This allows you to automatically save the best performing model during training, without having to evaluate the performance manually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = ModelCheckpoint(HOME + '/deepposekit-data/datasets/fly/best_model_densenet.h5',\n",
    "                                   monitor='val_loss',\n",
    "                                   verbose=1,\n",
    "                                   save_best_only=True,\n",
    "                                   optimizer=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`EarlyStopping` automatically stops the training session when the validation loss stops improving for a set number of epochs, which is set with the `patience` argument. This allows you to save time when training your model if there's not more improvment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping('val_loss',\n",
    "                           min_delta=0.001,\n",
    "                           patience=50,\n",
    "                           verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a list of callbacks to pass to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [logger, early_stop, reduce_lr, model_checkpoint]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit the model\n",
    "\n",
    "This fits the model for a set number of epochs with small batches of data. If you have a small dataset initially you can set `batch_size` to a small value and manually set `steps_per_epoch` to some large value, e.g. 500, to increase the number of batches per epoch, otherwise this is automatically determined by the size of the dataset. See the doc string for details:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "84/84 [==============================] - 45s 540ms/step - loss: 141.5929 - output_0_loss: 71.9562 - output_1_loss: 69.6367 - val_loss: 127.7636 - val_output_0_loss: 65.9062 - val_output_1_loss: 61.8574\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 20.8619 13.9248 (1.5311, 74.3796) - mae: 12.8411 9.3500 (0.9800, 45.2200) - mse: 410.8777 97.0960 (1.1721, 2766.1602) - rmse: 14.7516 9.8464 (1.0826, 52.5943)\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 127.76356, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 2/1000\n",
      "84/84 [==============================] - 35s 411ms/step - loss: 123.4802 - output_0_loss: 65.3742 - output_1_loss: 58.1060 - val_loss: 114.6841 - val_output_0_loss: 63.1798 - val_output_1_loss: 51.5043\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 20.0451 14.3249 (1.0671, 72.1541) - mae: 11.5309 9.2665 (0.6600, 40.3005) - mse: 414.4482 103.0886 (0.5694, 2603.1043) - rmse: 14.1740 10.1292 (0.7546, 51.0206)\n",
      "\n",
      "Epoch 00002: val_loss improved from 127.76356 to 114.68405, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 3/1000\n",
      "84/84 [==============================] - 36s 433ms/step - loss: 108.1311 - output_0_loss: 61.4599 - output_1_loss: 46.6712 - val_loss: 97.7990 - val_output_0_loss: 58.4986 - val_output_1_loss: 39.3004\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 10.3509 4.2044 (0.6596, 72.4485) - mae: 6.1413 2.6748 (0.4199, 39.8000) - mse: 205.2073 8.8410 (0.2175, 2624.3938) - rmse: 7.3192 2.9730 (0.4664, 51.2288)\n",
      "\n",
      "Epoch 00003: val_loss improved from 114.68405 to 97.79897, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 4/1000\n",
      "84/84 [==============================] - 38s 447ms/step - loss: 91.8964 - output_0_loss: 57.5500 - output_1_loss: 34.3465 - val_loss: 83.5508 - val_output_0_loss: 54.7832 - val_output_1_loss: 28.7676\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 5.9511 2.6944 (0.5123, 37.3852) - mae: 3.7003 1.7288 (0.3200, 23.9294) - mse: 83.5868 3.6304 (0.1312, 698.8257) - rmse: 4.2081 1.9052 (0.3622, 26.4353)\n",
      "\n",
      "Epoch 00004: val_loss improved from 97.79897 to 83.55084, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 5/1000\n",
      "84/84 [==============================] - 37s 442ms/step - loss: 80.6402 - output_0_loss: 53.8462 - output_1_loss: 26.7940 - val_loss: 75.2245 - val_output_0_loss: 51.3208 - val_output_1_loss: 23.9037\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 5.2108 2.5024 (0.4948, 29.9731) - mae: 3.2574 1.6300 (0.3000, 19.4830) - mse: 58.6598 3.1309 (0.1224, 449.1946) - rmse: 3.6846 1.7694 (0.3499, 21.1942)\n",
      "\n",
      "Epoch 00005: val_loss improved from 83.55084 to 75.22447, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 6/1000\n",
      "84/84 [==============================] - 36s 426ms/step - loss: 74.4513 - output_0_loss: 50.7298 - output_1_loss: 23.7215 - val_loss: 68.6243 - val_output_0_loss: 48.0636 - val_output_1_loss: 20.5607\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 3.9513 2.1145 (0.4561, 19.8573) - mae: 2.5297 1.3350 (0.2800, 13.1607) - mse: 29.2464 2.2361 (0.1040, 197.1576) - rmse: 2.7940 1.4952 (0.3225, 14.0413)\n",
      "\n",
      "Epoch 00006: val_loss improved from 75.22447 to 68.62431, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 7/1000\n",
      "84/84 [==============================] - 37s 437ms/step - loss: 69.4985 - output_0_loss: 48.0178 - output_1_loss: 21.4808 - val_loss: 63.6569 - val_output_0_loss: 45.2328 - val_output_1_loss: 18.4241\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 3.5782 1.9324 (0.3418, 18.6150) - mae: 2.2873 1.2000 (0.2200, 12.1834) - mse: 25.7538 1.8672 (0.0584, 173.2588) - rmse: 2.5302 1.3664 (0.2417, 13.1628)\n",
      "\n",
      "Epoch 00007: val_loss improved from 68.62431 to 63.65687, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 8/1000\n",
      "84/84 [==============================] - 36s 434ms/step - loss: 64.3544 - output_0_loss: 44.2102 - output_1_loss: 20.1442 - val_loss: 56.9272 - val_output_0_loss: 39.4944 - val_output_1_loss: 17.4328\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 3.5603 1.8922 (0.3299, 19.3273) - mae: 2.2851 1.1850 (0.2200, 12.5924) - mse: 24.7474 1.7903 (0.0544, 186.7723) - rmse: 2.5175 1.3380 (0.2332, 13.6665)\n",
      "\n",
      "Epoch 00008: val_loss improved from 63.65687 to 56.92722, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 9/1000\n",
      "84/84 [==============================] - 36s 434ms/step - loss: 56.6931 - output_0_loss: 37.5027 - output_1_loss: 19.1903 - val_loss: 50.0952 - val_output_0_loss: 33.2904 - val_output_1_loss: 16.8048\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 3.2350 1.7412 (0.3394, 17.0024) - mae: 2.0617 1.0877 (0.2000, 10.5552) - mse: 20.6909 1.5160 (0.0576, 144.5402) - rmse: 2.2875 1.2312 (0.2400, 12.0225)\n",
      "\n",
      "Epoch 00009: val_loss improved from 56.92722 to 50.09522, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 10/1000\n",
      "84/84 [==============================] - 37s 437ms/step - loss: 50.8308 - output_0_loss: 32.8036 - output_1_loss: 18.0272 - val_loss: 46.2102 - val_output_0_loss: 30.2164 - val_output_1_loss: 15.9938\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 3.0652 1.6768 (0.3225, 14.9659) - mae: 1.9475 1.0650 (0.2000, 9.3430) - mse: 17.7118 1.4058 (0.0520, 111.9912) - rmse: 2.1674 1.1856 (0.2280, 10.5825)\n",
      "\n",
      "Epoch 00010: val_loss improved from 50.09522 to 46.21015, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 11/1000\n",
      "84/84 [==============================] - 36s 432ms/step - loss: 47.8430 - output_0_loss: 30.4918 - output_1_loss: 17.3512 - val_loss: 42.8479 - val_output_0_loss: 27.3875 - val_output_1_loss: 15.4604\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 3.2000 1.8886 (0.3688, 16.3841) - mae: 2.0503 1.2000 (0.2291, 10.1815) - mse: 17.8535 1.7846 (0.0680, 134.2189) - rmse: 2.2627 1.3354 (0.2608, 11.5853)\n",
      "\n",
      "Epoch 00011: val_loss improved from 46.21015 to 42.84786, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 12/1000\n",
      "84/84 [==============================] - 37s 436ms/step - loss: 45.0239 - output_0_loss: 28.6180 - output_1_loss: 16.4059 - val_loss: 43.5580 - val_output_0_loss: 27.0284 - val_output_1_loss: 16.5295\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 3.2874 2.1538 (0.4252, 14.8791) - mae: 2.1099 1.3700 (0.2600, 9.7410) - mse: 16.5771 2.3200 (0.0904, 110.6937) - rmse: 2.3245 1.5229 (0.3007, 10.5211)\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 42.84786\n",
      "Epoch 13/1000\n",
      "84/84 [==============================] - 36s 433ms/step - loss: 43.1670 - output_0_loss: 27.3763 - output_1_loss: 15.7908 - val_loss: 40.9062 - val_output_0_loss: 25.9638 - val_output_1_loss: 14.9424\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 3.1372 1.8886 (0.4000, 14.5262) - mae: 1.9975 1.1900 (0.2400, 9.1019) - mse: 16.9359 1.7846 (0.0800, 105.5052) - rmse: 2.2183 1.3354 (0.2828, 10.2716)\n",
      "\n",
      "Epoch 00013: val_loss improved from 42.84786 to 40.90618, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 14/1000\n",
      "84/84 [==============================] - 37s 444ms/step - loss: 41.0488 - output_0_loss: 26.1454 - output_1_loss: 14.9034 - val_loss: 37.9238 - val_output_0_loss: 24.4767 - val_output_1_loss: 13.4471\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.8428 1.6904 (0.3225, 13.0821) - mae: 1.8170 1.1050 (0.2000, 8.1653) - mse: 15.3661 1.4288 (0.0520, 85.5708) - rmse: 2.0102 1.1953 (0.2280, 9.2504)\n",
      "\n",
      "Epoch 00014: val_loss improved from 40.90618 to 37.92379, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 15/1000\n",
      "84/84 [==============================] - 37s 436ms/step - loss: 39.6973 - output_0_loss: 25.3932 - output_1_loss: 14.3041 - val_loss: 37.3492 - val_output_0_loss: 23.6238 - val_output_1_loss: 13.7253\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.8574 1.8835 (0.3688, 12.1269) - mae: 1.8219 1.1800 (0.2400, 7.4911) - mse: 12.7364 1.7738 (0.0680, 73.5315) - rmse: 2.0205 1.3318 (0.2608, 8.5750)\n",
      "\n",
      "Epoch 00015: val_loss improved from 37.92379 to 37.34920, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 16/1000\n",
      "84/84 [==============================] - 36s 434ms/step - loss: 38.5882 - output_0_loss: 24.7468 - output_1_loss: 13.8414 - val_loss: 35.4326 - val_output_0_loss: 22.9502 - val_output_1_loss: 12.4824\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.7322 1.5391 (0.3298, 13.0069) - mae: 1.7435 0.9900 (0.2000, 8.3829) - mse: 14.3818 1.1847 (0.0544, 84.5908) - rmse: 1.9320 1.0883 (0.2332, 9.1973)\n",
      "\n",
      "Epoch 00016: val_loss improved from 37.34920 to 35.43258, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 17/1000\n",
      "84/84 [==============================] - 36s 428ms/step - loss: 37.8794 - output_0_loss: 24.2916 - output_1_loss: 13.5877 - val_loss: 34.7290 - val_output_0_loss: 22.4048 - val_output_1_loss: 12.3242\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.5869 1.6321 (0.3124, 11.5736) - mae: 1.6475 1.0300 (0.1898, 7.5010) - mse: 11.4246 1.3339 (0.0488, 66.9746) - rmse: 1.8292 1.1541 (0.2209, 8.1838)\n",
      "\n",
      "Epoch 00017: val_loss improved from 35.43258 to 34.72899, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 18/1000\n",
      "84/84 [==============================] - 38s 456ms/step - loss: 36.8937 - output_0_loss: 23.7255 - output_1_loss: 13.1682 - val_loss: 34.2345 - val_output_0_loss: 22.1591 - val_output_1_loss: 12.0754\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.5680 1.7379 (0.3200, 10.6994) - mae: 1.6337 1.1100 (0.2000, 6.6084) - mse: 12.2533 1.5102 (0.0512, 57.2381) - rmse: 1.8158 1.2289 (0.2263, 7.5656)\n",
      "\n",
      "Epoch 00018: val_loss improved from 34.72899 to 34.23453, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 19/1000\n",
      "84/84 [==============================] - 35s 422ms/step - loss: 36.2280 - output_0_loss: 23.3008 - output_1_loss: 12.9272 - val_loss: 33.5475 - val_output_0_loss: 21.6257 - val_output_1_loss: 11.9219\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.4675 1.6888 (0.3599, 9.2493) - mae: 1.5676 1.0760 (0.2200, 5.8615) - mse: 9.2089 1.4262 (0.0648, 42.7744) - rmse: 1.7448 1.1942 (0.2545, 6.5402)\n",
      "\n",
      "Epoch 00019: val_loss improved from 34.23453 to 33.54755, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 20/1000\n",
      "84/84 [==============================] - 37s 438ms/step - loss: 35.4976 - output_0_loss: 22.8384 - output_1_loss: 12.6592 - val_loss: 31.7553 - val_output_0_loss: 20.7555 - val_output_1_loss: 10.9998\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.3572 1.5869 (0.2828, 10.2201) - mae: 1.4985 0.9700 (0.1800, 6.4003) - mse: 9.0123 1.2593 (0.0400, 52.2248) - rmse: 1.6668 1.1221 (0.2000, 7.2267)\n",
      "\n",
      "Epoch 00020: val_loss improved from 33.54755 to 31.75530, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 21/1000\n",
      "84/84 [==============================] - 36s 432ms/step - loss: 34.6835 - output_0_loss: 22.3039 - output_1_loss: 12.3796 - val_loss: 31.5623 - val_output_0_loss: 20.7261 - val_output_1_loss: 10.8361\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.3812 1.5126 (0.2680, 10.1522) - mae: 1.5199 0.9850 (0.1600, 6.3802) - mse: 9.8236 1.1442 (0.0359, 51.5332) - rmse: 1.6838 1.0696 (0.1895, 7.1787)\n",
      "\n",
      "Epoch 00021: val_loss improved from 31.75530 to 31.56227, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 22/1000\n",
      "84/84 [==============================] - 38s 451ms/step - loss: 34.4331 - output_0_loss: 22.1382 - output_1_loss: 12.2949 - val_loss: 33.7011 - val_output_0_loss: 21.2255 - val_output_1_loss: 12.4756\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.6841 1.9687 (0.4337, 9.6959) - mae: 1.7089 1.2636 (0.2600, 6.3152) - mse: 10.0134 1.9382 (0.0940, 47.0054) - rmse: 1.8980 1.3921 (0.3066, 6.8560)\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 31.56227\n",
      "Epoch 23/1000\n",
      "84/84 [==============================] - 36s 432ms/step - loss: 33.4564 - output_0_loss: 21.6183 - output_1_loss: 11.8381 - val_loss: 32.2479 - val_output_0_loss: 21.1458 - val_output_1_loss: 11.1021\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.4591 1.5720 (0.3574, 10.1499) - mae: 1.5582 1.0100 (0.2200, 6.4312) - mse: 10.2904 1.2356 (0.0639, 51.5107) - rmse: 1.7388 1.1116 (0.2527, 7.1771)\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 31.56227\n",
      "Epoch 24/1000\n",
      "84/84 [==============================] - 39s 460ms/step - loss: 32.8300 - output_0_loss: 21.2371 - output_1_loss: 11.5928 - val_loss: 31.0438 - val_output_0_loss: 19.8836 - val_output_1_loss: 11.1602\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.4771 1.7904 (0.3578, 9.7997) - mae: 1.5775 1.1300 (0.2200, 6.3867) - mse: 9.8173 1.6034 (0.0640, 48.0173) - rmse: 1.7516 1.2660 (0.2530, 6.9295)\n",
      "\n",
      "Epoch 00024: val_loss improved from 31.56227 to 31.04382, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 25/1000\n",
      "84/84 [==============================] - 36s 433ms/step - loss: 32.7696 - output_0_loss: 21.0972 - output_1_loss: 11.6724 - val_loss: 31.2296 - val_output_0_loss: 20.1222 - val_output_1_loss: 11.1074\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.5044 1.7067 (0.3578, 9.4923) - mae: 1.5896 1.0650 (0.2200, 6.1189) - mse: 11.3086 1.4568 (0.0640, 45.0523) - rmse: 1.7709 1.2068 (0.2530, 6.7121)\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 31.04382\n",
      "Epoch 26/1000\n",
      "84/84 [==============================] - 38s 448ms/step - loss: 32.0395 - output_0_loss: 20.7407 - output_1_loss: 11.2987 - val_loss: 30.3471 - val_output_0_loss: 19.8620 - val_output_1_loss: 10.4851\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.2988 1.5510 (0.2800, 9.3042) - mae: 1.4648 0.9600 (0.1600, 5.9230) - mse: 9.8792 1.2030 (0.0392, 43.2838) - rmse: 1.6255 1.0967 (0.1980, 6.5790)\n",
      "\n",
      "Epoch 00026: val_loss improved from 31.04382 to 30.34709, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 27/1000\n",
      "84/84 [==============================] - 37s 436ms/step - loss: 31.9804 - output_0_loss: 20.6739 - output_1_loss: 11.3065 - val_loss: 29.5350 - val_output_0_loss: 19.3067 - val_output_1_loss: 10.2283\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.3520 1.6384 (0.3019, 9.1816) - mae: 1.4912 1.0200 (0.1934, 5.8805) - mse: 9.5087 1.3422 (0.0456, 42.1506) - rmse: 1.6631 1.1585 (0.2135, 6.4923)\n",
      "\n",
      "Epoch 00027: val_loss improved from 30.34709 to 29.53500, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 28/1000\n",
      "84/84 [==============================] - 36s 433ms/step - loss: 31.4567 - output_0_loss: 20.2615 - output_1_loss: 11.1952 - val_loss: 29.7951 - val_output_0_loss: 19.2182 - val_output_1_loss: 10.5769\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.4159 1.7000 (0.3688, 9.3529) - mae: 1.5340 1.0524 (0.2246, 5.9261) - mse: 9.2212 1.4450 (0.0680, 43.7382) - rmse: 1.7083 1.2021 (0.2608, 6.6135)\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 29.53500\n",
      "Epoch 29/1000\n",
      "84/84 [==============================] - 37s 439ms/step - loss: 30.8867 - output_0_loss: 19.9155 - output_1_loss: 10.9712 - val_loss: 27.9875 - val_output_0_loss: 17.9795 - val_output_1_loss: 10.0080\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.3088 1.4228 (0.2561, 9.9297) - mae: 1.4655 0.8750 (0.1600, 6.1777) - mse: 10.3172 1.0128 (0.0328, 49.2995) - rmse: 1.6326 1.0061 (0.1811, 7.0214)\n",
      "\n",
      "Epoch 00029: val_loss improved from 29.53500 to 27.98748, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 30/1000\n",
      "84/84 [==============================] - 36s 431ms/step - loss: 30.5568 - output_0_loss: 19.5680 - output_1_loss: 10.9887 - val_loss: 29.2291 - val_output_0_loss: 18.2186 - val_output_1_loss: 11.0105\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.4682 1.8510 (0.4078, 9.3251) - mae: 1.5708 1.1288 (0.2600, 5.8609) - mse: 8.6105 1.7134 (0.0831, 43.4784) - rmse: 1.7453 1.3089 (0.2883, 6.5938)\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 27.98748\n",
      "Epoch 31/1000\n",
      "84/84 [==============================] - 37s 439ms/step - loss: 30.3501 - output_0_loss: 19.3069 - output_1_loss: 11.0432 - val_loss: 28.3343 - val_output_0_loss: 18.0650 - val_output_1_loss: 10.2693\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.3604 1.6818 (0.3688, 8.4739) - mae: 1.4967 1.0650 (0.2200, 5.4556) - mse: 8.4616 1.4146 (0.0680, 35.9034) - rmse: 1.6690 1.1892 (0.2608, 5.9919)\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 27.98748\n",
      "Epoch 32/1000\n",
      "84/84 [==============================] - 36s 433ms/step - loss: 29.3488 - output_0_loss: 18.6776 - output_1_loss: 10.6712 - val_loss: 27.2635 - val_output_0_loss: 17.1144 - val_output_1_loss: 10.1492\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.3183 1.6729 (0.3794, 8.6848) - mae: 1.4721 1.0300 (0.2400, 5.5602) - mse: 7.9809 1.3994 (0.0720, 37.7126) - rmse: 1.6393 1.1829 (0.2683, 6.1411)\n",
      "\n",
      "Epoch 00032: val_loss improved from 27.98748 to 27.26354, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 33/1000\n",
      "84/84 [==============================] - 36s 427ms/step - loss: 28.7776 - output_0_loss: 18.3406 - output_1_loss: 10.4369 - val_loss: 25.8893 - val_output_0_loss: 16.4950 - val_output_1_loss: 9.3944\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1377 1.5077 (0.2828, 8.0232) - mae: 1.3503 0.9300 (0.1800, 5.0089) - mse: 6.7004 1.1366 (0.0400, 32.1863) - rmse: 1.5116 1.0661 (0.2000, 5.6733)\n",
      "\n",
      "Epoch 00033: val_loss improved from 27.26354 to 25.88934, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 34/1000\n",
      "84/84 [==============================] - 37s 440ms/step - loss: 28.7866 - output_0_loss: 18.2213 - output_1_loss: 10.5654 - val_loss: 26.8944 - val_output_0_loss: 16.8720 - val_output_1_loss: 10.0224\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.2792 1.6146 (0.3124, 8.7828) - mae: 1.4508 1.0232 (0.2000, 5.6163) - mse: 7.3323 1.3036 (0.0488, 38.5689) - rmse: 1.6116 1.1417 (0.2209, 6.2104)\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 25.88934\n",
      "Epoch 35/1000\n",
      "84/84 [==============================] - 36s 430ms/step - loss: 28.2948 - output_0_loss: 17.8997 - output_1_loss: 10.3951 - val_loss: 25.8282 - val_output_0_loss: 16.1785 - val_output_1_loss: 9.6497\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.2717 1.5446 (0.3225, 8.9360) - mae: 1.4466 0.9650 (0.2000, 5.8210) - mse: 9.0839 1.1930 (0.0520, 39.9267) - rmse: 1.6064 1.0922 (0.2280, 6.3187)\n",
      "\n",
      "Epoch 00035: val_loss improved from 25.88934 to 25.82818, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 36/1000\n",
      "84/84 [==============================] - 37s 437ms/step - loss: 28.0417 - output_0_loss: 17.8107 - output_1_loss: 10.2310 - val_loss: 27.1758 - val_output_0_loss: 17.0971 - val_output_1_loss: 10.0787\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.3641 1.6627 (0.3298, 9.3636) - mae: 1.5036 1.0550 (0.2002, 5.8570) - mse: 10.4434 1.3824 (0.0544, 43.8382) - rmse: 1.6716 1.1757 (0.2332, 6.6210)\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 25.82818\n",
      "Epoch 37/1000\n",
      "84/84 [==============================] - 37s 436ms/step - loss: 27.7761 - output_0_loss: 17.6275 - output_1_loss: 10.1487 - val_loss: 25.9174 - val_output_0_loss: 16.2299 - val_output_1_loss: 9.6875\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.2649 1.5122 (0.3418, 8.4805) - mae: 1.4378 0.9598 (0.2200, 5.4369) - mse: 7.6866 1.1438 (0.0584, 35.9597) - rmse: 1.6015 1.0693 (0.2417, 5.9966)\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 25.82818\n",
      "Epoch 38/1000\n",
      "84/84 [==============================] - 37s 435ms/step - loss: 27.7834 - output_0_loss: 17.5491 - output_1_loss: 10.2343 - val_loss: 26.3035 - val_output_0_loss: 16.1929 - val_output_1_loss: 10.1106\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.3693 1.7248 (0.4000, 9.0377) - mae: 1.5009 1.1100 (0.2600, 5.5607) - mse: 8.2670 1.4874 (0.0800, 40.8405) - rmse: 1.6754 1.2196 (0.2828, 6.3906)\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 25.82818\n",
      "Epoch 39/1000\n",
      "84/84 [==============================] - 36s 431ms/step - loss: 27.0519 - output_0_loss: 17.1430 - output_1_loss: 9.9089 - val_loss: 24.9869 - val_output_0_loss: 15.7215 - val_output_1_loss: 9.2654\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1999 1.4296 (0.2561, 8.7746) - mae: 1.3970 0.8900 (0.1600, 5.8204) - mse: 8.3837 1.0219 (0.0328, 38.4968) - rmse: 1.5556 1.0109 (0.1811, 6.2046)\n",
      "\n",
      "Epoch 00039: val_loss improved from 25.82818 to 24.98689, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 40/1000\n",
      "84/84 [==============================] - 36s 425ms/step - loss: 26.7758 - output_0_loss: 16.8934 - output_1_loss: 9.8824 - val_loss: 25.1324 - val_output_0_loss: 15.5244 - val_output_1_loss: 9.6080\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.2387 1.5925 (0.3298, 8.6371) - mae: 1.4217 1.0050 (0.2000, 5.5239) - mse: 7.7559 1.2684 (0.0544, 37.2994) - rmse: 1.5830 1.1261 (0.2332, 6.1073)\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 24.98689\n",
      "Epoch 41/1000\n",
      "84/84 [==============================] - 37s 436ms/step - loss: 27.0517 - output_0_loss: 17.0191 - output_1_loss: 10.0327 - val_loss: 25.6311 - val_output_0_loss: 15.7648 - val_output_1_loss: 9.8663\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.3161 1.6895 (0.3688, 8.6807) - mae: 1.4777 1.0600 (0.2400, 5.4763) - mse: 8.0801 1.4275 (0.0680, 37.6771) - rmse: 1.6377 1.1947 (0.2608, 6.1382)\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 24.98689\n",
      "Epoch 42/1000\n",
      "84/84 [==============================] - 36s 430ms/step - loss: 26.3593 - output_0_loss: 16.6328 - output_1_loss: 9.7265 - val_loss: 25.4601 - val_output_0_loss: 15.7807 - val_output_1_loss: 9.6794\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.2864 1.6483 (0.3771, 8.7076) - mae: 1.4512 1.0600 (0.2400, 5.5352) - mse: 7.4931 1.3590 (0.0711, 37.9109) - rmse: 1.6167 1.1655 (0.2667, 6.1572)\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 24.98689\n",
      "Epoch 43/1000\n",
      "84/84 [==============================] - 37s 437ms/step - loss: 26.1169 - output_0_loss: 16.4863 - output_1_loss: 9.6306 - val_loss: 24.1999 - val_output_0_loss: 15.1075 - val_output_1_loss: 9.0924\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1454 1.5793 (0.3299, 8.1887) - mae: 1.3618 0.9950 (0.2000, 5.0903) - mse: 6.7527 1.2472 (0.0544, 33.5275) - rmse: 1.5171 1.1168 (0.2332, 5.7903)\n",
      "\n",
      "Epoch 00043: val_loss improved from 24.98689 to 24.19985, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 44/1000\n",
      "84/84 [==============================] - 37s 437ms/step - loss: 26.1351 - output_0_loss: 16.4880 - output_1_loss: 9.6471 - val_loss: 24.6663 - val_output_0_loss: 15.2169 - val_output_1_loss: 9.4494\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.2662 1.5930 (0.3441, 9.0216) - mae: 1.4416 1.0000 (0.2200, 5.3801) - mse: 9.4024 1.2688 (0.0592, 40.6944) - rmse: 1.6025 1.1264 (0.2433, 6.3792)\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 24.19985\n",
      "Epoch 45/1000\n",
      "84/84 [==============================] - 36s 426ms/step - loss: 26.1036 - output_0_loss: 16.4691 - output_1_loss: 9.6344 - val_loss: 24.0527 - val_output_0_loss: 14.9412 - val_output_1_loss: 9.1115\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1609 1.5443 (0.2885, 8.4917) - mae: 1.3703 0.9750 (0.1800, 5.1454) - mse: 7.0354 1.1924 (0.0416, 36.0546) - rmse: 1.5280 1.0920 (0.2040, 6.0046)\n",
      "\n",
      "Epoch 00045: val_loss improved from 24.19985 to 24.05269, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 46/1000\n",
      "84/84 [==============================] - 36s 431ms/step - loss: 25.4013 - output_0_loss: 16.0410 - output_1_loss: 9.3603 - val_loss: 25.3949 - val_output_0_loss: 15.6740 - val_output_1_loss: 9.7208\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.3342 1.7185 (0.3599, 8.3114) - mae: 1.4827 1.1000 (0.2200, 5.2387) - mse: 9.4777 1.4766 (0.0648, 34.5395) - rmse: 1.6505 1.2151 (0.2545, 5.8770)\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 24.05269\n",
      "Epoch 47/1000\n",
      "84/84 [==============================] - 37s 445ms/step - loss: 25.5021 - output_0_loss: 16.0803 - output_1_loss: 9.4218 - val_loss: 24.1083 - val_output_0_loss: 14.9174 - val_output_1_loss: 9.1909\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1553 1.5892 (0.3418, 8.0893) - mae: 1.3719 1.0000 (0.2102, 5.0540) - mse: 6.5669 1.2630 (0.0584, 32.7184) - rmse: 1.5240 1.1238 (0.2417, 5.7200)\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 24.05269\n",
      "Epoch 48/1000\n",
      "84/84 [==============================] - 37s 438ms/step - loss: 25.5172 - output_0_loss: 16.0328 - output_1_loss: 9.4844 - val_loss: 23.1121 - val_output_0_loss: 14.3926 - val_output_1_loss: 8.7195\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0971 1.4919 (0.3225, 8.3684) - mae: 1.3320 0.9400 (0.2000, 5.1044) - mse: 7.0043 1.1130 (0.0520, 35.0153) - rmse: 1.4829 1.0549 (0.2280, 5.9174)\n",
      "\n",
      "Epoch 00048: val_loss improved from 24.05269 to 23.11213, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 49/1000\n",
      "84/84 [==============================] - 37s 442ms/step - loss: 25.0371 - output_0_loss: 15.7235 - output_1_loss: 9.3136 - val_loss: 24.1281 - val_output_0_loss: 14.7389 - val_output_1_loss: 9.3892\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.2604 1.6745 (0.3686, 8.8023) - mae: 1.4326 1.0700 (0.2200, 5.4898) - mse: 8.2241 1.4020 (0.0679, 38.7402) - rmse: 1.5983 1.1840 (0.2606, 6.2242)\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 23.11213\n",
      "Epoch 50/1000\n",
      "84/84 [==============================] - 38s 453ms/step - loss: 25.3023 - output_0_loss: 15.8816 - output_1_loss: 9.4206 - val_loss: 23.5782 - val_output_0_loss: 14.6633 - val_output_1_loss: 8.9150\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1346 1.4894 (0.2912, 8.5451) - mae: 1.3561 0.9450 (0.1800, 5.2940) - mse: 7.8894 1.1092 (0.0424, 36.5095) - rmse: 1.5094 1.0532 (0.2059, 6.0423)\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 23.11213\n",
      "Epoch 51/1000\n",
      "84/84 [==============================] - 36s 430ms/step - loss: 24.6325 - output_0_loss: 15.4597 - output_1_loss: 9.1728 - val_loss: 23.9902 - val_output_0_loss: 14.9290 - val_output_1_loss: 9.0612\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.2603 1.4258 (0.3043, 9.6832) - mae: 1.4386 0.9050 (0.1800, 6.2555) - mse: 10.8905 1.0164 (0.0463, 46.8818) - rmse: 1.5983 1.0082 (0.2152, 6.8470)\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 23.11213\n",
      "Epoch 52/1000\n",
      "84/84 [==============================] - 36s 429ms/step - loss: 24.5932 - output_0_loss: 15.4139 - output_1_loss: 9.1793 - val_loss: 23.3211 - val_output_0_loss: 14.5146 - val_output_1_loss: 8.8066\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1051 1.4979 (0.3298, 7.9410) - mae: 1.3375 0.9500 (0.2200, 5.0805) - mse: 6.2994 1.1230 (0.0544, 31.5298) - rmse: 1.4886 1.0592 (0.2332, 5.6151)\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 23.11213\n",
      "Epoch 53/1000\n",
      "84/84 [==============================] - 37s 439ms/step - loss: 24.4972 - output_0_loss: 15.3395 - output_1_loss: 9.1577 - val_loss: 23.3745 - val_output_0_loss: 14.4302 - val_output_1_loss: 8.9444\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1963 1.5329 (0.3225, 8.5852) - mae: 1.3976 0.9764 (0.2000, 5.1800) - mse: 8.5287 1.1750 (0.0520, 36.8528) - rmse: 1.5530 1.0839 (0.2280, 6.0706)\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 23.11213\n",
      "Epoch 54/1000\n",
      "84/84 [==============================] - 37s 439ms/step - loss: 24.2490 - output_0_loss: 15.1862 - output_1_loss: 9.0628 - val_loss: 23.0001 - val_output_0_loss: 14.4470 - val_output_1_loss: 8.5530\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0674 1.3797 (0.3225, 8.3340) - mae: 1.3123 0.8800 (0.2000, 5.2952) - mse: 7.1019 0.9518 (0.0520, 34.7281) - rmse: 1.4619 0.9756 (0.2280, 5.8931)\n",
      "\n",
      "Epoch 00054: val_loss improved from 23.11213 to 23.00005, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 55/1000\n",
      "84/84 [==============================] - 36s 431ms/step - loss: 24.1420 - output_0_loss: 15.1348 - output_1_loss: 9.0072 - val_loss: 23.3374 - val_output_0_loss: 14.3737 - val_output_1_loss: 8.9637\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1930 1.5028 (0.2828, 8.9387) - mae: 1.4058 0.9450 (0.1800, 5.6410) - mse: 9.5300 1.1301 (0.0400, 39.9500) - rmse: 1.5507 1.0627 (0.2000, 6.3206)\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 23.00005\n",
      "Epoch 56/1000\n",
      "84/84 [==============================] - 36s 431ms/step - loss: 24.3240 - output_0_loss: 15.1555 - output_1_loss: 9.1685 - val_loss: 22.1473 - val_output_0_loss: 13.7772 - val_output_1_loss: 8.3701\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0417 1.4050 (0.2828, 8.0775) - mae: 1.3005 0.8920 (0.1800, 5.1405) - mse: 6.9901 0.9878 (0.0400, 32.6227) - rmse: 1.4437 0.9935 (0.1999, 5.7116)\n",
      "\n",
      "Epoch 00056: val_loss improved from 23.00005 to 22.14727, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 57/1000\n",
      "84/84 [==============================] - 37s 443ms/step - loss: 23.8181 - output_0_loss: 14.9160 - output_1_loss: 8.9021 - val_loss: 21.8968 - val_output_0_loss: 13.7181 - val_output_1_loss: 8.1787\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0142 1.3802 (0.2530, 8.2194) - mae: 1.2852 0.8750 (0.1600, 5.3408) - mse: 7.0189 0.9530 (0.0320, 33.7800) - rmse: 1.4243 0.9760 (0.1789, 5.8120)\n",
      "\n",
      "Epoch 00057: val_loss improved from 22.14727 to 21.89685, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 58/1000\n",
      "84/84 [==============================] - 37s 441ms/step - loss: 23.8923 - output_0_loss: 14.9164 - output_1_loss: 8.9760 - val_loss: 23.3203 - val_output_0_loss: 14.3906 - val_output_1_loss: 8.9297\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.2115 1.6453 (0.3774, 7.8507) - mae: 1.4076 1.0400 (0.2400, 5.1202) - mse: 7.6644 1.3536 (0.0712, 30.8171) - rmse: 1.5638 1.1634 (0.2668, 5.5513)\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 21.89685\n",
      "Epoch 59/1000\n",
      "84/84 [==============================] - 36s 429ms/step - loss: 23.6902 - output_0_loss: 14.7419 - output_1_loss: 8.9483 - val_loss: 21.3828 - val_output_0_loss: 13.4360 - val_output_1_loss: 7.9467\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9952 1.4070 (0.2883, 7.9155) - mae: 1.2698 0.8950 (0.1800, 5.0208) - mse: 6.9062 0.9908 (0.0416, 31.3273) - rmse: 1.4108 0.9949 (0.2039, 5.5971)\n",
      "\n",
      "Epoch 00059: val_loss improved from 21.89685 to 21.38276, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 60/1000\n",
      "84/84 [==============================] - 36s 433ms/step - loss: 23.8840 - output_0_loss: 14.8495 - output_1_loss: 9.0345 - val_loss: 22.3370 - val_output_0_loss: 13.5681 - val_output_1_loss: 8.7689\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1069 1.5415 (0.3225, 7.9597) - mae: 1.3432 0.9800 (0.2000, 5.0019) - mse: 6.2964 1.1889 (0.0520, 31.6786) - rmse: 1.4898 1.0900 (0.2280, 5.6284)\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 21.38276\n",
      "Epoch 61/1000\n",
      "84/84 [==============================] - 36s 431ms/step - loss: 23.5599 - output_0_loss: 14.6243 - output_1_loss: 8.9356 - val_loss: 22.5179 - val_output_0_loss: 13.6904 - val_output_1_loss: 8.8275\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1389 1.4857 (0.3225, 8.2284) - mae: 1.3602 0.9450 (0.2000, 5.1255) - mse: 6.8528 1.1038 (0.0520, 33.8533) - rmse: 1.5124 1.0506 (0.2280, 5.8184)\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 21.38276\n",
      "Epoch 62/1000\n",
      "84/84 [==============================] - 36s 426ms/step - loss: 23.2600 - output_0_loss: 14.4451 - output_1_loss: 8.8148 - val_loss: 22.5158 - val_output_0_loss: 13.7257 - val_output_1_loss: 8.7902\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1719 1.6186 (0.3578, 8.4451) - mae: 1.3789 1.0099 (0.2200, 5.2005) - mse: 6.9185 1.3100 (0.0640, 35.6595) - rmse: 1.5358 1.1445 (0.2530, 5.9716)\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 21.38276\n",
      "Epoch 63/1000\n",
      "84/84 [==============================] - 36s 429ms/step - loss: 23.2859 - output_0_loss: 14.4457 - output_1_loss: 8.8403 - val_loss: 22.4812 - val_output_0_loss: 13.6144 - val_output_1_loss: 8.8668\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1842 1.5479 (0.3288, 8.6467) - mae: 1.3907 0.9600 (0.2000, 5.4806) - mse: 8.2117 1.1980 (0.0541, 37.3829) - rmse: 1.5445 1.0945 (0.2325, 6.1142)\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 21.38276\n",
      "Epoch 64/1000\n",
      "84/84 [==============================] - 37s 437ms/step - loss: 23.2301 - output_0_loss: 14.3938 - output_1_loss: 8.8364 - val_loss: 22.6211 - val_output_0_loss: 13.6931 - val_output_1_loss: 8.9280\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1820 1.5436 (0.3392, 7.9860) - mae: 1.3890 0.9700 (0.2102, 5.2005) - mse: 8.8466 1.1914 (0.0575, 31.8881) - rmse: 1.5429 1.0915 (0.2398, 5.6470)\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 21.38276\n",
      "Epoch 65/1000\n",
      "84/84 [==============================] - 37s 435ms/step - loss: 23.1962 - output_0_loss: 14.4127 - output_1_loss: 8.7835 - val_loss: 21.7911 - val_output_0_loss: 13.2051 - val_output_1_loss: 8.5860\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1448 1.5359 (0.3200, 8.1133) - mae: 1.3671 0.9800 (0.2000, 5.1141) - mse: 8.0415 1.1794 (0.0512, 32.9131) - rmse: 1.5166 1.0860 (0.2263, 5.7370)\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 21.38276\n",
      "Epoch 66/1000\n",
      "84/84 [==============================] - 37s 436ms/step - loss: 23.0572 - output_0_loss: 14.3043 - output_1_loss: 8.7528 - val_loss: 21.6831 - val_output_0_loss: 13.2582 - val_output_1_loss: 8.4249\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1150 1.4080 (0.2912, 8.8736) - mae: 1.3483 0.8800 (0.1800, 5.6167) - mse: 8.0206 0.9912 (0.0424, 39.3708) - rmse: 1.4955 0.9956 (0.2059, 6.2746)\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 21.38276\n",
      "Epoch 67/1000\n",
      "84/84 [==============================] - 37s 436ms/step - loss: 23.1063 - output_0_loss: 14.2693 - output_1_loss: 8.8369 - val_loss: 21.9234 - val_output_0_loss: 13.3561 - val_output_1_loss: 8.5673\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1693 1.5441 (0.3124, 7.9288) - mae: 1.3785 0.9699 (0.2000, 5.1207) - mse: 8.2048 1.1922 (0.0488, 31.4331) - rmse: 1.5339 1.0919 (0.2209, 5.6065)\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 21.38276\n",
      "Epoch 68/1000\n",
      "84/84 [==============================] - 37s 442ms/step - loss: 22.4958 - output_0_loss: 13.9027 - output_1_loss: 8.5931 - val_loss: 24.8953 - val_output_0_loss: 14.3747 - val_output_1_loss: 10.5205\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.5135 1.9181 (0.4833, 8.6142) - mae: 1.5871 1.1550 (0.3000, 5.5298) - mse: 8.3189 1.8404 (0.1168, 37.1026) - rmse: 1.7773 1.3563 (0.3417, 6.0912)\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 21.38276\n",
      "Epoch 69/1000\n",
      "84/84 [==============================] - 36s 430ms/step - loss: 22.7062 - output_0_loss: 14.0784 - output_1_loss: 8.6278 - val_loss: 20.8831 - val_output_0_loss: 12.9359 - val_output_1_loss: 7.9472\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9535 1.3367 (0.2912, 7.8769) - mae: 1.2418 0.8550 (0.1800, 4.9226) - mse: 5.8035 0.8938 (0.0424, 31.0228) - rmse: 1.3813 0.9452 (0.2059, 5.5698)\n",
      "\n",
      "Epoch 00069: val_loss improved from 21.38276 to 20.88308, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 70/1000\n",
      "84/84 [==============================] - 36s 434ms/step - loss: 22.3257 - output_0_loss: 13.8838 - output_1_loss: 8.4419 - val_loss: 21.3218 - val_output_0_loss: 13.1119 - val_output_1_loss: 8.2099\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0392 1.4641 (0.2912, 8.1208) - mae: 1.3013 0.9250 (0.2000, 5.1000) - mse: 7.4080 1.0718 (0.0424, 32.9739) - rmse: 1.4419 1.0353 (0.2059, 5.7423)\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 20.88308\n",
      "Epoch 71/1000\n",
      "84/84 [==============================] - 37s 439ms/step - loss: 22.2405 - output_0_loss: 13.7427 - output_1_loss: 8.4977 - val_loss: 21.1677 - val_output_0_loss: 12.9617 - val_output_1_loss: 8.2060\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0442 1.4375 (0.3046, 8.1711) - mae: 1.3001 0.9200 (0.2000, 5.1565) - mse: 6.5090 1.0338 (0.0464, 33.3838) - rmse: 1.4455 1.0165 (0.2154, 5.7779)\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 20.88308\n",
      "Epoch 72/1000\n",
      "84/84 [==============================] - 36s 432ms/step - loss: 22.1561 - output_0_loss: 13.6844 - output_1_loss: 8.4717 - val_loss: 20.9412 - val_output_0_loss: 12.6946 - val_output_1_loss: 8.2466\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0374 1.4445 (0.3046, 7.8858) - mae: 1.2931 0.9250 (0.1800, 4.8600) - mse: 6.1455 1.0434 (0.0464, 31.0931) - rmse: 1.4407 1.0214 (0.2154, 5.5761)\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 20.88308\n",
      "Epoch 73/1000\n",
      "84/84 [==============================] - 36s 431ms/step - loss: 22.1052 - output_0_loss: 13.6626 - output_1_loss: 8.4427 - val_loss: 20.3141 - val_output_0_loss: 12.3355 - val_output_1_loss: 7.9786\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0235 1.3186 (0.2797, 8.1756) - mae: 1.2847 0.8332 (0.1695, 5.3200) - mse: 7.6112 0.8694 (0.0391, 33.4201) - rmse: 1.4308 0.9324 (0.1978, 5.7810)\n",
      "\n",
      "Epoch 00073: val_loss improved from 20.88308 to 20.31411, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 74/1000\n",
      "84/84 [==============================] - 37s 435ms/step - loss: 21.9997 - output_0_loss: 13.6314 - output_1_loss: 8.3683 - val_loss: 21.7080 - val_output_0_loss: 12.9913 - val_output_1_loss: 8.7167\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1872 1.6536 (0.3298, 8.0845) - mae: 1.3870 1.0075 (0.2152, 5.0452) - mse: 6.5914 1.3673 (0.0544, 32.6799) - rmse: 1.5466 1.1692 (0.2332, 5.7166)\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 20.31411\n",
      "Epoch 75/1000\n",
      "84/84 [==============================] - 37s 437ms/step - loss: 21.9789 - output_0_loss: 13.5444 - output_1_loss: 8.4345 - val_loss: 20.1367 - val_output_0_loss: 12.3034 - val_output_1_loss: 7.8333\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0299 1.3677 (0.2883, 7.8613) - mae: 1.2938 0.8800 (0.1800, 4.9803) - mse: 8.3472 0.9354 (0.0416, 30.8997) - rmse: 1.4354 0.9671 (0.2039, 5.5587)\n",
      "\n",
      "Epoch 00075: val_loss improved from 20.31411 to 20.13670, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 76/1000\n",
      "84/84 [==============================] - 38s 447ms/step - loss: 21.9571 - output_0_loss: 13.6262 - output_1_loss: 8.3309 - val_loss: 22.4082 - val_output_0_loss: 13.3903 - val_output_1_loss: 9.0179\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.2622 1.6416 (0.3940, 8.7279) - mae: 1.4340 1.0300 (0.2400, 5.5422) - mse: 8.5892 1.3474 (0.0776, 38.0884) - rmse: 1.5996 1.1608 (0.2786, 6.1716)\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 20.13670\n",
      "Epoch 77/1000\n",
      "84/84 [==============================] - 37s 437ms/step - loss: 21.6988 - output_0_loss: 13.3888 - output_1_loss: 8.3101 - val_loss: 20.8603 - val_output_0_loss: 12.6163 - val_output_1_loss: 8.2439\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0925 1.4289 (0.2683, 8.3448) - mae: 1.3324 0.9050 (0.1800, 5.2536) - mse: 7.4967 1.0216 (0.0360, 34.8182) - rmse: 1.4796 1.0104 (0.1897, 5.9007)\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 20.13670\n",
      "Epoch 78/1000\n",
      "84/84 [==============================] - 37s 441ms/step - loss: 21.8760 - output_0_loss: 13.4284 - output_1_loss: 8.4476 - val_loss: 20.9109 - val_output_0_loss: 12.6246 - val_output_1_loss: 8.2863\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0659 1.4888 (0.2884, 8.4326) - mae: 1.3126 0.9500 (0.1800, 5.2812) - mse: 7.0569 1.1082 (0.0416, 35.5551) - rmse: 1.4608 1.0527 (0.2040, 5.9628)\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 20.13670\n",
      "Epoch 79/1000\n",
      "84/84 [==============================] - 37s 438ms/step - loss: 21.6533 - output_0_loss: 13.3155 - output_1_loss: 8.3379 - val_loss: 21.2207 - val_output_0_loss: 12.6144 - val_output_1_loss: 8.6062\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1465 1.5165 (0.3225, 8.0063) - mae: 1.3607 0.9600 (0.2100, 5.2146) - mse: 6.9474 1.1502 (0.0520, 32.0501) - rmse: 1.5178 1.0723 (0.2280, 5.6613)\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 20.13670\n",
      "Epoch 80/1000\n",
      "84/84 [==============================] - 38s 448ms/step - loss: 21.6879 - output_0_loss: 13.3568 - output_1_loss: 8.3311 - val_loss: 20.0740 - val_output_0_loss: 12.2135 - val_output_1_loss: 7.8605\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9974 1.3392 (0.2800, 7.9045) - mae: 1.2757 0.8500 (0.1800, 5.0015) - mse: 7.0633 0.8968 (0.0392, 31.2407) - rmse: 1.4124 0.9470 (0.1980, 5.5893)\n",
      "\n",
      "Epoch 00080: val_loss improved from 20.13670 to 20.07396, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 81/1000\n",
      "84/84 [==============================] - 36s 431ms/step - loss: 21.4028 - output_0_loss: 13.1408 - output_1_loss: 8.2620 - val_loss: 20.5629 - val_output_0_loss: 12.3049 - val_output_1_loss: 8.2580\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1141 1.4257 (0.2828, 8.4598) - mae: 1.3479 0.8888 (0.1800, 5.3406) - mse: 9.2452 1.0164 (0.0400, 35.7839) - rmse: 1.4949 1.0081 (0.2000, 5.9820)\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 20.07396\n",
      "Epoch 82/1000\n",
      "84/84 [==============================] - 37s 444ms/step - loss: 21.4506 - output_0_loss: 13.1473 - output_1_loss: 8.3032 - val_loss: 20.7358 - val_output_0_loss: 12.4380 - val_output_1_loss: 8.2979\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1006 1.5444 (0.3200, 8.2573) - mae: 1.3394 0.9450 (0.2000, 5.2864) - mse: 7.3512 1.1927 (0.0512, 34.0912) - rmse: 1.4853 1.0921 (0.2263, 5.8388)\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 20.07396\n",
      "Epoch 83/1000\n",
      "84/84 [==============================] - 36s 434ms/step - loss: 21.2519 - output_0_loss: 13.0418 - output_1_loss: 8.2101 - val_loss: 20.9195 - val_output_0_loss: 12.5711 - val_output_1_loss: 8.3485\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0924 1.5880 (0.3578, 8.0864) - mae: 1.3259 1.0318 (0.2200, 5.1663) - mse: 6.2332 1.2622 (0.0640, 32.6949) - rmse: 1.4796 1.1229 (0.2530, 5.7179)\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 20.07396\n",
      "Epoch 84/1000\n",
      "84/84 [==============================] - 38s 455ms/step - loss: 21.2660 - output_0_loss: 13.0358 - output_1_loss: 8.2303 - val_loss: 20.6113 - val_output_0_loss: 12.1088 - val_output_1_loss: 8.5025\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1832 1.5752 (0.3297, 7.9988) - mae: 1.3823 0.9950 (0.2200, 5.2000) - mse: 8.7444 1.2408 (0.0543, 31.9907) - rmse: 1.5438 1.1138 (0.2331, 5.6560)\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 20.07396\n",
      "Epoch 85/1000\n",
      "84/84 [==============================] - 37s 436ms/step - loss: 21.1764 - output_0_loss: 13.0023 - output_1_loss: 8.1741 - val_loss: 21.7001 - val_output_0_loss: 12.8387 - val_output_1_loss: 8.8614\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.2403 1.6123 (0.3688, 8.7561) - mae: 1.4238 0.9900 (0.2400, 5.5128) - mse: 7.9807 1.2998 (0.0680, 38.3348) - rmse: 1.5841 1.1401 (0.2608, 6.1915)\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 20.07396\n",
      "Epoch 86/1000\n",
      "84/84 [==============================] - 37s 444ms/step - loss: 21.3305 - output_0_loss: 13.0735 - output_1_loss: 8.2571 - val_loss: 20.9975 - val_output_0_loss: 12.5892 - val_output_1_loss: 8.4083\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1471 1.5419 (0.3574, 7.7213) - mae: 1.3679 0.9800 (0.2200, 5.0010) - mse: 8.4241 1.1888 (0.0639, 29.8089) - rmse: 1.5182 1.0903 (0.2527, 5.4598)\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 20.07396\n",
      "Epoch 87/1000\n",
      "84/84 [==============================] - 36s 429ms/step - loss: 20.9098 - output_0_loss: 12.8076 - output_1_loss: 8.1022 - val_loss: 22.0480 - val_output_0_loss: 13.2128 - val_output_1_loss: 8.8352\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.2069 1.7587 (0.3225, 7.8746) - mae: 1.3997 1.0800 (0.2149, 4.9004) - mse: 7.4796 1.5468 (0.0520, 31.0044) - rmse: 1.5605 1.2436 (0.2280, 5.5682)\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 20.07396\n",
      "Epoch 88/1000\n",
      "84/84 [==============================] - 37s 445ms/step - loss: 20.7822 - output_0_loss: 12.7123 - output_1_loss: 8.0698 - val_loss: 20.1143 - val_output_0_loss: 11.9454 - val_output_1_loss: 8.1689\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0421 1.4607 (0.2884, 8.2327) - mae: 1.3019 0.9338 (0.1800, 5.2607) - mse: 7.1107 1.0668 (0.0416, 33.8891) - rmse: 1.4440 1.0328 (0.2040, 5.8214)\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 20.07396\n",
      "Epoch 89/1000\n",
      "84/84 [==============================] - 37s 442ms/step - loss: 20.9069 - output_0_loss: 12.7939 - output_1_loss: 8.1130 - val_loss: 19.7480 - val_output_0_loss: 11.8679 - val_output_1_loss: 7.8801\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0334 1.4377 (0.3046, 7.9336) - mae: 1.2979 0.9200 (0.1800, 5.1406) - mse: 7.6111 1.0336 (0.0464, 31.4712) - rmse: 1.4378 1.0166 (0.2154, 5.6099)\n",
      "\n",
      "Epoch 00089: val_loss improved from 20.07396 to 19.74802, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 90/1000\n",
      "84/84 [==============================] - 36s 431ms/step - loss: 20.7913 - output_0_loss: 12.7393 - output_1_loss: 8.0520 - val_loss: 21.3771 - val_output_0_loss: 12.5899 - val_output_1_loss: 8.7872\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1698 1.5766 (0.3688, 7.7702) - mae: 1.3767 0.9950 (0.2304, 5.1614) - mse: 7.3713 1.2434 (0.0680, 30.1881) - rmse: 1.5343 1.1148 (0.2608, 5.4944)\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 19.74802\n",
      "Epoch 91/1000\n",
      "84/84 [==============================] - 37s 440ms/step - loss: 20.9527 - output_0_loss: 12.7633 - output_1_loss: 8.1894 - val_loss: 20.4598 - val_output_0_loss: 11.9614 - val_output_1_loss: 8.4985\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1036 1.5255 (0.3046, 7.9250) - mae: 1.3437 0.9413 (0.2000, 5.0470) - mse: 7.5137 1.1636 (0.0464, 31.4025) - rmse: 1.4875 1.0787 (0.2154, 5.6038)\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 19.74802\n",
      "Epoch 92/1000\n",
      "84/84 [==============================] - 36s 430ms/step - loss: 21.0494 - output_0_loss: 12.7849 - output_1_loss: 8.2645 - val_loss: 19.9020 - val_output_0_loss: 11.7999 - val_output_1_loss: 8.1020\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1028 1.5142 (0.3200, 7.7502) - mae: 1.3412 0.9200 (0.2000, 4.7600) - mse: 8.1409 1.1464 (0.0512, 30.0326) - rmse: 1.4869 1.0707 (0.2263, 5.4802)\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 19.74802\n",
      "Epoch 93/1000\n",
      "84/84 [==============================] - 37s 440ms/step - loss: 20.4810 - output_0_loss: 12.5279 - output_1_loss: 7.9531 - val_loss: 21.2771 - val_output_0_loss: 12.3474 - val_output_1_loss: 8.9297\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.2498 1.7108 (0.4118, 7.7579) - mae: 1.4229 1.0600 (0.2600, 4.9404) - mse: 7.4708 1.4644 (0.0848, 30.0925) - rmse: 1.5909 1.2097 (0.2912, 5.4857)\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 19.74802\n",
      "Epoch 94/1000\n",
      "84/84 [==============================] - 38s 448ms/step - loss: 20.1621 - output_0_loss: 12.3245 - output_1_loss: 7.8376 - val_loss: 20.1539 - val_output_0_loss: 12.0184 - val_output_1_loss: 8.1354\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0727 1.3801 (0.2683, 8.2700) - mae: 1.3190 0.8800 (0.1800, 5.2005) - mse: 7.6990 0.9524 (0.0360, 34.1972) - rmse: 1.4656 0.9759 (0.1897, 5.8478)\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 19.74802\n",
      "Epoch 95/1000\n",
      "84/84 [==============================] - 38s 451ms/step - loss: 20.5240 - output_0_loss: 12.5081 - output_1_loss: 8.0160 - val_loss: 19.6974 - val_output_0_loss: 11.5514 - val_output_1_loss: 8.1459\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1298 1.4441 (0.3046, 8.4614) - mae: 1.3593 0.9050 (0.2000, 5.4529) - mse: 9.2720 1.0428 (0.0464, 35.7979) - rmse: 1.5060 1.0212 (0.2154, 5.9831)\n",
      "\n",
      "Epoch 00095: val_loss improved from 19.74802 to 19.69737, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 96/1000\n",
      "84/84 [==============================] - 36s 431ms/step - loss: 20.2563 - output_0_loss: 12.3657 - output_1_loss: 7.8906 - val_loss: 19.3080 - val_output_0_loss: 11.4439 - val_output_1_loss: 7.8641\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0528 1.4796 (0.3046, 7.9770) - mae: 1.3103 0.9003 (0.2000, 5.0811) - mse: 8.4231 1.0947 (0.0464, 31.8163) - rmse: 1.4516 1.0462 (0.2154, 5.6406)\n",
      "\n",
      "Epoch 00096: val_loss improved from 19.69737 to 19.30804, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 97/1000\n",
      "84/84 [==============================] - 37s 445ms/step - loss: 20.2197 - output_0_loss: 12.3288 - output_1_loss: 7.8909 - val_loss: 19.3001 - val_output_0_loss: 11.3684 - val_output_1_loss: 7.9317\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0892 1.4591 (0.3124, 8.2614) - mae: 1.3338 0.9100 (0.2000, 5.1610) - mse: 9.2298 1.0646 (0.0488, 34.1253) - rmse: 1.4773 1.0317 (0.2209, 5.8417)\n",
      "\n",
      "Epoch 00097: val_loss improved from 19.30804 to 19.30013, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 98/1000\n",
      "84/84 [==============================] - 36s 432ms/step - loss: 20.1704 - output_0_loss: 12.2713 - output_1_loss: 7.8991 - val_loss: 18.9900 - val_output_0_loss: 11.2956 - val_output_1_loss: 7.6944\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9571 1.2827 (0.2561, 8.2571) - mae: 1.2472 0.8000 (0.1600, 5.1600) - mse: 6.8539 0.8228 (0.0328, 34.0903) - rmse: 1.3839 0.9070 (0.1811, 5.8387)\n",
      "\n",
      "Epoch 00098: val_loss improved from 19.30013 to 18.98999, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 99/1000\n",
      "84/84 [==============================] - 37s 442ms/step - loss: 20.4063 - output_0_loss: 12.4325 - output_1_loss: 7.9738 - val_loss: 18.9671 - val_output_0_loss: 11.2732 - val_output_1_loss: 7.6939\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0150 1.3277 (0.2560, 8.6439) - mae: 1.2841 0.8400 (0.1600, 5.5015) - mse: 8.1402 0.8814 (0.0328, 37.3587) - rmse: 1.4248 0.9388 (0.1811, 6.1122)\n",
      "\n",
      "Epoch 00099: val_loss improved from 18.98999 to 18.96707, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 100/1000\n",
      "84/84 [==============================] - 37s 441ms/step - loss: 20.5583 - output_0_loss: 12.4616 - output_1_loss: 8.0967 - val_loss: 18.9155 - val_output_0_loss: 11.2551 - val_output_1_loss: 7.6604\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9398 1.4021 (0.2883, 7.5563) - mae: 1.2334 0.9000 (0.1800, 4.8425) - mse: 6.1102 0.9830 (0.0416, 28.5489) - rmse: 1.3717 0.9914 (0.2039, 5.3431)\n",
      "\n",
      "Epoch 00100: val_loss improved from 18.96707 to 18.91548, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 101/1000\n",
      "84/84 [==============================] - 36s 432ms/step - loss: 20.3342 - output_0_loss: 12.3658 - output_1_loss: 7.9684 - val_loss: 19.9672 - val_output_0_loss: 11.8191 - val_output_1_loss: 8.1481\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0967 1.5042 (0.2828, 8.5503) - mae: 1.3415 0.9500 (0.1800, 5.4210) - mse: 8.6163 1.1314 (0.0400, 36.5539) - rmse: 1.4826 1.0636 (0.2000, 6.0460)\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 18.91548\n",
      "Epoch 102/1000\n",
      "84/84 [==============================] - 37s 439ms/step - loss: 19.9768 - output_0_loss: 12.1334 - output_1_loss: 7.8434 - val_loss: 19.0769 - val_output_0_loss: 11.3566 - val_output_1_loss: 7.7203\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0089 1.4096 (0.3046, 7.8476) - mae: 1.2831 0.9000 (0.1800, 5.0223) - mse: 6.6820 0.9936 (0.0464, 30.7927) - rmse: 1.4205 0.9968 (0.2154, 5.5491)\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 18.91548\n",
      "Epoch 103/1000\n",
      "84/84 [==============================] - 37s 436ms/step - loss: 19.9961 - output_0_loss: 12.1594 - output_1_loss: 7.8367 - val_loss: 18.7981 - val_output_0_loss: 11.2354 - val_output_1_loss: 7.5628\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9400 1.3097 (0.2828, 7.5769) - mae: 1.2324 0.8100 (0.1646, 4.8535) - mse: 6.3017 0.8578 (0.0400, 28.7052) - rmse: 1.3718 0.9261 (0.1999, 5.3577)\n",
      "\n",
      "Epoch 00103: val_loss improved from 18.91548 to 18.79814, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 104/1000\n",
      "84/84 [==============================] - 37s 442ms/step - loss: 19.9901 - output_0_loss: 12.1448 - output_1_loss: 7.8453 - val_loss: 19.6498 - val_output_0_loss: 11.6987 - val_output_1_loss: 7.9511\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0444 1.4320 (0.3122, 7.6594) - mae: 1.3058 0.8950 (0.2000, 5.0209) - mse: 7.4263 1.0254 (0.0487, 29.3336) - rmse: 1.4456 1.0126 (0.2208, 5.4160)\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 18.79814\n",
      "Epoch 105/1000\n",
      "84/84 [==============================] - 36s 430ms/step - loss: 20.1101 - output_0_loss: 12.2266 - output_1_loss: 7.8834 - val_loss: 18.5231 - val_output_0_loss: 11.0644 - val_output_1_loss: 7.4587\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9427 1.3139 (0.2683, 7.7308) - mae: 1.2395 0.8350 (0.1600, 4.9415) - mse: 6.7571 0.8632 (0.0360, 29.8827) - rmse: 1.3737 0.9290 (0.1897, 5.4665)\n",
      "\n",
      "Epoch 00105: val_loss improved from 18.79814 to 18.52313, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 106/1000\n",
      "84/84 [==============================] - 36s 433ms/step - loss: 19.9156 - output_0_loss: 12.0116 - output_1_loss: 7.9040 - val_loss: 18.8338 - val_output_0_loss: 11.0412 - val_output_1_loss: 7.7926\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0376 1.4461 (0.3124, 8.0848) - mae: 1.3006 0.9050 (0.2000, 5.1239) - mse: 8.1521 1.0456 (0.0488, 32.6822) - rmse: 1.4408 1.0225 (0.2209, 5.7168)\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 18.52313\n",
      "Epoch 107/1000\n",
      "84/84 [==============================] - 37s 444ms/step - loss: 20.0076 - output_0_loss: 12.1290 - output_1_loss: 7.8786 - val_loss: 17.8683 - val_output_0_loss: 10.6620 - val_output_1_loss: 7.2062\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.8687 1.2637 (0.2400, 7.5677) - mae: 1.1891 0.8076 (0.1400, 4.9241) - mse: 6.5470 0.7987 (0.0288, 28.6348) - rmse: 1.3214 0.8936 (0.1697, 5.3511)\n",
      "\n",
      "Epoch 00107: val_loss improved from 18.52313 to 17.86829, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 108/1000\n",
      "84/84 [==============================] - 36s 434ms/step - loss: 19.7728 - output_0_loss: 12.0028 - output_1_loss: 7.7699 - val_loss: 18.3621 - val_output_0_loss: 10.8499 - val_output_1_loss: 7.5122\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9446 1.3253 (0.2884, 7.8063) - mae: 1.2372 0.8449 (0.1800, 4.9157) - mse: 6.2849 0.8786 (0.0416, 30.4689) - rmse: 1.3751 0.9371 (0.2040, 5.5199)\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 17.86829\n",
      "Epoch 109/1000\n",
      "84/84 [==============================] - 37s 436ms/step - loss: 19.5876 - output_0_loss: 11.8894 - output_1_loss: 7.6982 - val_loss: 19.4944 - val_output_0_loss: 11.7085 - val_output_1_loss: 7.7859\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9791 1.3632 (0.3043, 7.6935) - mae: 1.2626 0.8597 (0.1800, 4.8292) - mse: 6.3165 0.9292 (0.0463, 29.5953) - rmse: 1.3994 0.9639 (0.2152, 5.4402)\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 17.86829\n",
      "Epoch 110/1000\n",
      "84/84 [==============================] - 37s 440ms/step - loss: 19.8355 - output_0_loss: 12.1068 - output_1_loss: 7.7286 - val_loss: 19.7977 - val_output_0_loss: 11.6883 - val_output_1_loss: 8.1095\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0920 1.5178 (0.3440, 8.0357) - mae: 1.3220 0.9600 (0.2106, 5.1001) - mse: 6.2516 1.1518 (0.0592, 32.2863) - rmse: 1.4793 1.0732 (0.2432, 5.6821)\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 17.86829\n",
      "Epoch 111/1000\n",
      "84/84 [==============================] - 37s 437ms/step - loss: 19.4159 - output_0_loss: 11.7736 - output_1_loss: 7.6423 - val_loss: 19.8075 - val_output_0_loss: 11.4943 - val_output_1_loss: 8.3132\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1135 1.5724 (0.3399, 7.6777) - mae: 1.3423 0.9700 (0.2200, 5.0003) - mse: 6.3938 1.2368 (0.0578, 29.4738) - rmse: 1.4944 1.1119 (0.2403, 5.4290)\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 17.86829\n",
      "Epoch 112/1000\n",
      "84/84 [==============================] - 37s 440ms/step - loss: 19.5716 - output_0_loss: 11.8509 - output_1_loss: 7.7207 - val_loss: 18.2271 - val_output_0_loss: 10.7366 - val_output_1_loss: 7.4905\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9623 1.3992 (0.2884, 7.3955) - mae: 1.2480 0.8550 (0.1800, 4.7003) - mse: 6.9255 0.9789 (0.0416, 27.3463) - rmse: 1.3876 0.9894 (0.2040, 5.2294)\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 17.86829\n",
      "Epoch 113/1000\n",
      "84/84 [==============================] - 36s 433ms/step - loss: 19.5378 - output_0_loss: 11.7896 - output_1_loss: 7.7482 - val_loss: 18.4619 - val_output_0_loss: 10.8295 - val_output_1_loss: 7.6324\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9741 1.4081 (0.2884, 7.6821) - mae: 1.2524 0.8749 (0.1800, 4.7936) - mse: 6.0438 0.9913 (0.0416, 29.5076) - rmse: 1.3959 0.9956 (0.2040, 5.4321)\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 17.86829\n",
      "Epoch 114/1000\n",
      "84/84 [==============================] - 37s 440ms/step - loss: 19.1712 - output_0_loss: 11.6557 - output_1_loss: 7.5155 - val_loss: 17.7747 - val_output_0_loss: 10.4638 - val_output_1_loss: 7.3109\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9180 1.3665 (0.3046, 7.3117) - mae: 1.2193 0.8450 (0.1800, 4.7204) - mse: 6.1948 0.9336 (0.0464, 26.7306) - rmse: 1.3562 0.9662 (0.2154, 5.1702)\n",
      "\n",
      "Epoch 00114: val_loss improved from 17.86829 to 17.77473, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 115/1000\n",
      "84/84 [==============================] - 37s 446ms/step - loss: 19.4763 - output_0_loss: 11.7891 - output_1_loss: 7.6872 - val_loss: 19.5289 - val_output_0_loss: 11.2604 - val_output_1_loss: 8.2685\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1015 1.5137 (0.3418, 7.7220) - mae: 1.3321 0.9450 (0.2200, 4.9605) - mse: 6.2420 1.1457 (0.0584, 29.8146) - rmse: 1.4860 1.0703 (0.2417, 5.4603)\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 17.77473\n",
      "Epoch 116/1000\n",
      "84/84 [==============================] - 36s 430ms/step - loss: 19.4713 - output_0_loss: 11.7603 - output_1_loss: 7.7109 - val_loss: 18.3361 - val_output_0_loss: 10.6376 - val_output_1_loss: 7.6986\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9993 1.4500 (0.3224, 7.3741) - mae: 1.2702 0.9200 (0.2000, 4.8679) - mse: 6.9610 1.0512 (0.0520, 27.1885) - rmse: 1.4137 1.0253 (0.2280, 5.2143)\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 17.77473\n",
      "Epoch 117/1000\n",
      "84/84 [==============================] - 36s 434ms/step - loss: 19.1999 - output_0_loss: 11.5896 - output_1_loss: 7.6103 - val_loss: 18.3242 - val_output_0_loss: 10.6985 - val_output_1_loss: 7.6256\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9877 1.3685 (0.2683, 7.6011) - mae: 1.2613 0.8750 (0.1600, 4.8400) - mse: 6.5507 0.9364 (0.0360, 28.8882) - rmse: 1.4055 0.9677 (0.1897, 5.3748)\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 17.77473\n",
      "Epoch 118/1000\n",
      "84/84 [==============================] - 37s 441ms/step - loss: 19.1021 - output_0_loss: 11.5433 - output_1_loss: 7.5588 - val_loss: 17.9142 - val_output_0_loss: 10.6731 - val_output_1_loss: 7.2411\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.8837 1.2493 (0.2263, 7.5628) - mae: 1.1985 0.7900 (0.1400, 4.7205) - mse: 6.3299 0.7804 (0.0256, 28.5982) - rmse: 1.3320 0.8834 (0.1600, 5.3477)\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 17.77473\n",
      "Epoch 119/1000\n",
      "84/84 [==============================] - 36s 424ms/step - loss: 18.9636 - output_0_loss: 11.4521 - output_1_loss: 7.5115 - val_loss: 19.4591 - val_output_0_loss: 11.2263 - val_output_1_loss: 8.2328\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0727 1.4875 (0.3260, 8.0660) - mae: 1.3160 0.9500 (0.2000, 5.2220) - mse: 6.3640 1.1064 (0.0531, 32.5303) - rmse: 1.4656 1.0518 (0.2305, 5.7035)\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 17.77473\n",
      "Epoch 120/1000\n",
      "84/84 [==============================] - 37s 441ms/step - loss: 18.8235 - output_0_loss: 11.3610 - output_1_loss: 7.4626 - val_loss: 18.6383 - val_output_0_loss: 10.9170 - val_output_1_loss: 7.7213\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0468 1.4295 (0.3124, 7.8413) - mae: 1.3009 0.9100 (0.2000, 5.0213) - mse: 7.6953 1.0218 (0.0488, 30.7432) - rmse: 1.4473 1.0108 (0.2209, 5.5447)\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 17.77473\n",
      "Epoch 121/1000\n",
      "84/84 [==============================] - 37s 440ms/step - loss: 18.9777 - output_0_loss: 11.4568 - output_1_loss: 7.5210 - val_loss: 18.6115 - val_output_0_loss: 10.8368 - val_output_1_loss: 7.7747\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0437 1.5126 (0.2885, 7.7410) - mae: 1.3036 0.9500 (0.1800, 4.8412) - mse: 7.3736 1.1440 (0.0416, 29.9612) - rmse: 1.4451 1.0695 (0.2040, 5.4737)\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 17.77473\n",
      "Epoch 122/1000\n",
      "84/84 [==============================] - 37s 435ms/step - loss: 19.2930 - output_0_loss: 11.6387 - output_1_loss: 7.6543 - val_loss: 17.6177 - val_output_0_loss: 10.4479 - val_output_1_loss: 7.1698\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.8910 1.2859 (0.2529, 7.7039) - mae: 1.2083 0.8150 (0.1600, 4.8401) - mse: 6.9061 0.8276 (0.0320, 29.6751) - rmse: 1.3372 0.9093 (0.1789, 5.4475)\n",
      "\n",
      "Epoch 00122: val_loss improved from 17.77473 to 17.61774, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 123/1000\n",
      "84/84 [==============================] - 37s 445ms/step - loss: 19.1263 - output_0_loss: 11.5082 - output_1_loss: 7.6182 - val_loss: 19.6752 - val_output_0_loss: 11.4114 - val_output_1_loss: 8.2639\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1305 1.6658 (0.3578, 7.2458) - mae: 1.3488 1.0250 (0.2200, 4.7812) - mse: 7.4038 1.3874 (0.0640, 26.2511) - rmse: 1.5065 1.1779 (0.2530, 5.1236)\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 17.61774\n",
      "Epoch 124/1000\n",
      "84/84 [==============================] - 36s 431ms/step - loss: 18.8846 - output_0_loss: 11.4035 - output_1_loss: 7.4810 - val_loss: 19.0156 - val_output_0_loss: 11.2316 - val_output_1_loss: 7.7840\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0339 1.4528 (0.3392, 7.4653) - mae: 1.2915 0.9200 (0.2200, 4.8414) - mse: 6.3887 1.0554 (0.0575, 27.8651) - rmse: 1.4382 1.0273 (0.2398, 5.2787)\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 17.61774\n",
      "Epoch 125/1000\n",
      "84/84 [==============================] - 37s 442ms/step - loss: 19.0953 - output_0_loss: 11.4594 - output_1_loss: 7.6359 - val_loss: 18.4038 - val_output_0_loss: 10.8654 - val_output_1_loss: 7.5384\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9067 1.3194 (0.2828, 7.7794) - mae: 1.2115 0.8206 (0.1800, 4.7259) - mse: 5.9452 0.8704 (0.0400, 30.2599) - rmse: 1.3482 0.9329 (0.2000, 5.5009)\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 17.61774\n",
      "Epoch 126/1000\n",
      "84/84 [==============================] - 37s 436ms/step - loss: 18.9713 - output_0_loss: 11.4024 - output_1_loss: 7.5688 - val_loss: 18.4361 - val_output_0_loss: 10.7933 - val_output_1_loss: 7.6428\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9854 1.3976 (0.2884, 7.6985) - mae: 1.2629 0.8862 (0.1800, 4.7807) - mse: 6.2725 0.9770 (0.0416, 29.6332) - rmse: 1.4039 0.9882 (0.2040, 5.4436)\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 17.61774\n",
      "Epoch 127/1000\n",
      "84/84 [==============================] - 37s 436ms/step - loss: 18.6961 - output_0_loss: 11.2703 - output_1_loss: 7.4258 - val_loss: 18.2229 - val_output_0_loss: 10.5576 - val_output_1_loss: 7.6653\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0159 1.3756 (0.2828, 7.9337) - mae: 1.2835 0.8600 (0.1800, 5.0863) - mse: 7.6235 0.9462 (0.0400, 31.4715) - rmse: 1.4254 0.9727 (0.2000, 5.6099)\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 17.61774\n",
      "Epoch 128/1000\n",
      "84/84 [==============================] - 36s 433ms/step - loss: 18.8355 - output_0_loss: 11.3510 - output_1_loss: 7.4845 - val_loss: 19.1017 - val_output_0_loss: 11.2245 - val_output_1_loss: 7.8771\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0405 1.4663 (0.3225, 7.2924) - mae: 1.2943 0.9100 (0.2000, 4.7400) - mse: 6.2669 1.0750 (0.0520, 26.5894) - rmse: 1.4428 1.0368 (0.2280, 5.1565)\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 17.61774\n",
      "Epoch 129/1000\n",
      "84/84 [==============================] - 37s 442ms/step - loss: 18.5501 - output_0_loss: 11.1622 - output_1_loss: 7.3879 - val_loss: 18.2628 - val_output_0_loss: 10.6381 - val_output_1_loss: 7.6247\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0028 1.4647 (0.2800, 8.0838) - mae: 1.2702 0.9100 (0.1600, 5.0401) - mse: 7.1816 1.0727 (0.0392, 32.6744) - rmse: 1.4162 1.0357 (0.1980, 5.7161)\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 17.61774\n",
      "Epoch 130/1000\n",
      "84/84 [==============================] - 37s 440ms/step - loss: 18.5550 - output_0_loss: 11.1670 - output_1_loss: 7.3880 - val_loss: 18.7347 - val_output_0_loss: 10.8021 - val_output_1_loss: 7.9326\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0775 1.4899 (0.3298, 7.7836) - mae: 1.3197 0.9223 (0.2200, 5.0142) - mse: 6.6828 1.1101 (0.0544, 30.2926) - rmse: 1.4690 1.0535 (0.2332, 5.5039)\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 17.61774\n",
      "Epoch 131/1000\n",
      "84/84 [==============================] - 36s 429ms/step - loss: 18.6593 - output_0_loss: 11.2637 - output_1_loss: 7.3957 - val_loss: 18.6886 - val_output_0_loss: 10.8533 - val_output_1_loss: 7.8353\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0243 1.4762 (0.3124, 7.1286) - mae: 1.2840 0.9300 (0.2000, 4.6600) - mse: 6.0509 1.0896 (0.0488, 25.4083) - rmse: 1.4314 1.0438 (0.2209, 5.0407)\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 17.61774\n",
      "Epoch 132/1000\n",
      "84/84 [==============================] - 37s 445ms/step - loss: 18.8238 - output_0_loss: 11.2995 - output_1_loss: 7.5243 - val_loss: 17.2709 - val_output_0_loss: 10.0751 - val_output_1_loss: 7.1958\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9035 1.2571 (0.2563, 7.5145) - mae: 1.2103 0.7900 (0.1600, 4.9003) - mse: 6.1526 0.7902 (0.0329, 28.2342) - rmse: 1.3460 0.8889 (0.1813, 5.3136)\n",
      "\n",
      "Epoch 00132: val_loss improved from 17.61774 to 17.27093, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 133/1000\n",
      "84/84 [==============================] - 36s 427ms/step - loss: 18.6867 - output_0_loss: 11.2437 - output_1_loss: 7.4431 - val_loss: 17.4259 - val_output_0_loss: 10.0561 - val_output_1_loss: 7.3697\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9895 1.3929 (0.3124, 7.4615) - mae: 1.2674 0.8950 (0.2000, 4.7777) - mse: 8.2742 0.9707 (0.0488, 27.8375) - rmse: 1.4068 0.9849 (0.2209, 5.2761)\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 17.27093\n",
      "Epoch 134/1000\n",
      "84/84 [==============================] - 38s 450ms/step - loss: 18.5105 - output_0_loss: 11.1415 - output_1_loss: 7.3690 - val_loss: 17.6123 - val_output_0_loss: 10.3385 - val_output_1_loss: 7.2738\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9186 1.3585 (0.2561, 7.8621) - mae: 1.2195 0.8600 (0.1600, 4.9748) - mse: 6.4130 0.9230 (0.0328, 30.9060) - rmse: 1.3567 0.9606 (0.1811, 5.5593)\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 17.27093\n",
      "Epoch 135/1000\n",
      "84/84 [==============================] - 36s 433ms/step - loss: 18.8058 - output_0_loss: 11.3479 - output_1_loss: 7.4579 - val_loss: 18.3242 - val_output_0_loss: 10.6211 - val_output_1_loss: 7.7030\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0169 1.4175 (0.3124, 7.5530) - mae: 1.2779 0.8950 (0.2000, 4.7960) - mse: 6.3374 1.0049 (0.0488, 28.5243) - rmse: 1.4261 1.0023 (0.2209, 5.3408)\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 17.27093\n",
      "Epoch 136/1000\n",
      "84/84 [==============================] - 36s 430ms/step - loss: 18.6076 - output_0_loss: 11.1575 - output_1_loss: 7.4500 - val_loss: 18.0593 - val_output_0_loss: 10.5355 - val_output_1_loss: 7.5238\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9937 1.2964 (0.2683, 7.8977) - mae: 1.2741 0.8350 (0.1600, 5.0290) - mse: 9.6560 0.8404 (0.0360, 31.1870) - rmse: 1.4097 0.9167 (0.1897, 5.5845)\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 17.27093\n",
      "Epoch 137/1000\n",
      "84/84 [==============================] - 38s 449ms/step - loss: 18.5748 - output_0_loss: 11.1195 - output_1_loss: 7.4553 - val_loss: 17.7208 - val_output_0_loss: 10.1821 - val_output_1_loss: 7.5387\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0379 1.4228 (0.2912, 8.1715) - mae: 1.2950 0.9150 (0.1800, 5.1070) - mse: 7.9229 1.0122 (0.0424, 33.3867) - rmse: 1.4410 1.0061 (0.2059, 5.7781)\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 17.27093\n",
      "Epoch 138/1000\n",
      "84/84 [==============================] - 37s 443ms/step - loss: 18.3279 - output_0_loss: 11.0292 - output_1_loss: 7.2988 - val_loss: 17.5464 - val_output_0_loss: 10.0485 - val_output_1_loss: 7.4978\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9673 1.3796 (0.2828, 7.5559) - mae: 1.2514 0.8775 (0.1800, 4.8407) - mse: 6.1858 0.9516 (0.0400, 28.5459) - rmse: 1.3911 0.9755 (0.2000, 5.3428)\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 17.27093\n",
      "Epoch 139/1000\n",
      "84/84 [==============================] - 37s 435ms/step - loss: 18.0988 - output_0_loss: 10.9074 - output_1_loss: 7.1914 - val_loss: 18.2142 - val_output_0_loss: 10.3091 - val_output_1_loss: 7.9050\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0719 1.4830 (0.3200, 8.0532) - mae: 1.3166 0.9300 (0.2000, 5.1546) - mse: 6.8915 1.0996 (0.0512, 32.4268) - rmse: 1.4651 1.0486 (0.2263, 5.6944)\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 17.27093\n",
      "Epoch 140/1000\n",
      "84/84 [==============================] - 37s 440ms/step - loss: 18.1708 - output_0_loss: 10.9244 - output_1_loss: 7.2464 - val_loss: 18.0637 - val_output_0_loss: 10.2464 - val_output_1_loss: 7.8172\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0700 1.3982 (0.3122, 8.0189) - mae: 1.3197 0.8886 (0.2000, 5.1604) - mse: 8.4628 0.9778 (0.0487, 32.1513) - rmse: 1.4637 0.9887 (0.2208, 5.6702)\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 17.27093\n",
      "Epoch 141/1000\n",
      "84/84 [==============================] - 37s 444ms/step - loss: 18.3064 - output_0_loss: 11.0083 - output_1_loss: 7.2981 - val_loss: 17.1573 - val_output_0_loss: 9.9293 - val_output_1_loss: 7.2280\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.8938 1.2390 (0.2332, 7.7467) - mae: 1.2054 0.7950 (0.1400, 5.1003) - mse: 6.3033 0.7677 (0.0272, 30.0060) - rmse: 1.3391 0.8761 (0.1649, 5.4778)\n",
      "\n",
      "Epoch 00141: val_loss improved from 17.27093 to 17.15728, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 142/1000\n",
      "84/84 [==============================] - 36s 427ms/step - loss: 18.1247 - output_0_loss: 10.8430 - output_1_loss: 7.2816 - val_loss: 18.8331 - val_output_0_loss: 10.7677 - val_output_1_loss: 8.0654\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1258 1.4810 (0.3225, 8.1507) - mae: 1.3498 0.9200 (0.2000, 5.2103) - mse: 8.2497 1.0970 (0.0520, 33.2173) - rmse: 1.5032 1.0473 (0.2280, 5.7634)\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 17.15728\n",
      "Epoch 143/1000\n",
      "84/84 [==============================] - 37s 441ms/step - loss: 18.2405 - output_0_loss: 10.9220 - output_1_loss: 7.3185 - val_loss: 19.0521 - val_output_0_loss: 10.8736 - val_output_1_loss: 8.1785\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0911 1.3887 (0.3225, 8.2223) - mae: 1.3327 0.8950 (0.2000, 5.3004) - mse: 8.1439 0.9644 (0.0520, 33.8032) - rmse: 1.4786 0.9820 (0.2280, 5.8140)\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 17.15728\n",
      "Epoch 144/1000\n",
      "84/84 [==============================] - 36s 430ms/step - loss: 18.3270 - output_0_loss: 10.9855 - output_1_loss: 7.3415 - val_loss: 19.3267 - val_output_0_loss: 10.9811 - val_output_1_loss: 8.3457\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1640 1.5378 (0.3688, 7.9377) - mae: 1.3735 0.9884 (0.2399, 5.1805) - mse: 6.8730 1.1824 (0.0680, 31.5039) - rmse: 1.5302 1.0874 (0.2608, 5.6128)\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 17.15728\n",
      "Epoch 145/1000\n",
      "84/84 [==============================] - 37s 442ms/step - loss: 18.0884 - output_0_loss: 10.8887 - output_1_loss: 7.1997 - val_loss: 18.5165 - val_output_0_loss: 10.4706 - val_output_1_loss: 8.0459\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0556 1.5431 (0.3124, 7.8105) - mae: 1.3019 0.9650 (0.2000, 5.1042) - mse: 6.3475 1.1906 (0.0488, 30.5018) - rmse: 1.4535 1.0911 (0.2209, 5.5228)\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 17.15728\n",
      "Epoch 146/1000\n",
      "84/84 [==============================] - 37s 435ms/step - loss: 18.2830 - output_0_loss: 10.9775 - output_1_loss: 7.3055 - val_loss: 17.5504 - val_output_0_loss: 10.1755 - val_output_1_loss: 7.3749\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9399 1.3237 (0.2828, 7.6663) - mae: 1.2327 0.8300 (0.1800, 4.7800) - mse: 6.1716 0.8762 (0.0400, 29.3859) - rmse: 1.3718 0.9360 (0.2000, 5.4209)\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 17.15728\n",
      "Epoch 147/1000\n",
      "84/84 [==============================] - 37s 441ms/step - loss: 18.3043 - output_0_loss: 10.9568 - output_1_loss: 7.3475 - val_loss: 17.0205 - val_output_0_loss: 9.9563 - val_output_1_loss: 7.0642\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9016 1.3075 (0.2560, 7.6492) - mae: 1.2126 0.8210 (0.1600, 4.7010) - mse: 6.9291 0.8550 (0.0328, 29.2551) - rmse: 1.3446 0.9245 (0.1811, 5.4088)\n",
      "\n",
      "Epoch 00147: val_loss improved from 17.15728 to 17.02047, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 148/1000\n",
      "84/84 [==============================] - 36s 434ms/step - loss: 18.1917 - output_0_loss: 10.8837 - output_1_loss: 7.3080 - val_loss: 18.0170 - val_output_0_loss: 10.4401 - val_output_1_loss: 7.5769\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0010 1.3537 (0.2828, 7.6941) - mae: 1.2746 0.8700 (0.1800, 4.8536) - mse: 6.8724 0.9166 (0.0400, 29.5994) - rmse: 1.4150 0.9572 (0.2000, 5.4405)\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 17.02047\n",
      "Epoch 149/1000\n",
      "84/84 [==============================] - 36s 434ms/step - loss: 18.0309 - output_0_loss: 10.8311 - output_1_loss: 7.1998 - val_loss: 17.3946 - val_output_0_loss: 10.2250 - val_output_1_loss: 7.1695\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9015 1.3245 (0.2683, 7.5964) - mae: 1.2112 0.8500 (0.1800, 4.7642) - mse: 6.0821 0.8772 (0.0360, 28.8529) - rmse: 1.3445 0.9366 (0.1897, 5.3715)\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 17.02047\n",
      "Epoch 150/1000\n",
      "84/84 [==============================] - 36s 426ms/step - loss: 18.2391 - output_0_loss: 10.9549 - output_1_loss: 7.2842 - val_loss: 16.9033 - val_output_0_loss: 9.7990 - val_output_1_loss: 7.1043\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.8477 1.2252 (0.2332, 7.6195) - mae: 1.1767 0.7700 (0.1400, 4.8718) - mse: 6.2723 0.7506 (0.0272, 29.0286) - rmse: 1.3065 0.8663 (0.1649, 5.3878)\n",
      "\n",
      "Epoch 00150: val_loss improved from 17.02047 to 16.90330, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 151/1000\n",
      "84/84 [==============================] - 38s 448ms/step - loss: 17.9121 - output_0_loss: 10.7375 - output_1_loss: 7.1746 - val_loss: 16.3669 - val_output_0_loss: 9.5148 - val_output_1_loss: 6.8521\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.8518 1.2590 (0.2332, 7.4034) - mae: 1.1778 0.7850 (0.1400, 4.7000) - mse: 6.8059 0.7926 (0.0272, 27.4056) - rmse: 1.3094 0.8902 (0.1649, 5.2350)\n",
      "\n",
      "Epoch 00151: val_loss improved from 16.90330 to 16.36692, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 152/1000\n",
      "84/84 [==============================] - 36s 431ms/step - loss: 18.0686 - output_0_loss: 10.8030 - output_1_loss: 7.2656 - val_loss: 17.8027 - val_output_0_loss: 10.1227 - val_output_1_loss: 7.6800\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9577 1.3205 (0.2561, 7.6488) - mae: 1.2470 0.8500 (0.1600, 4.7615) - mse: 6.3983 0.8718 (0.0328, 29.2518) - rmse: 1.3843 0.9337 (0.1811, 5.4085)\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 16.36692\n",
      "Epoch 153/1000\n",
      "84/84 [==============================] - 36s 434ms/step - loss: 17.7308 - output_0_loss: 10.6208 - output_1_loss: 7.1100 - val_loss: 17.5118 - val_output_0_loss: 10.0373 - val_output_1_loss: 7.4745\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9877 1.3320 (0.2828, 8.0994) - mae: 1.2641 0.8200 (0.1800, 5.0103) - mse: 7.7489 0.8872 (0.0400, 32.8002) - rmse: 1.4055 0.9419 (0.2000, 5.7271)\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 16.36692\n",
      "Epoch 154/1000\n",
      "84/84 [==============================] - 37s 445ms/step - loss: 17.7394 - output_0_loss: 10.6350 - output_1_loss: 7.1044 - val_loss: 17.3988 - val_output_0_loss: 10.0608 - val_output_1_loss: 7.3380\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9238 1.3386 (0.2683, 7.3610) - mae: 1.2245 0.8300 (0.1605, 4.7180) - mse: 6.0097 0.8962 (0.0360, 27.0922) - rmse: 1.3604 0.9465 (0.1897, 5.2050)\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 16.36692\n",
      "Epoch 155/1000\n",
      "84/84 [==============================] - 37s 445ms/step - loss: 17.7673 - output_0_loss: 10.6441 - output_1_loss: 7.1232 - val_loss: 17.7212 - val_output_0_loss: 10.2070 - val_output_1_loss: 7.5142\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9491 1.3632 (0.2828, 7.5309) - mae: 1.2420 0.8510 (0.1800, 4.8205) - mse: 6.2017 0.9295 (0.0400, 28.3574) - rmse: 1.3782 0.9639 (0.2000, 5.3252)\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 16.36692\n",
      "Epoch 156/1000\n",
      "84/84 [==============================] - 36s 434ms/step - loss: 17.9703 - output_0_loss: 10.7510 - output_1_loss: 7.2194 - val_loss: 18.9668 - val_output_0_loss: 10.6888 - val_output_1_loss: 8.2779\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1314 1.6236 (0.3622, 7.4811) - mae: 1.3509 1.0100 (0.2400, 4.7605) - mse: 6.0327 1.3180 (0.0656, 27.9832) - rmse: 1.5071 1.1480 (0.2561, 5.2899)\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 16.36692\n",
      "Epoch 157/1000\n",
      "84/84 [==============================] - 36s 433ms/step - loss: 18.0488 - output_0_loss: 10.8532 - output_1_loss: 7.1957 - val_loss: 18.2214 - val_output_0_loss: 10.5433 - val_output_1_loss: 7.6781\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0023 1.4667 (0.3225, 7.8224) - mae: 1.2693 0.9350 (0.2000, 4.9489) - mse: 6.1301 1.0756 (0.0520, 30.5953) - rmse: 1.4158 1.0371 (0.2280, 5.5313)\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 16.36692\n",
      "Epoch 158/1000\n",
      "84/84 [==============================] - 38s 447ms/step - loss: 17.6482 - output_0_loss: 10.6091 - output_1_loss: 7.0390 - val_loss: 16.5291 - val_output_0_loss: 9.5057 - val_output_1_loss: 7.0234\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.8589 1.2992 (0.2561, 7.2877) - mae: 1.1811 0.8050 (0.1600, 4.6810) - mse: 5.7731 0.8450 (0.0328, 26.5553) - rmse: 1.3144 0.9187 (0.1811, 5.1532)\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 16.36692\n",
      "Epoch 159/1000\n",
      "84/84 [==============================] - 36s 425ms/step - loss: 17.8104 - output_0_loss: 10.6287 - output_1_loss: 7.1817 - val_loss: 16.5957 - val_output_0_loss: 9.7110 - val_output_1_loss: 6.8847\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.8194 1.1973 (0.2527, 7.3642) - mae: 1.1584 0.7450 (0.1600, 4.7947) - mse: 5.3068 0.7168 (0.0319, 27.1157) - rmse: 1.2865 0.8466 (0.1787, 5.2073)\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 16.36692\n",
      "Epoch 160/1000\n",
      "84/84 [==============================] - 36s 433ms/step - loss: 17.8381 - output_0_loss: 10.6767 - output_1_loss: 7.1614 - val_loss: 16.4807 - val_output_0_loss: 9.6110 - val_output_1_loss: 6.8697\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.8002 1.2463 (0.2415, 7.1658) - mae: 1.1455 0.7727 (0.1600, 4.5820) - mse: 5.2939 0.7768 (0.0292, 25.6746) - rmse: 1.2729 0.8813 (0.1707, 5.0670)\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 16.36692\n",
      "Epoch 161/1000\n",
      "84/84 [==============================] - 38s 450ms/step - loss: 17.4912 - output_0_loss: 10.5111 - output_1_loss: 6.9802 - val_loss: 18.8790 - val_output_0_loss: 10.6039 - val_output_1_loss: 8.2751\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1556 1.6138 (0.3688, 7.4844) - mae: 1.3648 1.0000 (0.2339, 4.7400) - mse: 7.4969 1.3024 (0.0680, 28.0084) - rmse: 1.5243 1.1411 (0.2608, 5.2923)\n",
      "\n",
      "Epoch 00161: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 16.36692\n",
      "Epoch 162/1000\n",
      "84/84 [==============================] - 35s 423ms/step - loss: 16.4513 - output_0_loss: 9.9220 - output_1_loss: 6.5293 - val_loss: 15.9561 - val_output_0_loss: 9.1780 - val_output_1_loss: 6.7781\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.8688 1.2812 (0.2683, 7.0882) - mae: 1.1899 0.8150 (0.1600, 4.5743) - mse: 6.7681 0.8211 (0.0360, 25.1214) - rmse: 1.3214 0.9059 (0.1897, 5.0121)\n",
      "\n",
      "Epoch 00162: val_loss improved from 16.36692 to 15.95612, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 163/1000\n",
      "84/84 [==============================] - 37s 439ms/step - loss: 16.1812 - output_0_loss: 9.8074 - output_1_loss: 6.3738 - val_loss: 16.4528 - val_output_0_loss: 9.3978 - val_output_1_loss: 7.0551\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9318 1.3756 (0.3046, 7.0756) - mae: 1.2261 0.8600 (0.1800, 4.6220) - mse: 6.8862 0.9462 (0.0464, 25.0323) - rmse: 1.3660 0.9727 (0.2154, 5.0032)\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 15.95612\n",
      "Epoch 164/1000\n",
      "84/84 [==============================] - 37s 439ms/step - loss: 16.0173 - output_0_loss: 9.7008 - output_1_loss: 6.3166 - val_loss: 16.1213 - val_output_0_loss: 9.2879 - val_output_1_loss: 6.8334\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.8629 1.3016 (0.2706, 6.8485) - mae: 1.1800 0.8250 (0.1700, 4.4400) - mse: 5.4783 0.8472 (0.0366, 23.4507) - rmse: 1.3173 0.9204 (0.1913, 4.8426)\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 15.95612\n",
      "Epoch 165/1000\n",
      "84/84 [==============================] - 37s 439ms/step - loss: 16.2336 - output_0_loss: 9.8543 - output_1_loss: 6.3793 - val_loss: 16.2107 - val_output_0_loss: 9.2447 - val_output_1_loss: 6.9660\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.8972 1.3302 (0.2883, 7.2586) - mae: 1.2028 0.8427 (0.1800, 4.6005) - mse: 5.5974 0.8848 (0.0416, 26.3437) - rmse: 1.3415 0.9406 (0.2039, 5.1326)\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 15.95612\n",
      "Epoch 166/1000\n",
      "84/84 [==============================] - 37s 444ms/step - loss: 15.9537 - output_0_loss: 9.7154 - output_1_loss: 6.2383 - val_loss: 16.6804 - val_output_0_loss: 9.4688 - val_output_1_loss: 7.2116\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9689 1.4205 (0.3200, 7.2772) - mae: 1.2483 0.8900 (0.2000, 4.6825) - mse: 6.4461 1.0090 (0.0512, 26.4787) - rmse: 1.3922 1.0044 (0.2263, 5.1457)\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 15.95612\n",
      "Epoch 167/1000\n",
      "84/84 [==============================] - 37s 436ms/step - loss: 15.7123 - output_0_loss: 9.5528 - output_1_loss: 6.1595 - val_loss: 15.5528 - val_output_0_loss: 8.9756 - val_output_1_loss: 6.5772\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.8028 1.2181 (0.2561, 7.1931) - mae: 1.1456 0.7600 (0.1600, 4.6417) - mse: 5.5291 0.7420 (0.0328, 25.8701) - rmse: 1.2748 0.8614 (0.1811, 5.0863)\n",
      "\n",
      "Epoch 00167: val_loss improved from 15.95612 to 15.55280, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 168/1000\n",
      "84/84 [==============================] - 37s 438ms/step - loss: 15.9103 - output_0_loss: 9.6882 - output_1_loss: 6.2221 - val_loss: 15.9039 - val_output_0_loss: 9.0859 - val_output_1_loss: 6.8180\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.8640 1.3155 (0.2683, 7.1404) - mae: 1.1846 0.8200 (0.1705, 4.5610) - mse: 5.8338 0.8653 (0.0360, 25.4929) - rmse: 1.3181 0.9302 (0.1897, 5.0491)\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 15.55280\n",
      "Epoch 169/1000\n",
      "84/84 [==============================] - 39s 465ms/step - loss: 15.8140 - output_0_loss: 9.6447 - output_1_loss: 6.1694 - val_loss: 15.8128 - val_output_0_loss: 9.0794 - val_output_1_loss: 6.7334\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.8538 1.2885 (0.2561, 7.2419) - mae: 1.1785 0.7900 (0.1600, 4.6610) - mse: 5.8164 0.8302 (0.0328, 26.2228) - rmse: 1.3108 0.9111 (0.1811, 5.1208)\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 15.55280\n",
      "Epoch 170/1000\n",
      "84/84 [==============================] - 37s 443ms/step - loss: 15.7737 - output_0_loss: 9.6196 - output_1_loss: 6.1540 - val_loss: 16.6083 - val_output_0_loss: 9.3930 - val_output_1_loss: 7.2153\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9734 1.4039 (0.3225, 7.3101) - mae: 1.2536 0.8738 (0.2000, 4.7200) - mse: 7.1324 0.9856 (0.0520, 26.7190) - rmse: 1.3954 0.9927 (0.2280, 5.1690)\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 15.55280\n",
      "Epoch 171/1000\n",
      "84/84 [==============================] - 37s 442ms/step - loss: 15.7107 - output_0_loss: 9.5674 - output_1_loss: 6.1433 - val_loss: 16.5120 - val_output_0_loss: 9.3880 - val_output_1_loss: 7.1240\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9668 1.3265 (0.2912, 7.5055) - mae: 1.2513 0.8400 (0.1800, 4.7414) - mse: 7.5838 0.8798 (0.0424, 28.1662) - rmse: 1.3907 0.9380 (0.2059, 5.3072)\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 15.55280\n",
      "Epoch 172/1000\n",
      "84/84 [==============================] - 37s 438ms/step - loss: 15.8893 - output_0_loss: 9.6673 - output_1_loss: 6.2220 - val_loss: 17.0201 - val_output_0_loss: 9.6110 - val_output_1_loss: 7.4090\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0103 1.4359 (0.3124, 7.4395) - mae: 1.2763 0.8986 (0.2000, 4.8605) - mse: 7.6567 1.0310 (0.0488, 27.6731) - rmse: 1.4215 1.0153 (0.2209, 5.2605)\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 15.55280\n",
      "Epoch 173/1000\n",
      "84/84 [==============================] - 36s 432ms/step - loss: 15.7164 - output_0_loss: 9.5844 - output_1_loss: 6.1321 - val_loss: 16.4453 - val_output_0_loss: 9.2695 - val_output_1_loss: 7.1757\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9658 1.3767 (0.2912, 7.2195) - mae: 1.2497 0.8800 (0.1800, 4.6800) - mse: 7.3577 0.9476 (0.0424, 26.0605) - rmse: 1.3900 0.9734 (0.2059, 5.1049)\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 15.55280\n",
      "Epoch 174/1000\n",
      "84/84 [==============================] - 37s 439ms/step - loss: 15.6719 - output_0_loss: 9.5503 - output_1_loss: 6.1216 - val_loss: 16.6043 - val_output_0_loss: 9.3367 - val_output_1_loss: 7.2676\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0130 1.3559 (0.3198, 7.4820) - mae: 1.2807 0.8550 (0.2000, 4.8577) - mse: 8.4015 0.9192 (0.0511, 27.9902) - rmse: 1.4234 0.9587 (0.2261, 5.2906)\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 15.55280\n",
      "Epoch 175/1000\n",
      "84/84 [==============================] - 36s 428ms/step - loss: 15.6581 - output_0_loss: 9.5709 - output_1_loss: 6.0872 - val_loss: 16.6561 - val_output_0_loss: 9.4070 - val_output_1_loss: 7.2491\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9918 1.3855 (0.3198, 7.3758) - mae: 1.2652 0.8800 (0.2000, 4.7816) - mse: 7.7385 0.9600 (0.0511, 27.2012) - rmse: 1.4084 0.9797 (0.2261, 5.2155)\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 15.55280\n",
      "Epoch 176/1000\n",
      "84/84 [==============================] - 37s 444ms/step - loss: 15.7383 - output_0_loss: 9.6230 - output_1_loss: 6.1153 - val_loss: 16.1210 - val_output_0_loss: 9.0865 - val_output_1_loss: 7.0345\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9436 1.3175 (0.2828, 7.6208) - mae: 1.2351 0.8300 (0.1800, 4.7210) - mse: 7.9888 0.8686 (0.0400, 29.0387) - rmse: 1.3743 0.9316 (0.2000, 5.3888)\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 15.55280\n",
      "Epoch 177/1000\n",
      "84/84 [==============================] - 37s 439ms/step - loss: 15.7513 - output_0_loss: 9.6413 - output_1_loss: 6.1101 - val_loss: 15.1176 - val_output_0_loss: 8.6558 - val_output_1_loss: 6.4618\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.8050 1.2250 (0.2400, 6.8926) - mae: 1.1486 0.7650 (0.1597, 4.3606) - mse: 7.0732 0.7504 (0.0288, 23.7542) - rmse: 1.2763 0.8662 (0.1697, 4.8738)\n",
      "\n",
      "Epoch 00177: val_loss improved from 15.55280 to 15.11760, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 178/1000\n",
      "84/84 [==============================] - 37s 438ms/step - loss: 15.6313 - output_0_loss: 9.5675 - output_1_loss: 6.0638 - val_loss: 16.1131 - val_output_0_loss: 9.1078 - val_output_1_loss: 7.0053\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9088 1.3383 (0.2884, 7.3635) - mae: 1.2095 0.8500 (0.1800, 4.6781) - mse: 6.1358 0.8956 (0.0416, 27.1108) - rmse: 1.3497 0.9464 (0.2040, 5.2068)\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 15.11760\n",
      "Epoch 179/1000\n",
      "84/84 [==============================] - 37s 439ms/step - loss: 15.4346 - output_0_loss: 9.4528 - output_1_loss: 5.9818 - val_loss: 15.8046 - val_output_0_loss: 8.8968 - val_output_1_loss: 6.9078\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.8877 1.3078 (0.2560, 7.4723) - mae: 1.1980 0.8250 (0.1600, 4.8563) - mse: 6.4249 0.8554 (0.0328, 27.9175) - rmse: 1.3348 0.9248 (0.1811, 5.2837)\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 15.11760\n",
      "Epoch 180/1000\n",
      "84/84 [==============================] - 37s 437ms/step - loss: 15.7179 - output_0_loss: 9.6206 - output_1_loss: 6.0974 - val_loss: 16.6428 - val_output_0_loss: 9.3532 - val_output_1_loss: 7.2896\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0066 1.3944 (0.2912, 7.4439) - mae: 1.2736 0.8650 (0.1800, 4.8800) - mse: 7.7369 0.9722 (0.0424, 27.7061) - rmse: 1.4189 0.9860 (0.2059, 5.2637)\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 15.11760\n",
      "Epoch 181/1000\n",
      "84/84 [==============================] - 37s 439ms/step - loss: 15.7093 - output_0_loss: 9.6063 - output_1_loss: 6.1030 - val_loss: 16.2839 - val_output_0_loss: 9.2132 - val_output_1_loss: 7.0707\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9535 1.3235 (0.2885, 7.5533) - mae: 1.2411 0.8300 (0.1800, 4.8410) - mse: 7.6278 0.8758 (0.0416, 28.5259) - rmse: 1.3813 0.9358 (0.2040, 5.3410)\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 15.11760\n",
      "Epoch 182/1000\n",
      "84/84 [==============================] - 37s 439ms/step - loss: 15.4754 - output_0_loss: 9.4911 - output_1_loss: 5.9843 - val_loss: 15.6355 - val_output_0_loss: 8.8892 - val_output_1_loss: 6.7462\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.8836 1.2361 (0.2530, 7.5613) - mae: 1.1963 0.7950 (0.1600, 4.8201) - mse: 7.2524 0.7640 (0.0320, 28.5869) - rmse: 1.3319 0.8741 (0.1789, 5.3467)\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 15.11760\n",
      "Epoch 183/1000\n",
      "84/84 [==============================] - 36s 432ms/step - loss: 15.5029 - output_0_loss: 9.4836 - output_1_loss: 6.0193 - val_loss: 15.9614 - val_output_0_loss: 9.0053 - val_output_1_loss: 6.9561\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9149 1.3209 (0.2911, 7.4674) - mae: 1.2135 0.8400 (0.1800, 4.8041) - mse: 6.4684 0.8724 (0.0424, 27.8812) - rmse: 1.3540 0.9340 (0.2059, 5.2803)\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 15.11760\n",
      "Epoch 184/1000\n",
      "84/84 [==============================] - 37s 436ms/step - loss: 15.6301 - output_0_loss: 9.5514 - output_1_loss: 6.0787 - val_loss: 16.4817 - val_output_0_loss: 9.1567 - val_output_1_loss: 7.3250\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0292 1.4222 (0.3224, 7.4695) - mae: 1.2884 0.8861 (0.2000, 4.8552) - mse: 8.3461 1.0114 (0.0520, 27.8964) - rmse: 1.4349 1.0057 (0.2280, 5.2817)\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 15.11760\n",
      "Epoch 185/1000\n",
      "84/84 [==============================] - 37s 439ms/step - loss: 15.5273 - output_0_loss: 9.5355 - output_1_loss: 5.9918 - val_loss: 15.3296 - val_output_0_loss: 8.6913 - val_output_1_loss: 6.6383\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.8328 1.2048 (0.2263, 7.2822) - mae: 1.1677 0.7673 (0.1400, 4.6186) - mse: 7.4346 0.7259 (0.0256, 26.5150) - rmse: 1.2960 0.8519 (0.1600, 5.1493)\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 15.11760\n",
      "Epoch 186/1000\n",
      "84/84 [==============================] - 38s 451ms/step - loss: 15.5003 - output_0_loss: 9.4982 - output_1_loss: 6.0021 - val_loss: 15.9646 - val_output_0_loss: 8.9379 - val_output_1_loss: 7.0266\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9155 1.3254 (0.2828, 7.3817) - mae: 1.2158 0.8300 (0.1800, 4.7204) - mse: 7.3729 0.8784 (0.0400, 27.2449) - rmse: 1.3545 0.9372 (0.2000, 5.2197)\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 15.11760\n",
      "Epoch 187/1000\n",
      "84/84 [==============================] - 37s 437ms/step - loss: 15.5129 - output_0_loss: 9.4874 - output_1_loss: 6.0255 - val_loss: 15.7517 - val_output_0_loss: 8.8721 - val_output_1_loss: 6.8796\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9065 1.3038 (0.2800, 7.4577) - mae: 1.2119 0.8400 (0.1600, 4.8210) - mse: 6.9166 0.8500 (0.0392, 27.8087) - rmse: 1.3481 0.9219 (0.1980, 5.2734)\n",
      "\n",
      "Epoch 00187: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 15.11760\n",
      "Epoch 188/1000\n",
      "84/84 [==============================] - 36s 430ms/step - loss: 15.2360 - output_0_loss: 9.3671 - output_1_loss: 5.8689 - val_loss: 15.8786 - val_output_0_loss: 8.9096 - val_output_1_loss: 6.9691\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9266 1.3096 (0.2884, 7.2539) - mae: 1.2243 0.8450 (0.1800, 4.7410) - mse: 7.4051 0.8576 (0.0416, 26.3094) - rmse: 1.3623 0.9261 (0.2040, 5.1293)\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 15.11760\n",
      "Epoch 189/1000\n",
      "84/84 [==============================] - 37s 441ms/step - loss: 15.1251 - output_0_loss: 9.2987 - output_1_loss: 5.8264 - val_loss: 15.6805 - val_output_0_loss: 8.8119 - val_output_1_loss: 6.8686\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9036 1.3154 (0.2800, 7.1583) - mae: 1.2106 0.8115 (0.1800, 4.6805) - mse: 7.4025 0.8652 (0.0392, 25.6210) - rmse: 1.3460 0.9301 (0.1980, 5.0617)\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 15.11760\n",
      "Epoch 190/1000\n",
      "84/84 [==============================] - 36s 433ms/step - loss: 15.2028 - output_0_loss: 9.3482 - output_1_loss: 5.8546 - val_loss: 15.8007 - val_output_0_loss: 8.8613 - val_output_1_loss: 6.9394\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9270 1.2943 (0.2883, 7.3335) - mae: 1.2247 0.8181 (0.1800, 4.7000) - mse: 7.5428 0.8376 (0.0416, 26.8899) - rmse: 1.3626 0.9152 (0.2039, 5.1855)\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 15.11760\n",
      "Epoch 191/1000\n",
      "84/84 [==============================] - 36s 434ms/step - loss: 14.9720 - output_0_loss: 9.2159 - output_1_loss: 5.7561 - val_loss: 15.8271 - val_output_0_loss: 8.9059 - val_output_1_loss: 6.9212\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9206 1.3116 (0.2912, 7.2643) - mae: 1.2209 0.8300 (0.1800, 4.7205) - mse: 7.3612 0.8601 (0.0424, 26.3848) - rmse: 1.3581 0.9274 (0.2059, 5.1366)\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 15.11760\n",
      "Epoch 192/1000\n",
      "84/84 [==============================] - 37s 445ms/step - loss: 15.0042 - output_0_loss: 9.2367 - output_1_loss: 5.7675 - val_loss: 15.6898 - val_output_0_loss: 8.8278 - val_output_1_loss: 6.8620\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9012 1.2886 (0.2560, 7.2027) - mae: 1.2091 0.8200 (0.1600, 4.7800) - mse: 7.4459 0.8302 (0.0328, 25.9396) - rmse: 1.3443 0.9112 (0.1811, 5.0931)\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 15.11760\n",
      "Epoch 193/1000\n",
      "84/84 [==============================] - 36s 428ms/step - loss: 14.8739 - output_0_loss: 9.1714 - output_1_loss: 5.7025 - val_loss: 16.0779 - val_output_0_loss: 8.9944 - val_output_1_loss: 7.0835\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9549 1.3405 (0.2912, 7.2936) - mae: 1.2416 0.8400 (0.1800, 4.7405) - mse: 7.6278 0.8985 (0.0424, 26.5980) - rmse: 1.3823 0.9478 (0.2059, 5.1573)\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 15.11760\n",
      "Epoch 194/1000\n",
      "84/84 [==============================] - 38s 448ms/step - loss: 15.1680 - output_0_loss: 9.3432 - output_1_loss: 5.8248 - val_loss: 15.4894 - val_output_0_loss: 8.7427 - val_output_1_loss: 6.7466\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.8840 1.2531 (0.2530, 7.2113) - mae: 1.1983 0.7950 (0.1600, 4.7405) - mse: 7.5753 0.7852 (0.0320, 26.0011) - rmse: 1.3322 0.8861 (0.1789, 5.0991)\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 15.11760\n",
      "Epoch 195/1000\n",
      "84/84 [==============================] - 37s 443ms/step - loss: 14.9933 - output_0_loss: 9.2309 - output_1_loss: 5.7624 - val_loss: 16.1501 - val_output_0_loss: 8.9970 - val_output_1_loss: 7.1531\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9729 1.3612 (0.3046, 7.3220) - mae: 1.2531 0.8600 (0.1800, 4.7810) - mse: 7.7241 0.9266 (0.0464, 26.8061) - rmse: 1.3951 0.9625 (0.2154, 5.1775)\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 15.11760\n",
      "Epoch 196/1000\n",
      "84/84 [==============================] - 37s 442ms/step - loss: 14.9824 - output_0_loss: 9.2462 - output_1_loss: 5.7361 - val_loss: 16.1100 - val_output_0_loss: 8.9616 - val_output_1_loss: 7.1484\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9792 1.3489 (0.2912, 7.4647) - mae: 1.2561 0.8599 (0.1800, 4.8422) - mse: 7.8566 0.9098 (0.0424, 27.8612) - rmse: 1.3995 0.9538 (0.2059, 5.2784)\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 15.11760\n",
      "Epoch 197/1000\n",
      "84/84 [==============================] - 37s 441ms/step - loss: 15.1712 - output_0_loss: 9.3472 - output_1_loss: 5.8240 - val_loss: 15.7402 - val_output_0_loss: 8.8095 - val_output_1_loss: 6.9307\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9098 1.2923 (0.2683, 7.3222) - mae: 1.2156 0.8170 (0.1800, 4.8165) - mse: 7.6156 0.8352 (0.0360, 26.8077) - rmse: 1.3504 0.9138 (0.1897, 5.1776)\n",
      "\n",
      "Epoch 00197: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 15.11760\n",
      "Epoch 198/1000\n",
      "84/84 [==============================] - 37s 445ms/step - loss: 15.0219 - output_0_loss: 9.2682 - output_1_loss: 5.7537 - val_loss: 15.6066 - val_output_0_loss: 8.7607 - val_output_1_loss: 6.8459\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.8973 1.2601 (0.2561, 7.3169) - mae: 1.2079 0.7950 (0.1600, 4.8200) - mse: 7.6684 0.7940 (0.0328, 26.7686) - rmse: 1.3416 0.8910 (0.1811, 5.1738)\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 15.11760\n",
      "Epoch 199/1000\n",
      "84/84 [==============================] - 37s 435ms/step - loss: 15.0350 - output_0_loss: 9.2678 - output_1_loss: 5.7672 - val_loss: 15.7208 - val_output_0_loss: 8.8174 - val_output_1_loss: 6.9034\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9077 1.2909 (0.2800, 7.3158) - mae: 1.2139 0.8100 (0.1600, 4.7772) - mse: 7.6264 0.8332 (0.0392, 26.7602) - rmse: 1.3490 0.9128 (0.1980, 5.1730)\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 15.11760\n",
      "Epoch 200/1000\n",
      "84/84 [==============================] - 37s 436ms/step - loss: 15.1071 - output_0_loss: 9.3165 - output_1_loss: 5.7906 - val_loss: 15.7601 - val_output_0_loss: 8.8451 - val_output_1_loss: 6.9149\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9137 1.2964 (0.2797, 7.3158) - mae: 1.2176 0.8100 (0.1600, 4.7176) - mse: 7.6511 0.8404 (0.0391, 26.7602) - rmse: 1.3532 0.9167 (0.1978, 5.1730)\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 15.11760\n",
      "Epoch 201/1000\n",
      "84/84 [==============================] - 36s 433ms/step - loss: 14.9828 - output_0_loss: 9.2402 - output_1_loss: 5.7426 - val_loss: 15.7547 - val_output_0_loss: 8.8389 - val_output_1_loss: 6.9159\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9149 1.2870 (0.2820, 7.2030) - mae: 1.2181 0.8150 (0.1800, 4.7064) - mse: 7.6302 0.8282 (0.0398, 25.9420) - rmse: 1.3540 0.9100 (0.1994, 5.0933)\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 15.11760\n",
      "Epoch 202/1000\n",
      "84/84 [==============================] - 37s 439ms/step - loss: 15.0291 - output_0_loss: 9.2558 - output_1_loss: 5.7733 - val_loss: 15.8200 - val_output_0_loss: 8.8799 - val_output_1_loss: 6.9402\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9216 1.2893 (0.2828, 7.2434) - mae: 1.2223 0.8300 (0.1800, 4.6869) - mse: 7.6392 0.8312 (0.0400, 26.2338) - rmse: 1.3588 0.9117 (0.2000, 5.1219)\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 15.11760\n",
      "Epoch 203/1000\n",
      "84/84 [==============================] - 36s 431ms/step - loss: 14.9835 - output_0_loss: 9.2472 - output_1_loss: 5.7363 - val_loss: 15.8383 - val_output_0_loss: 8.8884 - val_output_1_loss: 6.9499\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9256 1.3058 (0.2828, 7.2426) - mae: 1.2246 0.8200 (0.1800, 4.7019) - mse: 7.6603 0.8526 (0.0400, 26.2280) - rmse: 1.3616 0.9233 (0.1999, 5.1213)\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 15.11760\n",
      "Epoch 204/1000\n",
      "84/84 [==============================] - 37s 440ms/step - loss: 15.1204 - output_0_loss: 9.3256 - output_1_loss: 5.7948 - val_loss: 15.6746 - val_output_0_loss: 8.8137 - val_output_1_loss: 6.8610\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9030 1.2738 (0.2561, 7.2022) - mae: 1.2108 0.7997 (0.1600, 4.7774) - mse: 7.6331 0.8114 (0.0328, 25.9362) - rmse: 1.3457 0.9007 (0.1811, 5.0928)\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 15.11760\n",
      "Epoch 205/1000\n",
      "84/84 [==============================] - 36s 433ms/step - loss: 15.0256 - output_0_loss: 9.2752 - output_1_loss: 5.7504 - val_loss: 15.7599 - val_output_0_loss: 8.8561 - val_output_1_loss: 6.9039\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9143 1.2790 (0.2797, 7.2420) - mae: 1.2177 0.8050 (0.1800, 4.7415) - mse: 7.6522 0.8180 (0.0391, 26.2236) - rmse: 1.3536 0.9044 (0.1978, 5.1209)\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 15.11760\n",
      "Epoch 206/1000\n",
      "84/84 [==============================] - 36s 433ms/step - loss: 15.0829 - output_0_loss: 9.3006 - output_1_loss: 5.7823 - val_loss: 15.7761 - val_output_0_loss: 8.8569 - val_output_1_loss: 6.9192\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9195 1.2976 (0.2828, 7.2385) - mae: 1.2208 0.8200 (0.1800, 4.7404) - mse: 7.6481 0.8420 (0.0400, 26.1976) - rmse: 1.3573 0.9175 (0.2000, 5.1184)\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 15.11760\n",
      "Epoch 207/1000\n",
      "84/84 [==============================] - 38s 449ms/step - loss: 15.0057 - output_0_loss: 9.2584 - output_1_loss: 5.7473 - val_loss: 15.7993 - val_output_0_loss: 8.8613 - val_output_1_loss: 6.9380\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9230 1.3052 (0.2683, 7.2487) - mae: 1.2231 0.8150 (0.1799, 4.7005) - mse: 7.6584 0.8518 (0.0360, 26.2720) - rmse: 1.3598 0.9229 (0.1897, 5.1256)\n",
      "\n",
      "Epoch 00207: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 15.11760\n",
      "Epoch 208/1000\n",
      "84/84 [==============================] - 36s 431ms/step - loss: 14.9515 - output_0_loss: 9.2397 - output_1_loss: 5.7118 - val_loss: 15.7818 - val_output_0_loss: 8.8522 - val_output_1_loss: 6.9296\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9211 1.3008 (0.2828, 7.2415) - mae: 1.2217 0.8200 (0.1797, 4.7002) - mse: 7.6544 0.8460 (0.0400, 26.2195) - rmse: 1.3584 0.9198 (0.1999, 5.1205)\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 15.11760\n",
      "Epoch 209/1000\n",
      "84/84 [==============================] - 37s 435ms/step - loss: 15.0189 - output_0_loss: 9.2774 - output_1_loss: 5.7416 - val_loss: 15.8074 - val_output_0_loss: 8.8647 - val_output_1_loss: 6.9427\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9243 1.3008 (0.2769, 7.2497) - mae: 1.2237 0.8200 (0.1799, 4.7006) - mse: 7.6679 0.8460 (0.0383, 26.2789) - rmse: 1.3607 0.9198 (0.1958, 5.1263)\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 15.11760\n",
      "Epoch 210/1000\n",
      "84/84 [==============================] - 37s 442ms/step - loss: 15.0232 - output_0_loss: 9.2701 - output_1_loss: 5.7531 - val_loss: 15.8079 - val_output_0_loss: 8.8626 - val_output_1_loss: 6.9453\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9252 1.2997 (0.2683, 7.2607) - mae: 1.2242 0.8200 (0.1800, 4.7184) - mse: 7.6708 0.8446 (0.0360, 26.3591) - rmse: 1.3613 0.9190 (0.1897, 5.1341)\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 15.11760\n",
      "Epoch 211/1000\n",
      "84/84 [==============================] - 37s 441ms/step - loss: 15.0336 - output_0_loss: 9.2869 - output_1_loss: 5.7467 - val_loss: 15.7973 - val_output_0_loss: 8.8604 - val_output_1_loss: 6.9369\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9231 1.2997 (0.2797, 7.2607) - mae: 1.2229 0.8150 (0.1800, 4.6972) - mse: 7.6643 0.8446 (0.0391, 26.3591) - rmse: 1.3598 0.9190 (0.1978, 5.1341)\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 15.11760\n",
      "Epoch 212/1000\n",
      "84/84 [==============================] - 37s 438ms/step - loss: 15.0316 - output_0_loss: 9.2948 - output_1_loss: 5.7367 - val_loss: 15.8013 - val_output_0_loss: 8.8645 - val_output_1_loss: 6.9367\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9234 1.2997 (0.2683, 7.2812) - mae: 1.2231 0.8150 (0.1800, 4.7012) - mse: 7.6666 0.8446 (0.0360, 26.5076) - rmse: 1.3601 0.9190 (0.1897, 5.1486)\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 15.11760\n",
      "Epoch 213/1000\n",
      "84/84 [==============================] - 37s 439ms/step - loss: 14.9717 - output_0_loss: 9.2430 - output_1_loss: 5.7287 - val_loss: 15.8230 - val_output_0_loss: 8.8762 - val_output_1_loss: 6.9469\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9262 1.3045 (0.2828, 7.2818) - mae: 1.2248 0.8150 (0.1800, 4.7005) - mse: 7.6713 0.8508 (0.0400, 26.5125) - rmse: 1.3620 0.9224 (0.2000, 5.1490)\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 15.11760\n",
      "Epoch 214/1000\n",
      "84/84 [==============================] - 37s 440ms/step - loss: 14.9282 - output_0_loss: 9.2276 - output_1_loss: 5.7006 - val_loss: 15.8034 - val_output_0_loss: 8.8668 - val_output_1_loss: 6.9366\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9241 1.3093 (0.2828, 7.2616) - mae: 1.2235 0.8200 (0.1800, 4.7002) - mse: 7.6716 0.8572 (0.0400, 26.3652) - rmse: 1.3606 0.9258 (0.2000, 5.1347)\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 15.11760\n",
      "Epoch 215/1000\n",
      "84/84 [==============================] - 38s 447ms/step - loss: 15.0039 - output_0_loss: 9.2763 - output_1_loss: 5.7276 - val_loss: 15.8042 - val_output_0_loss: 8.8686 - val_output_1_loss: 6.9356\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9240 1.3046 (0.2828, 7.2989) - mae: 1.2235 0.8200 (0.1600, 4.6972) - mse: 7.6713 0.8510 (0.0400, 26.6373) - rmse: 1.3605 0.9225 (0.2000, 5.1611)\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 15.11760\n",
      "Epoch 216/1000\n",
      "84/84 [==============================] - 37s 437ms/step - loss: 15.0904 - output_0_loss: 9.3000 - output_1_loss: 5.7903 - val_loss: 15.8054 - val_output_0_loss: 8.8664 - val_output_1_loss: 6.9389\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9248 1.3014 (0.2828, 7.2948) - mae: 1.2239 0.8200 (0.1649, 4.6972) - mse: 7.6752 0.8468 (0.0400, 26.6071) - rmse: 1.3610 0.9202 (0.2000, 5.1582)\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 15.11760\n",
      "Epoch 217/1000\n",
      "84/84 [==============================] - 36s 433ms/step - loss: 14.9373 - output_0_loss: 9.2340 - output_1_loss: 5.7032 - val_loss: 15.7927 - val_output_0_loss: 8.8595 - val_output_1_loss: 6.9332\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9227 1.3046 (0.2828, 7.2948) - mae: 1.2227 0.8100 (0.1796, 4.6972) - mse: 7.6725 0.8510 (0.0400, 26.6071) - rmse: 1.3596 0.9225 (0.1999, 5.1582)\n",
      "\n",
      "Epoch 00217: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 15.11760\n",
      "Epoch 218/1000\n",
      "84/84 [==============================] - 37s 440ms/step - loss: 14.9090 - output_0_loss: 9.2098 - output_1_loss: 5.6992 - val_loss: 15.7919 - val_output_0_loss: 8.8594 - val_output_1_loss: 6.9326\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9227 1.3046 (0.2828, 7.2948) - mae: 1.2227 0.8100 (0.1600, 4.6972) - mse: 7.6719 0.8510 (0.0400, 26.6071) - rmse: 1.3595 0.9225 (0.2000, 5.1582)\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 15.11760\n",
      "Epoch 219/1000\n",
      "84/84 [==============================] - 36s 434ms/step - loss: 14.9145 - output_0_loss: 9.2232 - output_1_loss: 5.6913 - val_loss: 15.7935 - val_output_0_loss: 8.8600 - val_output_1_loss: 6.9335\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9229 1.3015 (0.2828, 7.2948) - mae: 1.2228 0.8100 (0.1796, 4.6972) - mse: 7.6728 0.8470 (0.0400, 26.6071) - rmse: 1.3597 0.9203 (0.2000, 5.1582)\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 15.11760\n",
      "Epoch 220/1000\n",
      "84/84 [==============================] - 37s 436ms/step - loss: 14.9246 - output_0_loss: 9.2164 - output_1_loss: 5.7081 - val_loss: 15.7941 - val_output_0_loss: 8.8607 - val_output_1_loss: 6.9334\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9230 1.3015 (0.2828, 7.2948) - mae: 1.2229 0.8100 (0.1800, 4.7002) - mse: 7.6735 0.8470 (0.0400, 26.6071) - rmse: 1.3598 0.9203 (0.2000, 5.1582)\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 15.11760\n",
      "Epoch 221/1000\n",
      "84/84 [==============================] - 38s 447ms/step - loss: 15.0775 - output_0_loss: 9.3013 - output_1_loss: 5.7762 - val_loss: 15.7973 - val_output_0_loss: 8.8624 - val_output_1_loss: 6.9349\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9233 1.3015 (0.2828, 7.2948) - mae: 1.2231 0.8100 (0.1800, 4.7002) - mse: 7.6744 0.8470 (0.0400, 26.6071) - rmse: 1.3600 0.9203 (0.2000, 5.1582)\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 15.11760\n",
      "Epoch 222/1000\n",
      "84/84 [==============================] - 36s 434ms/step - loss: 15.0834 - output_0_loss: 9.3146 - output_1_loss: 5.7688 - val_loss: 15.7942 - val_output_0_loss: 8.8609 - val_output_1_loss: 6.9332\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9231 1.3015 (0.2828, 7.2948) - mae: 1.2229 0.8100 (0.1600, 4.7002) - mse: 7.6727 0.8470 (0.0400, 26.6071) - rmse: 1.3598 0.9203 (0.2000, 5.1582)\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 15.11760\n",
      "Epoch 223/1000\n",
      "84/84 [==============================] - 37s 435ms/step - loss: 15.0595 - output_0_loss: 9.2995 - output_1_loss: 5.7600 - val_loss: 15.7935 - val_output_0_loss: 8.8609 - val_output_1_loss: 6.9326\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9228 1.3015 (0.2828, 7.2948) - mae: 1.2227 0.8100 (0.1600, 4.6972) - mse: 7.6722 0.8470 (0.0400, 26.6071) - rmse: 1.3596 0.9203 (0.2000, 5.1582)\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 15.11760\n",
      "Epoch 224/1000\n",
      "84/84 [==============================] - 37s 443ms/step - loss: 15.0290 - output_0_loss: 9.2797 - output_1_loss: 5.7494 - val_loss: 15.7968 - val_output_0_loss: 8.8624 - val_output_1_loss: 6.9343\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9230 1.3014 (0.2828, 7.2948) - mae: 1.2229 0.8100 (0.1600, 4.6972) - mse: 7.6709 0.8468 (0.0400, 26.6071) - rmse: 1.3598 0.9202 (0.2000, 5.1582)\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 15.11760\n",
      "Epoch 225/1000\n",
      "84/84 [==============================] - 37s 443ms/step - loss: 14.9376 - output_0_loss: 9.2147 - output_1_loss: 5.7229 - val_loss: 15.7853 - val_output_0_loss: 8.8575 - val_output_1_loss: 6.9278\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9217 1.3014 (0.2828, 7.2948) - mae: 1.2221 0.8100 (0.1649, 4.6972) - mse: 7.6692 0.8468 (0.0400, 26.6071) - rmse: 1.3589 0.9202 (0.2000, 5.1582)\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 15.11760\n",
      "Epoch 226/1000\n",
      "84/84 [==============================] - 37s 442ms/step - loss: 14.8560 - output_0_loss: 9.1930 - output_1_loss: 5.6630 - val_loss: 15.7822 - val_output_0_loss: 8.8557 - val_output_1_loss: 6.9265\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9212 1.3014 (0.2800, 7.2948) - mae: 1.2218 0.8050 (0.1600, 4.6972) - mse: 7.6688 0.8468 (0.0392, 26.6071) - rmse: 1.3585 0.9202 (0.1980, 5.1582)\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 15.11760\n",
      "Epoch 227/1000\n",
      "84/84 [==============================] - 37s 435ms/step - loss: 15.0417 - output_0_loss: 9.2848 - output_1_loss: 5.7569 - val_loss: 15.7758 - val_output_0_loss: 8.8535 - val_output_1_loss: 6.9222\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9204 1.3014 (0.2800, 7.2948) - mae: 1.2213 0.8050 (0.1600, 4.6972) - mse: 7.6679 0.8468 (0.0392, 26.6071) - rmse: 1.3579 0.9202 (0.1980, 5.1582)\n",
      "\n",
      "Epoch 00227: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 15.11760\n",
      "Epoch 00227: early stopping\n"
     ]
    }
   ],
   "source": [
    "model.fit(batch_size=16,\n",
    "          validation_batch_size=10,\n",
    "          callbacks=callbacks,\n",
    "          epochs=1000,\n",
    "          n_workers=8,\n",
    "          steps_per_epoch=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "from deepposekit import TrainingGenerator\n",
    "from deepposekit.augment import FlipAxis\n",
    "import imgaug.augmenters as iaa\n",
    "import imgaug as ia\n",
    "\n",
    "from deepposekit.models import (StackedDenseNet,\n",
    "                                DeepLabCut,\n",
    "                                StackedHourglass)\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from deepposekit.callbacks import Logger, ModelCheckpoint\n",
    "\n",
    "import time\n",
    "from os.path import expanduser\n",
    "HOME = expanduser(\"~\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/jake/deepposekit-data/datasets/fly/annotation_data_release.h5',\n",
       " '/home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5',\n",
       " '/home/jake/deepposekit-data/datasets/fly/example_annotation_set.h5',\n",
       " '/home/jake/deepposekit-data/datasets/fly/log_fly_densenet.h5']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations = sorted(glob.glob(HOME + '/deepposekit-data/datasets/fly/*.h5'))\n",
    "annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create an augmentation pipeline\n",
    "DeepPoseKit works with augmenters from the [imgaug package](https://github.com/aleju/imgaug).\n",
    "This is a short example using spatial augmentations with axis flipping and affine transforms\n",
    "See https://github.com/aleju/imgaug for more documentation on augmenters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmenter = []\n",
    "\n",
    "# FlipAxis only works if the data are rotationally aligned on the central body axis\n",
    "augmenter.append(FlipAxis(annotations[0], axis=0))  # flip image up-down\n",
    "augmenter.append(FlipAxis(annotations[0], axis=1))  # flip image left-right \n",
    "\n",
    "sometimes = []\n",
    "sometimes.append(iaa.Affine(scale={\"x\": (0.95, 1.05), \"y\": (0.95, 1.05)},\n",
    "                            translate_percent={'x': (-0.05, 0.05), 'y': (-0.05, 0.05)},\n",
    "                            shear=(-8, 8),\n",
    "                            order=ia.ALL,\n",
    "                            cval=ia.ALL,\n",
    "                            mode=ia.ALL)\n",
    "                 )\n",
    "sometimes.append(iaa.Affine(scale=(0.8, 1.2),\n",
    "                            mode=ia.ALL,\n",
    "                            order=ia.ALL,\n",
    "                            cval=ia.ALL)\n",
    "                 )\n",
    "augmenter.append(iaa.Sometimes(0.75, sometimes))\n",
    "augmenter.append(iaa.Affine(rotate=(-180, 180),\n",
    "                            mode=ia.ALL,\n",
    "                            order=ia.ALL,\n",
    "                            cval=ia.ALL)\n",
    "                 )\n",
    "augmenter = iaa.Sequential(augmenter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a training data generator\n",
    "This creates a data generator for training the model with annotated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'shuffle': True,\n",
       " 'downsample_factor': 2,\n",
       " 'sigma': 5,\n",
       " 'use_graph': True,\n",
       " 'graph_scale': 0.1,\n",
       " 'validation_split': 0.1,\n",
       " 'datapath': '/home/jake/deepposekit-data/datasets/fly/annotation_data_release.h5',\n",
       " 'dataset': 'images',\n",
       " 'output_shape': (48, 48),\n",
       " 'n_validation': 150,\n",
       " 'random_seed': 1,\n",
       " 'n_output_channels': 66,\n",
       " 'augmenter': True,\n",
       " 'n_keypoints': 32}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator = TrainingGenerator(annotations[0],\n",
    "                                    downsample_factor=2,\n",
    "                                    augmenter=augmenter,\n",
    "                                    sigma=5,\n",
    "                                    validation_split=0.1,\n",
    "                                    use_graph=True,\n",
    "                                    random_seed=1,\n",
    "                                    graph_scale=0.1)\n",
    "train_generator.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the training data, rerun this cell to see augmentations\n",
    "n_keypoints = train_generator.n_keypoints\n",
    "batch = train_generator(batch_size=1, validation=False)[0]\n",
    "inputs = batch[0]\n",
    "outputs = batch[1]\n",
    "\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(10,10))\n",
    "ax1.imshow(inputs[0,...,0], cmap='gray', vmin=0, vmax=255)\n",
    "ax2.imshow(outputs[0,...,n_keypoints:-1].max(-1))\n",
    "ax3.imshow(outputs[0,...,:n_keypoints].max(-1))\n",
    "ax4.imshow(outputs[0,...,-1], vmin=0)\n",
    "plt.show()\n",
    "\n",
    "train_generator.on_epoch_end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'StackedDenseNet',\n",
       " 'n_stacks': 2,\n",
       " 'n_layers': 1,\n",
       " 'n_transitions': 5,\n",
       " 'growth_rate': 48,\n",
       " 'bottleneck_factor': 1,\n",
       " 'compression_factor': 0.5,\n",
       " 'batchnorm': False,\n",
       " 'use_bias': True,\n",
       " 'activation': 'selu',\n",
       " 'pooling': 'max',\n",
       " 'interpolation': 'subpixel',\n",
       " 'subpixel': True,\n",
       " 'initializer': 'glorot_uniform',\n",
       " 'separable': False,\n",
       " 'squeeze_excite': False,\n",
       " 'shuffle': True,\n",
       " 'downsample_factor': 2,\n",
       " 'sigma': 5,\n",
       " 'use_graph': True,\n",
       " 'graph_scale': 0.1,\n",
       " 'validation_split': 0.1,\n",
       " 'datapath': '/home/jake/deepposekit-data/datasets/fly/annotation_data_release.h5',\n",
       " 'dataset': 'images',\n",
       " 'output_shape': (48, 48),\n",
       " 'n_validation': 150,\n",
       " 'random_seed': 1,\n",
       " 'n_output_channels': 66,\n",
       " 'augmenter': True,\n",
       " 'n_keypoints': 32}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = StackedDenseNet(data_generator=train_generator, n_stacks=2)\n",
    "# model = DeepLabCut(train_generator)\n",
    "model.compile('adam', 'mse')\n",
    "model.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 192, 192, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "float_1 (Float)                 (None, 192, 192, 1)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "image_normalization_1 (ImageNor (None, 192, 192, 1)  0           float_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 96, 96, 48)   2400        image_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 96, 96, 1)    0           image_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 96, 96, 48)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 96, 96, 49)   0           max_pooling2d_1[0][0]            \n",
      "                                                                 activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 96, 96, 48)   2400        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 96, 96, 48)   0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 96, 96, 48)   20784       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 96, 96, 48)   0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 96, 96, 97)   0           concatenate_1[0][0]              \n",
      "                                                                 activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 48, 48, 97)   0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 48, 48, 48)   4704        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 48, 48, 48)   0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 48, 48, 48)   20784       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 48, 48, 48)   0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 48, 48, 96)   0           activation_4[0][0]               \n",
      "                                                                 activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 24, 24, 96)   0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 24, 24, 48)   4656        max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 24, 24, 48)   0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 24, 24, 48)   20784       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 24, 24, 48)   0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 24, 24, 96)   0           activation_6[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 12, 12, 96)   0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 12, 12, 48)   4656        max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 12, 12, 48)   0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 12, 12, 48)   20784       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 12, 12, 48)   0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 12, 12, 96)   0           activation_8[0][0]               \n",
      "                                                                 activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 6, 6, 96)     0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 6, 6, 48)     4656        max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 6, 6, 48)     0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 6, 6, 48)     20784       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 6, 6, 48)     0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 12, 12, 96)   0           activation_8[0][0]               \n",
      "                                                                 activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 6, 6, 96)     0           activation_10[0][0]              \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 12, 12, 48)   4656        concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "sub_pixel_upscaling_1 (SubPixel (None, 12, 12, 24)   0           concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 12, 12, 48)   0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 12, 12, 72)   0           sub_pixel_upscaling_1[0][0]      \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 12, 12, 48)   3504        concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 12, 12, 48)   0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 12, 12, 48)   20784       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 12, 12, 48)   0           conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 24, 24, 96)   0           activation_6[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 12, 12, 120)  0           concatenate_8[0][0]              \n",
      "                                                                 activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 24, 24, 48)   4656        concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "sub_pixel_upscaling_2 (SubPixel (None, 24, 24, 30)   0           concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 24, 24, 48)   0           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 24, 24, 78)   0           sub_pixel_upscaling_2[0][0]      \n",
      "                                                                 activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 24, 24, 48)   3792        concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 24, 24, 48)   0           conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 24, 24, 48)   20784       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 24, 24, 48)   0           conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 24, 24, 126)  0           concatenate_11[0][0]             \n",
      "                                                                 activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 96, 96, 146)  0           max_pooling2d_1[0][0]            \n",
      "                                                                 activation_1[0][0]               \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 24, 24, 124)  15748       concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 48, 48, 96)   0           activation_4[0][0]               \n",
      "                                                                 activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 48, 48, 146)  0           concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 48, 48, 96)   0           activation_4[0][0]               \n",
      "                                                                 activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 24, 24, 124)  0           conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 48, 48, 48)   4656        concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 48, 48, 73)   10731       max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 48, 48, 48)   4656        concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "sub_pixel_upscaling_3 (SubPixel (None, 48, 48, 31)   0           activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 48, 48, 48)   0           conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 48, 48, 1)    0           image_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 48, 48, 73)   0           conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 48, 48, 48)   0           conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 48, 48, 201)  0           sub_pixel_upscaling_3[0][0]      \n",
      "                                                                 activation_19[0][0]              \n",
      "                                                                 max_pooling2d_6[0][0]            \n",
      "                                                                 activation_20[0][0]              \n",
      "                                                                 activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 48, 48, 48)   9696        concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 48, 48, 48)   0           conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 48, 48, 48)   20784       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 48, 48, 48)   0           conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 48, 48, 249)  0           concatenate_16[0][0]             \n",
      "                                                                 activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 48, 48, 124)  31000       concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 48, 48, 124)  0           conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output_0 (Conv2D)               (None, 48, 48, 66)   8250        activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "image_normalization_2 (ImageNor (None, 48, 48, 66)   0           output_0[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 48, 48, 190)  0           activation_24[0][0]              \n",
      "                                                                 image_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 48, 48, 48)   9168        concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 48, 48, 48)   0           conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 48, 48, 48)   20784       activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 48, 48, 48)   0           conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 48, 48, 238)  0           concatenate_18[0][0]             \n",
      "                                                                 activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 48, 48, 48)   11472       concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 48, 48, 48)   0           conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 48, 48, 48)   20784       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 48, 48, 48)   0           conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)    (None, 48, 48, 286)  0           concatenate_19[0][0]             \n",
      "                                                                 activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 48, 48, 48)   13776       concatenate_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 48, 48, 48)   0           conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 48, 48, 48)   20784       activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 48, 48, 48)   0           conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)    (None, 48, 48, 334)  0           concatenate_20[0][0]             \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 24, 24, 334)  0           concatenate_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 24, 24, 167)  55945       max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 24, 24, 167)  0           conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 24, 24, 48)   8064        activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 24, 24, 48)   0           conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 24, 24, 48)   20784       activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 24, 24, 48)   0           conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)    (None, 24, 24, 215)  0           activation_32[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 24, 24, 48)   10368       concatenate_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 24, 24, 48)   0           conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 24, 24, 48)   20784       activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 24, 24, 48)   0           conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)    (None, 24, 24, 263)  0           concatenate_22[0][0]             \n",
      "                                                                 activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 24, 24, 48)   12672       concatenate_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 24, 24, 48)   0           conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 24, 24, 48)   20784       activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 24, 24, 48)   0           conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_24 (Concatenate)    (None, 24, 24, 311)  0           concatenate_23[0][0]             \n",
      "                                                                 activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 12, 12, 311)  0           concatenate_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 12, 12, 156)  48672       max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 12, 12, 156)  0           conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 12, 12, 48)   7536        activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 12, 12, 48)   0           conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 12, 12, 48)   20784       activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 12, 12, 48)   0           conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_25 (Concatenate)    (None, 12, 12, 204)  0           activation_39[0][0]              \n",
      "                                                                 activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 12, 12, 48)   9840        concatenate_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 12, 12, 48)   0           conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 12, 12, 48)   20784       activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 12, 12, 48)   0           conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_26 (Concatenate)    (None, 12, 12, 252)  0           concatenate_25[0][0]             \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 12, 12, 48)   12144       concatenate_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 12, 12, 48)   0           conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 12, 12, 48)   20784       activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 12, 12, 48)   0           conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_27 (Concatenate)    (None, 12, 12, 300)  0           concatenate_26[0][0]             \n",
      "                                                                 activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 6, 6, 300)    0           concatenate_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 6, 6, 150)    45150       max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 6, 6, 150)    0           conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 6, 6, 48)     7248        activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 6, 6, 48)     0           conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 6, 6, 48)     20784       activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 6, 6, 48)     0           conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_28 (Concatenate)    (None, 6, 6, 198)    0           activation_46[0][0]              \n",
      "                                                                 activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 6, 6, 48)     9552        concatenate_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 6, 6, 48)     0           conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 6, 6, 48)     20784       activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 6, 6, 48)     0           conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_29 (Concatenate)    (None, 6, 6, 246)    0           concatenate_28[0][0]             \n",
      "                                                                 activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 6, 6, 48)     11856       concatenate_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 6, 6, 48)     0           conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 6, 6, 48)     20784       activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 6, 6, 48)     0           conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_30 (Concatenate)    (None, 6, 6, 294)    0           concatenate_29[0][0]             \n",
      "                                                                 activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 6, 6, 292)    86140       concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_31 (Concatenate)    (None, 12, 12, 300)  0           concatenate_26[0][0]             \n",
      "                                                                 activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 6, 6, 292)    0           conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 12, 12, 150)  45150       concatenate_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "sub_pixel_upscaling_4 (SubPixel (None, 12, 12, 73)   0           activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 12, 12, 150)  0           conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_32 (Concatenate)    (None, 12, 12, 223)  0           sub_pixel_upscaling_4[0][0]      \n",
      "                                                                 activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 12, 12, 48)   10752       concatenate_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 12, 12, 48)   0           conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 12, 12, 48)   20784       activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 12, 12, 48)   0           conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_33 (Concatenate)    (None, 12, 12, 271)  0           concatenate_32[0][0]             \n",
      "                                                                 activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 12, 12, 48)   13056       concatenate_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 12, 12, 48)   0           conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 12, 12, 48)   20784       activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 12, 12, 48)   0           conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_34 (Concatenate)    (None, 12, 12, 319)  0           concatenate_33[0][0]             \n",
      "                                                                 activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 12, 12, 320)  102400      concatenate_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_35 (Concatenate)    (None, 24, 24, 311)  0           concatenate_23[0][0]             \n",
      "                                                                 activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 12, 12, 320)  0           conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 24, 24, 156)  48672       concatenate_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "sub_pixel_upscaling_5 (SubPixel (None, 24, 24, 80)   0           activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 24, 24, 156)  0           conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_36 (Concatenate)    (None, 24, 24, 236)  0           sub_pixel_upscaling_5[0][0]      \n",
      "                                                                 activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 24, 24, 48)   11376       concatenate_36[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 24, 24, 48)   0           conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 24, 24, 48)   20784       activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 24, 24, 48)   0           conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_38 (Concatenate)    (None, 48, 48, 334)  0           concatenate_20[0][0]             \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_39 (Concatenate)    (None, 48, 48, 334)  0           concatenate_20[0][0]             \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_37 (Concatenate)    (None, 24, 24, 284)  0           concatenate_36[0][0]             \n",
      "                                                                 activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 48, 48, 167)  55945       concatenate_38[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 48, 48, 167)  55945       concatenate_39[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "sub_pixel_upscaling_6 (SubPixel (None, 48, 48, 71)   0           concatenate_37[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 48, 48, 167)  0           conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 48, 48, 167)  0           conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_40 (Concatenate)    (None, 48, 48, 405)  0           sub_pixel_upscaling_6[0][0]      \n",
      "                                                                 activation_63[0][0]              \n",
      "                                                                 activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 48, 48, 48)   19488       concatenate_40[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 48, 48, 48)   0           conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 48, 48, 48)   20784       activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 48, 48, 48)   0           conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_41 (Concatenate)    (None, 48, 48, 453)  0           concatenate_40[0][0]             \n",
      "                                                                 activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 48, 48, 226)  102604      concatenate_41[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 48, 48, 226)  0           conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output_1 (Conv2D)               (None, 48, 48, 66)   14982       activation_67[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,463,606\n",
      "Trainable params: 1,463,606\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.train_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 17s 2ms/step\n",
      "594.816896748916\n"
     ]
    }
   ],
   "source": [
    "# Test the prediction speed\n",
    "x = np.random.randint(0, 255, (10000, 192, 192, 1), dtype='uint8')\n",
    "model.predict(x[:100], batch_size=100)\n",
    "t0 = time.time()\n",
    "y = model.predict(x, batch_size=100, verbose=1)\n",
    "t1 = time.time()\n",
    "print(x.shape[0]/(t1-t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define callbacks to enhance model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = Logger(HOME + '/deepposekit-data/datasets/fly/log_densenet.h5',\n",
    "                batch_size=10)\n",
    "reduce_lr = ReduceLROnPlateau('val_loss',\n",
    "                              factor=0.2,\n",
    "                              verbose=1)\n",
    "model_checkpoint = ModelCheckpoint(HOME + '/deepposekit-data/datasets/fly/best_model_densenet.h5',\n",
    "                                   monitor='val_loss',\n",
    "                                   verbose=1,\n",
    "                                   save_best_only=True,\n",
    "                                   optimizer=False)\n",
    "early_stop = EarlyStopping('val_loss',\n",
    "                           min_delta=0.001,\n",
    "                           patience=50,\n",
    "                           verbose=1)\n",
    "callbacks = [logger, early_stop, reduce_lr, model_checkpoint]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "84/84 [==============================] - 45s 540ms/step - loss: 141.5929 - output_0_loss: 71.9562 - output_1_loss: 69.6367 - val_loss: 127.7636 - val_output_0_loss: 65.9062 - val_output_1_loss: 61.8574\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 20.8619 13.9248 (1.5311, 74.3796) - mae: 12.8411 9.3500 (0.9800, 45.2200) - mse: 410.8777 97.0960 (1.1721, 2766.1602) - rmse: 14.7516 9.8464 (1.0826, 52.5943)\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 127.76356, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 2/1000\n",
      "84/84 [==============================] - 35s 411ms/step - loss: 123.4802 - output_0_loss: 65.3742 - output_1_loss: 58.1060 - val_loss: 114.6841 - val_output_0_loss: 63.1798 - val_output_1_loss: 51.5043\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 20.0451 14.3249 (1.0671, 72.1541) - mae: 11.5309 9.2665 (0.6600, 40.3005) - mse: 414.4482 103.0886 (0.5694, 2603.1043) - rmse: 14.1740 10.1292 (0.7546, 51.0206)\n",
      "\n",
      "Epoch 00002: val_loss improved from 127.76356 to 114.68405, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 3/1000\n",
      "84/84 [==============================] - 36s 433ms/step - loss: 108.1311 - output_0_loss: 61.4599 - output_1_loss: 46.6712 - val_loss: 97.7990 - val_output_0_loss: 58.4986 - val_output_1_loss: 39.3004\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 10.3509 4.2044 (0.6596, 72.4485) - mae: 6.1413 2.6748 (0.4199, 39.8000) - mse: 205.2073 8.8410 (0.2175, 2624.3938) - rmse: 7.3192 2.9730 (0.4664, 51.2288)\n",
      "\n",
      "Epoch 00003: val_loss improved from 114.68405 to 97.79897, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 4/1000\n",
      "84/84 [==============================] - 38s 447ms/step - loss: 91.8964 - output_0_loss: 57.5500 - output_1_loss: 34.3465 - val_loss: 83.5508 - val_output_0_loss: 54.7832 - val_output_1_loss: 28.7676\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 5.9511 2.6944 (0.5123, 37.3852) - mae: 3.7003 1.7288 (0.3200, 23.9294) - mse: 83.5868 3.6304 (0.1312, 698.8257) - rmse: 4.2081 1.9052 (0.3622, 26.4353)\n",
      "\n",
      "Epoch 00004: val_loss improved from 97.79897 to 83.55084, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 5/1000\n",
      "84/84 [==============================] - 37s 442ms/step - loss: 80.6402 - output_0_loss: 53.8462 - output_1_loss: 26.7940 - val_loss: 75.2245 - val_output_0_loss: 51.3208 - val_output_1_loss: 23.9037\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 5.2108 2.5024 (0.4948, 29.9731) - mae: 3.2574 1.6300 (0.3000, 19.4830) - mse: 58.6598 3.1309 (0.1224, 449.1946) - rmse: 3.6846 1.7694 (0.3499, 21.1942)\n",
      "\n",
      "Epoch 00005: val_loss improved from 83.55084 to 75.22447, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 6/1000\n",
      "84/84 [==============================] - 36s 426ms/step - loss: 74.4513 - output_0_loss: 50.7298 - output_1_loss: 23.7215 - val_loss: 68.6243 - val_output_0_loss: 48.0636 - val_output_1_loss: 20.5607\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 3.9513 2.1145 (0.4561, 19.8573) - mae: 2.5297 1.3350 (0.2800, 13.1607) - mse: 29.2464 2.2361 (0.1040, 197.1576) - rmse: 2.7940 1.4952 (0.3225, 14.0413)\n",
      "\n",
      "Epoch 00006: val_loss improved from 75.22447 to 68.62431, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 7/1000\n",
      "84/84 [==============================] - 37s 437ms/step - loss: 69.4985 - output_0_loss: 48.0178 - output_1_loss: 21.4808 - val_loss: 63.6569 - val_output_0_loss: 45.2328 - val_output_1_loss: 18.4241\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 3.5782 1.9324 (0.3418, 18.6150) - mae: 2.2873 1.2000 (0.2200, 12.1834) - mse: 25.7538 1.8672 (0.0584, 173.2588) - rmse: 2.5302 1.3664 (0.2417, 13.1628)\n",
      "\n",
      "Epoch 00007: val_loss improved from 68.62431 to 63.65687, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 8/1000\n",
      "84/84 [==============================] - 36s 434ms/step - loss: 64.3544 - output_0_loss: 44.2102 - output_1_loss: 20.1442 - val_loss: 56.9272 - val_output_0_loss: 39.4944 - val_output_1_loss: 17.4328\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 3.5603 1.8922 (0.3299, 19.3273) - mae: 2.2851 1.1850 (0.2200, 12.5924) - mse: 24.7474 1.7903 (0.0544, 186.7723) - rmse: 2.5175 1.3380 (0.2332, 13.6665)\n",
      "\n",
      "Epoch 00008: val_loss improved from 63.65687 to 56.92722, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 9/1000\n",
      "84/84 [==============================] - 36s 434ms/step - loss: 56.6931 - output_0_loss: 37.5027 - output_1_loss: 19.1903 - val_loss: 50.0952 - val_output_0_loss: 33.2904 - val_output_1_loss: 16.8048\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 3.2350 1.7412 (0.3394, 17.0024) - mae: 2.0617 1.0877 (0.2000, 10.5552) - mse: 20.6909 1.5160 (0.0576, 144.5402) - rmse: 2.2875 1.2312 (0.2400, 12.0225)\n",
      "\n",
      "Epoch 00009: val_loss improved from 56.92722 to 50.09522, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 10/1000\n",
      "84/84 [==============================] - 37s 437ms/step - loss: 50.8308 - output_0_loss: 32.8036 - output_1_loss: 18.0272 - val_loss: 46.2102 - val_output_0_loss: 30.2164 - val_output_1_loss: 15.9938\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 3.0652 1.6768 (0.3225, 14.9659) - mae: 1.9475 1.0650 (0.2000, 9.3430) - mse: 17.7118 1.4058 (0.0520, 111.9912) - rmse: 2.1674 1.1856 (0.2280, 10.5825)\n",
      "\n",
      "Epoch 00010: val_loss improved from 50.09522 to 46.21015, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 11/1000\n",
      "84/84 [==============================] - 36s 432ms/step - loss: 47.8430 - output_0_loss: 30.4918 - output_1_loss: 17.3512 - val_loss: 42.8479 - val_output_0_loss: 27.3875 - val_output_1_loss: 15.4604\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 3.2000 1.8886 (0.3688, 16.3841) - mae: 2.0503 1.2000 (0.2291, 10.1815) - mse: 17.8535 1.7846 (0.0680, 134.2189) - rmse: 2.2627 1.3354 (0.2608, 11.5853)\n",
      "\n",
      "Epoch 00011: val_loss improved from 46.21015 to 42.84786, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 12/1000\n",
      "84/84 [==============================] - 37s 436ms/step - loss: 45.0239 - output_0_loss: 28.6180 - output_1_loss: 16.4059 - val_loss: 43.5580 - val_output_0_loss: 27.0284 - val_output_1_loss: 16.5295\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 3.2874 2.1538 (0.4252, 14.8791) - mae: 2.1099 1.3700 (0.2600, 9.7410) - mse: 16.5771 2.3200 (0.0904, 110.6937) - rmse: 2.3245 1.5229 (0.3007, 10.5211)\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 42.84786\n",
      "Epoch 13/1000\n",
      "84/84 [==============================] - 36s 433ms/step - loss: 43.1670 - output_0_loss: 27.3763 - output_1_loss: 15.7908 - val_loss: 40.9062 - val_output_0_loss: 25.9638 - val_output_1_loss: 14.9424\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 3.1372 1.8886 (0.4000, 14.5262) - mae: 1.9975 1.1900 (0.2400, 9.1019) - mse: 16.9359 1.7846 (0.0800, 105.5052) - rmse: 2.2183 1.3354 (0.2828, 10.2716)\n",
      "\n",
      "Epoch 00013: val_loss improved from 42.84786 to 40.90618, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 14/1000\n",
      "84/84 [==============================] - 37s 444ms/step - loss: 41.0488 - output_0_loss: 26.1454 - output_1_loss: 14.9034 - val_loss: 37.9238 - val_output_0_loss: 24.4767 - val_output_1_loss: 13.4471\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.8428 1.6904 (0.3225, 13.0821) - mae: 1.8170 1.1050 (0.2000, 8.1653) - mse: 15.3661 1.4288 (0.0520, 85.5708) - rmse: 2.0102 1.1953 (0.2280, 9.2504)\n",
      "\n",
      "Epoch 00014: val_loss improved from 40.90618 to 37.92379, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 15/1000\n",
      "84/84 [==============================] - 37s 436ms/step - loss: 39.6973 - output_0_loss: 25.3932 - output_1_loss: 14.3041 - val_loss: 37.3492 - val_output_0_loss: 23.6238 - val_output_1_loss: 13.7253\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.8574 1.8835 (0.3688, 12.1269) - mae: 1.8219 1.1800 (0.2400, 7.4911) - mse: 12.7364 1.7738 (0.0680, 73.5315) - rmse: 2.0205 1.3318 (0.2608, 8.5750)\n",
      "\n",
      "Epoch 00015: val_loss improved from 37.92379 to 37.34920, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 16/1000\n",
      "84/84 [==============================] - 36s 434ms/step - loss: 38.5882 - output_0_loss: 24.7468 - output_1_loss: 13.8414 - val_loss: 35.4326 - val_output_0_loss: 22.9502 - val_output_1_loss: 12.4824\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.7322 1.5391 (0.3298, 13.0069) - mae: 1.7435 0.9900 (0.2000, 8.3829) - mse: 14.3818 1.1847 (0.0544, 84.5908) - rmse: 1.9320 1.0883 (0.2332, 9.1973)\n",
      "\n",
      "Epoch 00016: val_loss improved from 37.34920 to 35.43258, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 17/1000\n",
      "84/84 [==============================] - 36s 428ms/step - loss: 37.8794 - output_0_loss: 24.2916 - output_1_loss: 13.5877 - val_loss: 34.7290 - val_output_0_loss: 22.4048 - val_output_1_loss: 12.3242\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.5869 1.6321 (0.3124, 11.5736) - mae: 1.6475 1.0300 (0.1898, 7.5010) - mse: 11.4246 1.3339 (0.0488, 66.9746) - rmse: 1.8292 1.1541 (0.2209, 8.1838)\n",
      "\n",
      "Epoch 00017: val_loss improved from 35.43258 to 34.72899, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 18/1000\n",
      "84/84 [==============================] - 38s 456ms/step - loss: 36.8937 - output_0_loss: 23.7255 - output_1_loss: 13.1682 - val_loss: 34.2345 - val_output_0_loss: 22.1591 - val_output_1_loss: 12.0754\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.5680 1.7379 (0.3200, 10.6994) - mae: 1.6337 1.1100 (0.2000, 6.6084) - mse: 12.2533 1.5102 (0.0512, 57.2381) - rmse: 1.8158 1.2289 (0.2263, 7.5656)\n",
      "\n",
      "Epoch 00018: val_loss improved from 34.72899 to 34.23453, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 19/1000\n",
      "84/84 [==============================] - 35s 422ms/step - loss: 36.2280 - output_0_loss: 23.3008 - output_1_loss: 12.9272 - val_loss: 33.5475 - val_output_0_loss: 21.6257 - val_output_1_loss: 11.9219\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.4675 1.6888 (0.3599, 9.2493) - mae: 1.5676 1.0760 (0.2200, 5.8615) - mse: 9.2089 1.4262 (0.0648, 42.7744) - rmse: 1.7448 1.1942 (0.2545, 6.5402)\n",
      "\n",
      "Epoch 00019: val_loss improved from 34.23453 to 33.54755, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 20/1000\n",
      "84/84 [==============================] - 37s 438ms/step - loss: 35.4976 - output_0_loss: 22.8384 - output_1_loss: 12.6592 - val_loss: 31.7553 - val_output_0_loss: 20.7555 - val_output_1_loss: 10.9998\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.3572 1.5869 (0.2828, 10.2201) - mae: 1.4985 0.9700 (0.1800, 6.4003) - mse: 9.0123 1.2593 (0.0400, 52.2248) - rmse: 1.6668 1.1221 (0.2000, 7.2267)\n",
      "\n",
      "Epoch 00020: val_loss improved from 33.54755 to 31.75530, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 21/1000\n",
      "84/84 [==============================] - 36s 432ms/step - loss: 34.6835 - output_0_loss: 22.3039 - output_1_loss: 12.3796 - val_loss: 31.5623 - val_output_0_loss: 20.7261 - val_output_1_loss: 10.8361\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.3812 1.5126 (0.2680, 10.1522) - mae: 1.5199 0.9850 (0.1600, 6.3802) - mse: 9.8236 1.1442 (0.0359, 51.5332) - rmse: 1.6838 1.0696 (0.1895, 7.1787)\n",
      "\n",
      "Epoch 00021: val_loss improved from 31.75530 to 31.56227, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 22/1000\n",
      "84/84 [==============================] - 38s 451ms/step - loss: 34.4331 - output_0_loss: 22.1382 - output_1_loss: 12.2949 - val_loss: 33.7011 - val_output_0_loss: 21.2255 - val_output_1_loss: 12.4756\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.6841 1.9687 (0.4337, 9.6959) - mae: 1.7089 1.2636 (0.2600, 6.3152) - mse: 10.0134 1.9382 (0.0940, 47.0054) - rmse: 1.8980 1.3921 (0.3066, 6.8560)\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 31.56227\n",
      "Epoch 23/1000\n",
      "84/84 [==============================] - 36s 432ms/step - loss: 33.4564 - output_0_loss: 21.6183 - output_1_loss: 11.8381 - val_loss: 32.2479 - val_output_0_loss: 21.1458 - val_output_1_loss: 11.1021\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.4591 1.5720 (0.3574, 10.1499) - mae: 1.5582 1.0100 (0.2200, 6.4312) - mse: 10.2904 1.2356 (0.0639, 51.5107) - rmse: 1.7388 1.1116 (0.2527, 7.1771)\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 31.56227\n",
      "Epoch 24/1000\n",
      "84/84 [==============================] - 39s 460ms/step - loss: 32.8300 - output_0_loss: 21.2371 - output_1_loss: 11.5928 - val_loss: 31.0438 - val_output_0_loss: 19.8836 - val_output_1_loss: 11.1602\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.4771 1.7904 (0.3578, 9.7997) - mae: 1.5775 1.1300 (0.2200, 6.3867) - mse: 9.8173 1.6034 (0.0640, 48.0173) - rmse: 1.7516 1.2660 (0.2530, 6.9295)\n",
      "\n",
      "Epoch 00024: val_loss improved from 31.56227 to 31.04382, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 25/1000\n",
      "84/84 [==============================] - 36s 433ms/step - loss: 32.7696 - output_0_loss: 21.0972 - output_1_loss: 11.6724 - val_loss: 31.2296 - val_output_0_loss: 20.1222 - val_output_1_loss: 11.1074\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.5044 1.7067 (0.3578, 9.4923) - mae: 1.5896 1.0650 (0.2200, 6.1189) - mse: 11.3086 1.4568 (0.0640, 45.0523) - rmse: 1.7709 1.2068 (0.2530, 6.7121)\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 31.04382\n",
      "Epoch 26/1000\n",
      "84/84 [==============================] - 38s 448ms/step - loss: 32.0395 - output_0_loss: 20.7407 - output_1_loss: 11.2987 - val_loss: 30.3471 - val_output_0_loss: 19.8620 - val_output_1_loss: 10.4851\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.2988 1.5510 (0.2800, 9.3042) - mae: 1.4648 0.9600 (0.1600, 5.9230) - mse: 9.8792 1.2030 (0.0392, 43.2838) - rmse: 1.6255 1.0967 (0.1980, 6.5790)\n",
      "\n",
      "Epoch 00026: val_loss improved from 31.04382 to 30.34709, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 27/1000\n",
      "84/84 [==============================] - 37s 436ms/step - loss: 31.9804 - output_0_loss: 20.6739 - output_1_loss: 11.3065 - val_loss: 29.5350 - val_output_0_loss: 19.3067 - val_output_1_loss: 10.2283\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.3520 1.6384 (0.3019, 9.1816) - mae: 1.4912 1.0200 (0.1934, 5.8805) - mse: 9.5087 1.3422 (0.0456, 42.1506) - rmse: 1.6631 1.1585 (0.2135, 6.4923)\n",
      "\n",
      "Epoch 00027: val_loss improved from 30.34709 to 29.53500, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 28/1000\n",
      "84/84 [==============================] - 36s 433ms/step - loss: 31.4567 - output_0_loss: 20.2615 - output_1_loss: 11.1952 - val_loss: 29.7951 - val_output_0_loss: 19.2182 - val_output_1_loss: 10.5769\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.4159 1.7000 (0.3688, 9.3529) - mae: 1.5340 1.0524 (0.2246, 5.9261) - mse: 9.2212 1.4450 (0.0680, 43.7382) - rmse: 1.7083 1.2021 (0.2608, 6.6135)\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 29.53500\n",
      "Epoch 29/1000\n",
      "84/84 [==============================] - 37s 439ms/step - loss: 30.8867 - output_0_loss: 19.9155 - output_1_loss: 10.9712 - val_loss: 27.9875 - val_output_0_loss: 17.9795 - val_output_1_loss: 10.0080\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.3088 1.4228 (0.2561, 9.9297) - mae: 1.4655 0.8750 (0.1600, 6.1777) - mse: 10.3172 1.0128 (0.0328, 49.2995) - rmse: 1.6326 1.0061 (0.1811, 7.0214)\n",
      "\n",
      "Epoch 00029: val_loss improved from 29.53500 to 27.98748, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 30/1000\n",
      "84/84 [==============================] - 36s 431ms/step - loss: 30.5568 - output_0_loss: 19.5680 - output_1_loss: 10.9887 - val_loss: 29.2291 - val_output_0_loss: 18.2186 - val_output_1_loss: 11.0105\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.4682 1.8510 (0.4078, 9.3251) - mae: 1.5708 1.1288 (0.2600, 5.8609) - mse: 8.6105 1.7134 (0.0831, 43.4784) - rmse: 1.7453 1.3089 (0.2883, 6.5938)\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 27.98748\n",
      "Epoch 31/1000\n",
      "84/84 [==============================] - 37s 439ms/step - loss: 30.3501 - output_0_loss: 19.3069 - output_1_loss: 11.0432 - val_loss: 28.3343 - val_output_0_loss: 18.0650 - val_output_1_loss: 10.2693\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.3604 1.6818 (0.3688, 8.4739) - mae: 1.4967 1.0650 (0.2200, 5.4556) - mse: 8.4616 1.4146 (0.0680, 35.9034) - rmse: 1.6690 1.1892 (0.2608, 5.9919)\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 27.98748\n",
      "Epoch 32/1000\n",
      "84/84 [==============================] - 36s 433ms/step - loss: 29.3488 - output_0_loss: 18.6776 - output_1_loss: 10.6712 - val_loss: 27.2635 - val_output_0_loss: 17.1144 - val_output_1_loss: 10.1492\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.3183 1.6729 (0.3794, 8.6848) - mae: 1.4721 1.0300 (0.2400, 5.5602) - mse: 7.9809 1.3994 (0.0720, 37.7126) - rmse: 1.6393 1.1829 (0.2683, 6.1411)\n",
      "\n",
      "Epoch 00032: val_loss improved from 27.98748 to 27.26354, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 33/1000\n",
      "84/84 [==============================] - 36s 427ms/step - loss: 28.7776 - output_0_loss: 18.3406 - output_1_loss: 10.4369 - val_loss: 25.8893 - val_output_0_loss: 16.4950 - val_output_1_loss: 9.3944\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1377 1.5077 (0.2828, 8.0232) - mae: 1.3503 0.9300 (0.1800, 5.0089) - mse: 6.7004 1.1366 (0.0400, 32.1863) - rmse: 1.5116 1.0661 (0.2000, 5.6733)\n",
      "\n",
      "Epoch 00033: val_loss improved from 27.26354 to 25.88934, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 34/1000\n",
      "84/84 [==============================] - 37s 440ms/step - loss: 28.7866 - output_0_loss: 18.2213 - output_1_loss: 10.5654 - val_loss: 26.8944 - val_output_0_loss: 16.8720 - val_output_1_loss: 10.0224\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.2792 1.6146 (0.3124, 8.7828) - mae: 1.4508 1.0232 (0.2000, 5.6163) - mse: 7.3323 1.3036 (0.0488, 38.5689) - rmse: 1.6116 1.1417 (0.2209, 6.2104)\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 25.88934\n",
      "Epoch 35/1000\n",
      "84/84 [==============================] - 36s 430ms/step - loss: 28.2948 - output_0_loss: 17.8997 - output_1_loss: 10.3951 - val_loss: 25.8282 - val_output_0_loss: 16.1785 - val_output_1_loss: 9.6497\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.2717 1.5446 (0.3225, 8.9360) - mae: 1.4466 0.9650 (0.2000, 5.8210) - mse: 9.0839 1.1930 (0.0520, 39.9267) - rmse: 1.6064 1.0922 (0.2280, 6.3187)\n",
      "\n",
      "Epoch 00035: val_loss improved from 25.88934 to 25.82818, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 36/1000\n",
      "84/84 [==============================] - 37s 437ms/step - loss: 28.0417 - output_0_loss: 17.8107 - output_1_loss: 10.2310 - val_loss: 27.1758 - val_output_0_loss: 17.0971 - val_output_1_loss: 10.0787\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.3641 1.6627 (0.3298, 9.3636) - mae: 1.5036 1.0550 (0.2002, 5.8570) - mse: 10.4434 1.3824 (0.0544, 43.8382) - rmse: 1.6716 1.1757 (0.2332, 6.6210)\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 25.82818\n",
      "Epoch 37/1000\n",
      "84/84 [==============================] - 37s 436ms/step - loss: 27.7761 - output_0_loss: 17.6275 - output_1_loss: 10.1487 - val_loss: 25.9174 - val_output_0_loss: 16.2299 - val_output_1_loss: 9.6875\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.2649 1.5122 (0.3418, 8.4805) - mae: 1.4378 0.9598 (0.2200, 5.4369) - mse: 7.6866 1.1438 (0.0584, 35.9597) - rmse: 1.6015 1.0693 (0.2417, 5.9966)\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 25.82818\n",
      "Epoch 38/1000\n",
      "84/84 [==============================] - 37s 435ms/step - loss: 27.7834 - output_0_loss: 17.5491 - output_1_loss: 10.2343 - val_loss: 26.3035 - val_output_0_loss: 16.1929 - val_output_1_loss: 10.1106\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.3693 1.7248 (0.4000, 9.0377) - mae: 1.5009 1.1100 (0.2600, 5.5607) - mse: 8.2670 1.4874 (0.0800, 40.8405) - rmse: 1.6754 1.2196 (0.2828, 6.3906)\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 25.82818\n",
      "Epoch 39/1000\n",
      "84/84 [==============================] - 36s 431ms/step - loss: 27.0519 - output_0_loss: 17.1430 - output_1_loss: 9.9089 - val_loss: 24.9869 - val_output_0_loss: 15.7215 - val_output_1_loss: 9.2654\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1999 1.4296 (0.2561, 8.7746) - mae: 1.3970 0.8900 (0.1600, 5.8204) - mse: 8.3837 1.0219 (0.0328, 38.4968) - rmse: 1.5556 1.0109 (0.1811, 6.2046)\n",
      "\n",
      "Epoch 00039: val_loss improved from 25.82818 to 24.98689, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 40/1000\n",
      "84/84 [==============================] - 36s 425ms/step - loss: 26.7758 - output_0_loss: 16.8934 - output_1_loss: 9.8824 - val_loss: 25.1324 - val_output_0_loss: 15.5244 - val_output_1_loss: 9.6080\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.2387 1.5925 (0.3298, 8.6371) - mae: 1.4217 1.0050 (0.2000, 5.5239) - mse: 7.7559 1.2684 (0.0544, 37.2994) - rmse: 1.5830 1.1261 (0.2332, 6.1073)\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 24.98689\n",
      "Epoch 41/1000\n",
      "84/84 [==============================] - 37s 436ms/step - loss: 27.0517 - output_0_loss: 17.0191 - output_1_loss: 10.0327 - val_loss: 25.6311 - val_output_0_loss: 15.7648 - val_output_1_loss: 9.8663\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.3161 1.6895 (0.3688, 8.6807) - mae: 1.4777 1.0600 (0.2400, 5.4763) - mse: 8.0801 1.4275 (0.0680, 37.6771) - rmse: 1.6377 1.1947 (0.2608, 6.1382)\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 24.98689\n",
      "Epoch 42/1000\n",
      "84/84 [==============================] - 36s 430ms/step - loss: 26.3593 - output_0_loss: 16.6328 - output_1_loss: 9.7265 - val_loss: 25.4601 - val_output_0_loss: 15.7807 - val_output_1_loss: 9.6794\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.2864 1.6483 (0.3771, 8.7076) - mae: 1.4512 1.0600 (0.2400, 5.5352) - mse: 7.4931 1.3590 (0.0711, 37.9109) - rmse: 1.6167 1.1655 (0.2667, 6.1572)\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 24.98689\n",
      "Epoch 43/1000\n",
      "84/84 [==============================] - 37s 437ms/step - loss: 26.1169 - output_0_loss: 16.4863 - output_1_loss: 9.6306 - val_loss: 24.1999 - val_output_0_loss: 15.1075 - val_output_1_loss: 9.0924\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1454 1.5793 (0.3299, 8.1887) - mae: 1.3618 0.9950 (0.2000, 5.0903) - mse: 6.7527 1.2472 (0.0544, 33.5275) - rmse: 1.5171 1.1168 (0.2332, 5.7903)\n",
      "\n",
      "Epoch 00043: val_loss improved from 24.98689 to 24.19985, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 44/1000\n",
      "84/84 [==============================] - 37s 437ms/step - loss: 26.1351 - output_0_loss: 16.4880 - output_1_loss: 9.6471 - val_loss: 24.6663 - val_output_0_loss: 15.2169 - val_output_1_loss: 9.4494\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.2662 1.5930 (0.3441, 9.0216) - mae: 1.4416 1.0000 (0.2200, 5.3801) - mse: 9.4024 1.2688 (0.0592, 40.6944) - rmse: 1.6025 1.1264 (0.2433, 6.3792)\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 24.19985\n",
      "Epoch 45/1000\n",
      "84/84 [==============================] - 36s 426ms/step - loss: 26.1036 - output_0_loss: 16.4691 - output_1_loss: 9.6344 - val_loss: 24.0527 - val_output_0_loss: 14.9412 - val_output_1_loss: 9.1115\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1609 1.5443 (0.2885, 8.4917) - mae: 1.3703 0.9750 (0.1800, 5.1454) - mse: 7.0354 1.1924 (0.0416, 36.0546) - rmse: 1.5280 1.0920 (0.2040, 6.0046)\n",
      "\n",
      "Epoch 00045: val_loss improved from 24.19985 to 24.05269, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 46/1000\n",
      "84/84 [==============================] - 36s 431ms/step - loss: 25.4013 - output_0_loss: 16.0410 - output_1_loss: 9.3603 - val_loss: 25.3949 - val_output_0_loss: 15.6740 - val_output_1_loss: 9.7208\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.3342 1.7185 (0.3599, 8.3114) - mae: 1.4827 1.1000 (0.2200, 5.2387) - mse: 9.4777 1.4766 (0.0648, 34.5395) - rmse: 1.6505 1.2151 (0.2545, 5.8770)\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 24.05269\n",
      "Epoch 47/1000\n",
      "84/84 [==============================] - 37s 445ms/step - loss: 25.5021 - output_0_loss: 16.0803 - output_1_loss: 9.4218 - val_loss: 24.1083 - val_output_0_loss: 14.9174 - val_output_1_loss: 9.1909\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1553 1.5892 (0.3418, 8.0893) - mae: 1.3719 1.0000 (0.2102, 5.0540) - mse: 6.5669 1.2630 (0.0584, 32.7184) - rmse: 1.5240 1.1238 (0.2417, 5.7200)\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 24.05269\n",
      "Epoch 48/1000\n",
      "84/84 [==============================] - 37s 438ms/step - loss: 25.5172 - output_0_loss: 16.0328 - output_1_loss: 9.4844 - val_loss: 23.1121 - val_output_0_loss: 14.3926 - val_output_1_loss: 8.7195\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0971 1.4919 (0.3225, 8.3684) - mae: 1.3320 0.9400 (0.2000, 5.1044) - mse: 7.0043 1.1130 (0.0520, 35.0153) - rmse: 1.4829 1.0549 (0.2280, 5.9174)\n",
      "\n",
      "Epoch 00048: val_loss improved from 24.05269 to 23.11213, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 49/1000\n",
      "84/84 [==============================] - 37s 442ms/step - loss: 25.0371 - output_0_loss: 15.7235 - output_1_loss: 9.3136 - val_loss: 24.1281 - val_output_0_loss: 14.7389 - val_output_1_loss: 9.3892\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.2604 1.6745 (0.3686, 8.8023) - mae: 1.4326 1.0700 (0.2200, 5.4898) - mse: 8.2241 1.4020 (0.0679, 38.7402) - rmse: 1.5983 1.1840 (0.2606, 6.2242)\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 23.11213\n",
      "Epoch 50/1000\n",
      "84/84 [==============================] - 38s 453ms/step - loss: 25.3023 - output_0_loss: 15.8816 - output_1_loss: 9.4206 - val_loss: 23.5782 - val_output_0_loss: 14.6633 - val_output_1_loss: 8.9150\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1346 1.4894 (0.2912, 8.5451) - mae: 1.3561 0.9450 (0.1800, 5.2940) - mse: 7.8894 1.1092 (0.0424, 36.5095) - rmse: 1.5094 1.0532 (0.2059, 6.0423)\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 23.11213\n",
      "Epoch 51/1000\n",
      "84/84 [==============================] - 36s 430ms/step - loss: 24.6325 - output_0_loss: 15.4597 - output_1_loss: 9.1728 - val_loss: 23.9902 - val_output_0_loss: 14.9290 - val_output_1_loss: 9.0612\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.2603 1.4258 (0.3043, 9.6832) - mae: 1.4386 0.9050 (0.1800, 6.2555) - mse: 10.8905 1.0164 (0.0463, 46.8818) - rmse: 1.5983 1.0082 (0.2152, 6.8470)\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 23.11213\n",
      "Epoch 52/1000\n",
      "84/84 [==============================] - 36s 429ms/step - loss: 24.5932 - output_0_loss: 15.4139 - output_1_loss: 9.1793 - val_loss: 23.3211 - val_output_0_loss: 14.5146 - val_output_1_loss: 8.8066\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1051 1.4979 (0.3298, 7.9410) - mae: 1.3375 0.9500 (0.2200, 5.0805) - mse: 6.2994 1.1230 (0.0544, 31.5298) - rmse: 1.4886 1.0592 (0.2332, 5.6151)\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 23.11213\n",
      "Epoch 53/1000\n",
      "84/84 [==============================] - 37s 439ms/step - loss: 24.4972 - output_0_loss: 15.3395 - output_1_loss: 9.1577 - val_loss: 23.3745 - val_output_0_loss: 14.4302 - val_output_1_loss: 8.9444\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1963 1.5329 (0.3225, 8.5852) - mae: 1.3976 0.9764 (0.2000, 5.1800) - mse: 8.5287 1.1750 (0.0520, 36.8528) - rmse: 1.5530 1.0839 (0.2280, 6.0706)\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 23.11213\n",
      "Epoch 54/1000\n",
      "84/84 [==============================] - 37s 439ms/step - loss: 24.2490 - output_0_loss: 15.1862 - output_1_loss: 9.0628 - val_loss: 23.0001 - val_output_0_loss: 14.4470 - val_output_1_loss: 8.5530\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0674 1.3797 (0.3225, 8.3340) - mae: 1.3123 0.8800 (0.2000, 5.2952) - mse: 7.1019 0.9518 (0.0520, 34.7281) - rmse: 1.4619 0.9756 (0.2280, 5.8931)\n",
      "\n",
      "Epoch 00054: val_loss improved from 23.11213 to 23.00005, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 55/1000\n",
      "84/84 [==============================] - 36s 431ms/step - loss: 24.1420 - output_0_loss: 15.1348 - output_1_loss: 9.0072 - val_loss: 23.3374 - val_output_0_loss: 14.3737 - val_output_1_loss: 8.9637\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1930 1.5028 (0.2828, 8.9387) - mae: 1.4058 0.9450 (0.1800, 5.6410) - mse: 9.5300 1.1301 (0.0400, 39.9500) - rmse: 1.5507 1.0627 (0.2000, 6.3206)\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 23.00005\n",
      "Epoch 56/1000\n",
      "84/84 [==============================] - 36s 431ms/step - loss: 24.3240 - output_0_loss: 15.1555 - output_1_loss: 9.1685 - val_loss: 22.1473 - val_output_0_loss: 13.7772 - val_output_1_loss: 8.3701\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0417 1.4050 (0.2828, 8.0775) - mae: 1.3005 0.8920 (0.1800, 5.1405) - mse: 6.9901 0.9878 (0.0400, 32.6227) - rmse: 1.4437 0.9935 (0.1999, 5.7116)\n",
      "\n",
      "Epoch 00056: val_loss improved from 23.00005 to 22.14727, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 57/1000\n",
      "84/84 [==============================] - 37s 443ms/step - loss: 23.8181 - output_0_loss: 14.9160 - output_1_loss: 8.9021 - val_loss: 21.8968 - val_output_0_loss: 13.7181 - val_output_1_loss: 8.1787\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0142 1.3802 (0.2530, 8.2194) - mae: 1.2852 0.8750 (0.1600, 5.3408) - mse: 7.0189 0.9530 (0.0320, 33.7800) - rmse: 1.4243 0.9760 (0.1789, 5.8120)\n",
      "\n",
      "Epoch 00057: val_loss improved from 22.14727 to 21.89685, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 58/1000\n",
      "84/84 [==============================] - 37s 441ms/step - loss: 23.8923 - output_0_loss: 14.9164 - output_1_loss: 8.9760 - val_loss: 23.3203 - val_output_0_loss: 14.3906 - val_output_1_loss: 8.9297\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.2115 1.6453 (0.3774, 7.8507) - mae: 1.4076 1.0400 (0.2400, 5.1202) - mse: 7.6644 1.3536 (0.0712, 30.8171) - rmse: 1.5638 1.1634 (0.2668, 5.5513)\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 21.89685\n",
      "Epoch 59/1000\n",
      "84/84 [==============================] - 36s 429ms/step - loss: 23.6902 - output_0_loss: 14.7419 - output_1_loss: 8.9483 - val_loss: 21.3828 - val_output_0_loss: 13.4360 - val_output_1_loss: 7.9467\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9952 1.4070 (0.2883, 7.9155) - mae: 1.2698 0.8950 (0.1800, 5.0208) - mse: 6.9062 0.9908 (0.0416, 31.3273) - rmse: 1.4108 0.9949 (0.2039, 5.5971)\n",
      "\n",
      "Epoch 00059: val_loss improved from 21.89685 to 21.38276, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 60/1000\n",
      "84/84 [==============================] - 36s 433ms/step - loss: 23.8840 - output_0_loss: 14.8495 - output_1_loss: 9.0345 - val_loss: 22.3370 - val_output_0_loss: 13.5681 - val_output_1_loss: 8.7689\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1069 1.5415 (0.3225, 7.9597) - mae: 1.3432 0.9800 (0.2000, 5.0019) - mse: 6.2964 1.1889 (0.0520, 31.6786) - rmse: 1.4898 1.0900 (0.2280, 5.6284)\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 21.38276\n",
      "Epoch 61/1000\n",
      "84/84 [==============================] - 36s 431ms/step - loss: 23.5599 - output_0_loss: 14.6243 - output_1_loss: 8.9356 - val_loss: 22.5179 - val_output_0_loss: 13.6904 - val_output_1_loss: 8.8275\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1389 1.4857 (0.3225, 8.2284) - mae: 1.3602 0.9450 (0.2000, 5.1255) - mse: 6.8528 1.1038 (0.0520, 33.8533) - rmse: 1.5124 1.0506 (0.2280, 5.8184)\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 21.38276\n",
      "Epoch 62/1000\n",
      "84/84 [==============================] - 36s 426ms/step - loss: 23.2600 - output_0_loss: 14.4451 - output_1_loss: 8.8148 - val_loss: 22.5158 - val_output_0_loss: 13.7257 - val_output_1_loss: 8.7902\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1719 1.6186 (0.3578, 8.4451) - mae: 1.3789 1.0099 (0.2200, 5.2005) - mse: 6.9185 1.3100 (0.0640, 35.6595) - rmse: 1.5358 1.1445 (0.2530, 5.9716)\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 21.38276\n",
      "Epoch 63/1000\n",
      "84/84 [==============================] - 36s 429ms/step - loss: 23.2859 - output_0_loss: 14.4457 - output_1_loss: 8.8403 - val_loss: 22.4812 - val_output_0_loss: 13.6144 - val_output_1_loss: 8.8668\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1842 1.5479 (0.3288, 8.6467) - mae: 1.3907 0.9600 (0.2000, 5.4806) - mse: 8.2117 1.1980 (0.0541, 37.3829) - rmse: 1.5445 1.0945 (0.2325, 6.1142)\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 21.38276\n",
      "Epoch 64/1000\n",
      "84/84 [==============================] - 37s 437ms/step - loss: 23.2301 - output_0_loss: 14.3938 - output_1_loss: 8.8364 - val_loss: 22.6211 - val_output_0_loss: 13.6931 - val_output_1_loss: 8.9280\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1820 1.5436 (0.3392, 7.9860) - mae: 1.3890 0.9700 (0.2102, 5.2005) - mse: 8.8466 1.1914 (0.0575, 31.8881) - rmse: 1.5429 1.0915 (0.2398, 5.6470)\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 21.38276\n",
      "Epoch 65/1000\n",
      "84/84 [==============================] - 37s 435ms/step - loss: 23.1962 - output_0_loss: 14.4127 - output_1_loss: 8.7835 - val_loss: 21.7911 - val_output_0_loss: 13.2051 - val_output_1_loss: 8.5860\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1448 1.5359 (0.3200, 8.1133) - mae: 1.3671 0.9800 (0.2000, 5.1141) - mse: 8.0415 1.1794 (0.0512, 32.9131) - rmse: 1.5166 1.0860 (0.2263, 5.7370)\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 21.38276\n",
      "Epoch 66/1000\n",
      "84/84 [==============================] - 37s 436ms/step - loss: 23.0572 - output_0_loss: 14.3043 - output_1_loss: 8.7528 - val_loss: 21.6831 - val_output_0_loss: 13.2582 - val_output_1_loss: 8.4249\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1150 1.4080 (0.2912, 8.8736) - mae: 1.3483 0.8800 (0.1800, 5.6167) - mse: 8.0206 0.9912 (0.0424, 39.3708) - rmse: 1.4955 0.9956 (0.2059, 6.2746)\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 21.38276\n",
      "Epoch 67/1000\n",
      "84/84 [==============================] - 37s 436ms/step - loss: 23.1063 - output_0_loss: 14.2693 - output_1_loss: 8.8369 - val_loss: 21.9234 - val_output_0_loss: 13.3561 - val_output_1_loss: 8.5673\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1693 1.5441 (0.3124, 7.9288) - mae: 1.3785 0.9699 (0.2000, 5.1207) - mse: 8.2048 1.1922 (0.0488, 31.4331) - rmse: 1.5339 1.0919 (0.2209, 5.6065)\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 21.38276\n",
      "Epoch 68/1000\n",
      "84/84 [==============================] - 37s 442ms/step - loss: 22.4958 - output_0_loss: 13.9027 - output_1_loss: 8.5931 - val_loss: 24.8953 - val_output_0_loss: 14.3747 - val_output_1_loss: 10.5205\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.5135 1.9181 (0.4833, 8.6142) - mae: 1.5871 1.1550 (0.3000, 5.5298) - mse: 8.3189 1.8404 (0.1168, 37.1026) - rmse: 1.7773 1.3563 (0.3417, 6.0912)\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 21.38276\n",
      "Epoch 69/1000\n",
      "84/84 [==============================] - 36s 430ms/step - loss: 22.7062 - output_0_loss: 14.0784 - output_1_loss: 8.6278 - val_loss: 20.8831 - val_output_0_loss: 12.9359 - val_output_1_loss: 7.9472\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9535 1.3367 (0.2912, 7.8769) - mae: 1.2418 0.8550 (0.1800, 4.9226) - mse: 5.8035 0.8938 (0.0424, 31.0228) - rmse: 1.3813 0.9452 (0.2059, 5.5698)\n",
      "\n",
      "Epoch 00069: val_loss improved from 21.38276 to 20.88308, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 70/1000\n",
      "84/84 [==============================] - 36s 434ms/step - loss: 22.3257 - output_0_loss: 13.8838 - output_1_loss: 8.4419 - val_loss: 21.3218 - val_output_0_loss: 13.1119 - val_output_1_loss: 8.2099\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0392 1.4641 (0.2912, 8.1208) - mae: 1.3013 0.9250 (0.2000, 5.1000) - mse: 7.4080 1.0718 (0.0424, 32.9739) - rmse: 1.4419 1.0353 (0.2059, 5.7423)\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 20.88308\n",
      "Epoch 71/1000\n",
      "84/84 [==============================] - 37s 439ms/step - loss: 22.2405 - output_0_loss: 13.7427 - output_1_loss: 8.4977 - val_loss: 21.1677 - val_output_0_loss: 12.9617 - val_output_1_loss: 8.2060\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0442 1.4375 (0.3046, 8.1711) - mae: 1.3001 0.9200 (0.2000, 5.1565) - mse: 6.5090 1.0338 (0.0464, 33.3838) - rmse: 1.4455 1.0165 (0.2154, 5.7779)\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 20.88308\n",
      "Epoch 72/1000\n",
      "84/84 [==============================] - 36s 432ms/step - loss: 22.1561 - output_0_loss: 13.6844 - output_1_loss: 8.4717 - val_loss: 20.9412 - val_output_0_loss: 12.6946 - val_output_1_loss: 8.2466\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0374 1.4445 (0.3046, 7.8858) - mae: 1.2931 0.9250 (0.1800, 4.8600) - mse: 6.1455 1.0434 (0.0464, 31.0931) - rmse: 1.4407 1.0214 (0.2154, 5.5761)\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 20.88308\n",
      "Epoch 73/1000\n",
      "84/84 [==============================] - 36s 431ms/step - loss: 22.1052 - output_0_loss: 13.6626 - output_1_loss: 8.4427 - val_loss: 20.3141 - val_output_0_loss: 12.3355 - val_output_1_loss: 7.9786\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0235 1.3186 (0.2797, 8.1756) - mae: 1.2847 0.8332 (0.1695, 5.3200) - mse: 7.6112 0.8694 (0.0391, 33.4201) - rmse: 1.4308 0.9324 (0.1978, 5.7810)\n",
      "\n",
      "Epoch 00073: val_loss improved from 20.88308 to 20.31411, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 74/1000\n",
      "84/84 [==============================] - 37s 435ms/step - loss: 21.9997 - output_0_loss: 13.6314 - output_1_loss: 8.3683 - val_loss: 21.7080 - val_output_0_loss: 12.9913 - val_output_1_loss: 8.7167\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1872 1.6536 (0.3298, 8.0845) - mae: 1.3870 1.0075 (0.2152, 5.0452) - mse: 6.5914 1.3673 (0.0544, 32.6799) - rmse: 1.5466 1.1692 (0.2332, 5.7166)\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 20.31411\n",
      "Epoch 75/1000\n",
      "84/84 [==============================] - 37s 437ms/step - loss: 21.9789 - output_0_loss: 13.5444 - output_1_loss: 8.4345 - val_loss: 20.1367 - val_output_0_loss: 12.3034 - val_output_1_loss: 7.8333\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0299 1.3677 (0.2883, 7.8613) - mae: 1.2938 0.8800 (0.1800, 4.9803) - mse: 8.3472 0.9354 (0.0416, 30.8997) - rmse: 1.4354 0.9671 (0.2039, 5.5587)\n",
      "\n",
      "Epoch 00075: val_loss improved from 20.31411 to 20.13670, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 76/1000\n",
      "84/84 [==============================] - 38s 447ms/step - loss: 21.9571 - output_0_loss: 13.6262 - output_1_loss: 8.3309 - val_loss: 22.4082 - val_output_0_loss: 13.3903 - val_output_1_loss: 9.0179\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.2622 1.6416 (0.3940, 8.7279) - mae: 1.4340 1.0300 (0.2400, 5.5422) - mse: 8.5892 1.3474 (0.0776, 38.0884) - rmse: 1.5996 1.1608 (0.2786, 6.1716)\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 20.13670\n",
      "Epoch 77/1000\n",
      "84/84 [==============================] - 37s 437ms/step - loss: 21.6988 - output_0_loss: 13.3888 - output_1_loss: 8.3101 - val_loss: 20.8603 - val_output_0_loss: 12.6163 - val_output_1_loss: 8.2439\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0925 1.4289 (0.2683, 8.3448) - mae: 1.3324 0.9050 (0.1800, 5.2536) - mse: 7.4967 1.0216 (0.0360, 34.8182) - rmse: 1.4796 1.0104 (0.1897, 5.9007)\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 20.13670\n",
      "Epoch 78/1000\n",
      "84/84 [==============================] - 37s 441ms/step - loss: 21.8760 - output_0_loss: 13.4284 - output_1_loss: 8.4476 - val_loss: 20.9109 - val_output_0_loss: 12.6246 - val_output_1_loss: 8.2863\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0659 1.4888 (0.2884, 8.4326) - mae: 1.3126 0.9500 (0.1800, 5.2812) - mse: 7.0569 1.1082 (0.0416, 35.5551) - rmse: 1.4608 1.0527 (0.2040, 5.9628)\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 20.13670\n",
      "Epoch 79/1000\n",
      "84/84 [==============================] - 37s 438ms/step - loss: 21.6533 - output_0_loss: 13.3155 - output_1_loss: 8.3379 - val_loss: 21.2207 - val_output_0_loss: 12.6144 - val_output_1_loss: 8.6062\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1465 1.5165 (0.3225, 8.0063) - mae: 1.3607 0.9600 (0.2100, 5.2146) - mse: 6.9474 1.1502 (0.0520, 32.0501) - rmse: 1.5178 1.0723 (0.2280, 5.6613)\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 20.13670\n",
      "Epoch 80/1000\n",
      "84/84 [==============================] - 38s 448ms/step - loss: 21.6879 - output_0_loss: 13.3568 - output_1_loss: 8.3311 - val_loss: 20.0740 - val_output_0_loss: 12.2135 - val_output_1_loss: 7.8605\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9974 1.3392 (0.2800, 7.9045) - mae: 1.2757 0.8500 (0.1800, 5.0015) - mse: 7.0633 0.8968 (0.0392, 31.2407) - rmse: 1.4124 0.9470 (0.1980, 5.5893)\n",
      "\n",
      "Epoch 00080: val_loss improved from 20.13670 to 20.07396, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 81/1000\n",
      "84/84 [==============================] - 36s 431ms/step - loss: 21.4028 - output_0_loss: 13.1408 - output_1_loss: 8.2620 - val_loss: 20.5629 - val_output_0_loss: 12.3049 - val_output_1_loss: 8.2580\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1141 1.4257 (0.2828, 8.4598) - mae: 1.3479 0.8888 (0.1800, 5.3406) - mse: 9.2452 1.0164 (0.0400, 35.7839) - rmse: 1.4949 1.0081 (0.2000, 5.9820)\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 20.07396\n",
      "Epoch 82/1000\n",
      "84/84 [==============================] - 37s 444ms/step - loss: 21.4506 - output_0_loss: 13.1473 - output_1_loss: 8.3032 - val_loss: 20.7358 - val_output_0_loss: 12.4380 - val_output_1_loss: 8.2979\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1006 1.5444 (0.3200, 8.2573) - mae: 1.3394 0.9450 (0.2000, 5.2864) - mse: 7.3512 1.1927 (0.0512, 34.0912) - rmse: 1.4853 1.0921 (0.2263, 5.8388)\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 20.07396\n",
      "Epoch 83/1000\n",
      "84/84 [==============================] - 36s 434ms/step - loss: 21.2519 - output_0_loss: 13.0418 - output_1_loss: 8.2101 - val_loss: 20.9195 - val_output_0_loss: 12.5711 - val_output_1_loss: 8.3485\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0924 1.5880 (0.3578, 8.0864) - mae: 1.3259 1.0318 (0.2200, 5.1663) - mse: 6.2332 1.2622 (0.0640, 32.6949) - rmse: 1.4796 1.1229 (0.2530, 5.7179)\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 20.07396\n",
      "Epoch 84/1000\n",
      "84/84 [==============================] - 38s 455ms/step - loss: 21.2660 - output_0_loss: 13.0358 - output_1_loss: 8.2303 - val_loss: 20.6113 - val_output_0_loss: 12.1088 - val_output_1_loss: 8.5025\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1832 1.5752 (0.3297, 7.9988) - mae: 1.3823 0.9950 (0.2200, 5.2000) - mse: 8.7444 1.2408 (0.0543, 31.9907) - rmse: 1.5438 1.1138 (0.2331, 5.6560)\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 20.07396\n",
      "Epoch 85/1000\n",
      "84/84 [==============================] - 37s 436ms/step - loss: 21.1764 - output_0_loss: 13.0023 - output_1_loss: 8.1741 - val_loss: 21.7001 - val_output_0_loss: 12.8387 - val_output_1_loss: 8.8614\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.2403 1.6123 (0.3688, 8.7561) - mae: 1.4238 0.9900 (0.2400, 5.5128) - mse: 7.9807 1.2998 (0.0680, 38.3348) - rmse: 1.5841 1.1401 (0.2608, 6.1915)\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 20.07396\n",
      "Epoch 86/1000\n",
      "84/84 [==============================] - 37s 444ms/step - loss: 21.3305 - output_0_loss: 13.0735 - output_1_loss: 8.2571 - val_loss: 20.9975 - val_output_0_loss: 12.5892 - val_output_1_loss: 8.4083\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1471 1.5419 (0.3574, 7.7213) - mae: 1.3679 0.9800 (0.2200, 5.0010) - mse: 8.4241 1.1888 (0.0639, 29.8089) - rmse: 1.5182 1.0903 (0.2527, 5.4598)\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 20.07396\n",
      "Epoch 87/1000\n",
      "84/84 [==============================] - 36s 429ms/step - loss: 20.9098 - output_0_loss: 12.8076 - output_1_loss: 8.1022 - val_loss: 22.0480 - val_output_0_loss: 13.2128 - val_output_1_loss: 8.8352\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.2069 1.7587 (0.3225, 7.8746) - mae: 1.3997 1.0800 (0.2149, 4.9004) - mse: 7.4796 1.5468 (0.0520, 31.0044) - rmse: 1.5605 1.2436 (0.2280, 5.5682)\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 20.07396\n",
      "Epoch 88/1000\n",
      "84/84 [==============================] - 37s 445ms/step - loss: 20.7822 - output_0_loss: 12.7123 - output_1_loss: 8.0698 - val_loss: 20.1143 - val_output_0_loss: 11.9454 - val_output_1_loss: 8.1689\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0421 1.4607 (0.2884, 8.2327) - mae: 1.3019 0.9338 (0.1800, 5.2607) - mse: 7.1107 1.0668 (0.0416, 33.8891) - rmse: 1.4440 1.0328 (0.2040, 5.8214)\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 20.07396\n",
      "Epoch 89/1000\n",
      "84/84 [==============================] - 37s 442ms/step - loss: 20.9069 - output_0_loss: 12.7939 - output_1_loss: 8.1130 - val_loss: 19.7480 - val_output_0_loss: 11.8679 - val_output_1_loss: 7.8801\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0334 1.4377 (0.3046, 7.9336) - mae: 1.2979 0.9200 (0.1800, 5.1406) - mse: 7.6111 1.0336 (0.0464, 31.4712) - rmse: 1.4378 1.0166 (0.2154, 5.6099)\n",
      "\n",
      "Epoch 00089: val_loss improved from 20.07396 to 19.74802, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 90/1000\n",
      "84/84 [==============================] - 36s 431ms/step - loss: 20.7913 - output_0_loss: 12.7393 - output_1_loss: 8.0520 - val_loss: 21.3771 - val_output_0_loss: 12.5899 - val_output_1_loss: 8.7872\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1698 1.5766 (0.3688, 7.7702) - mae: 1.3767 0.9950 (0.2304, 5.1614) - mse: 7.3713 1.2434 (0.0680, 30.1881) - rmse: 1.5343 1.1148 (0.2608, 5.4944)\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 19.74802\n",
      "Epoch 91/1000\n",
      "84/84 [==============================] - 37s 440ms/step - loss: 20.9527 - output_0_loss: 12.7633 - output_1_loss: 8.1894 - val_loss: 20.4598 - val_output_0_loss: 11.9614 - val_output_1_loss: 8.4985\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1036 1.5255 (0.3046, 7.9250) - mae: 1.3437 0.9413 (0.2000, 5.0470) - mse: 7.5137 1.1636 (0.0464, 31.4025) - rmse: 1.4875 1.0787 (0.2154, 5.6038)\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 19.74802\n",
      "Epoch 92/1000\n",
      "84/84 [==============================] - 36s 430ms/step - loss: 21.0494 - output_0_loss: 12.7849 - output_1_loss: 8.2645 - val_loss: 19.9020 - val_output_0_loss: 11.7999 - val_output_1_loss: 8.1020\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1028 1.5142 (0.3200, 7.7502) - mae: 1.3412 0.9200 (0.2000, 4.7600) - mse: 8.1409 1.1464 (0.0512, 30.0326) - rmse: 1.4869 1.0707 (0.2263, 5.4802)\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 19.74802\n",
      "Epoch 93/1000\n",
      "84/84 [==============================] - 37s 440ms/step - loss: 20.4810 - output_0_loss: 12.5279 - output_1_loss: 7.9531 - val_loss: 21.2771 - val_output_0_loss: 12.3474 - val_output_1_loss: 8.9297\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.2498 1.7108 (0.4118, 7.7579) - mae: 1.4229 1.0600 (0.2600, 4.9404) - mse: 7.4708 1.4644 (0.0848, 30.0925) - rmse: 1.5909 1.2097 (0.2912, 5.4857)\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 19.74802\n",
      "Epoch 94/1000\n",
      "84/84 [==============================] - 38s 448ms/step - loss: 20.1621 - output_0_loss: 12.3245 - output_1_loss: 7.8376 - val_loss: 20.1539 - val_output_0_loss: 12.0184 - val_output_1_loss: 8.1354\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0727 1.3801 (0.2683, 8.2700) - mae: 1.3190 0.8800 (0.1800, 5.2005) - mse: 7.6990 0.9524 (0.0360, 34.1972) - rmse: 1.4656 0.9759 (0.1897, 5.8478)\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 19.74802\n",
      "Epoch 95/1000\n",
      "84/84 [==============================] - 38s 451ms/step - loss: 20.5240 - output_0_loss: 12.5081 - output_1_loss: 8.0160 - val_loss: 19.6974 - val_output_0_loss: 11.5514 - val_output_1_loss: 8.1459\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1298 1.4441 (0.3046, 8.4614) - mae: 1.3593 0.9050 (0.2000, 5.4529) - mse: 9.2720 1.0428 (0.0464, 35.7979) - rmse: 1.5060 1.0212 (0.2154, 5.9831)\n",
      "\n",
      "Epoch 00095: val_loss improved from 19.74802 to 19.69737, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 96/1000\n",
      "84/84 [==============================] - 36s 431ms/step - loss: 20.2563 - output_0_loss: 12.3657 - output_1_loss: 7.8906 - val_loss: 19.3080 - val_output_0_loss: 11.4439 - val_output_1_loss: 7.8641\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0528 1.4796 (0.3046, 7.9770) - mae: 1.3103 0.9003 (0.2000, 5.0811) - mse: 8.4231 1.0947 (0.0464, 31.8163) - rmse: 1.4516 1.0462 (0.2154, 5.6406)\n",
      "\n",
      "Epoch 00096: val_loss improved from 19.69737 to 19.30804, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 97/1000\n",
      "84/84 [==============================] - 37s 445ms/step - loss: 20.2197 - output_0_loss: 12.3288 - output_1_loss: 7.8909 - val_loss: 19.3001 - val_output_0_loss: 11.3684 - val_output_1_loss: 7.9317\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0892 1.4591 (0.3124, 8.2614) - mae: 1.3338 0.9100 (0.2000, 5.1610) - mse: 9.2298 1.0646 (0.0488, 34.1253) - rmse: 1.4773 1.0317 (0.2209, 5.8417)\n",
      "\n",
      "Epoch 00097: val_loss improved from 19.30804 to 19.30013, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 98/1000\n",
      "84/84 [==============================] - 36s 432ms/step - loss: 20.1704 - output_0_loss: 12.2713 - output_1_loss: 7.8991 - val_loss: 18.9900 - val_output_0_loss: 11.2956 - val_output_1_loss: 7.6944\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9571 1.2827 (0.2561, 8.2571) - mae: 1.2472 0.8000 (0.1600, 5.1600) - mse: 6.8539 0.8228 (0.0328, 34.0903) - rmse: 1.3839 0.9070 (0.1811, 5.8387)\n",
      "\n",
      "Epoch 00098: val_loss improved from 19.30013 to 18.98999, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 99/1000\n",
      "84/84 [==============================] - 37s 442ms/step - loss: 20.4063 - output_0_loss: 12.4325 - output_1_loss: 7.9738 - val_loss: 18.9671 - val_output_0_loss: 11.2732 - val_output_1_loss: 7.6939\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0150 1.3277 (0.2560, 8.6439) - mae: 1.2841 0.8400 (0.1600, 5.5015) - mse: 8.1402 0.8814 (0.0328, 37.3587) - rmse: 1.4248 0.9388 (0.1811, 6.1122)\n",
      "\n",
      "Epoch 00099: val_loss improved from 18.98999 to 18.96707, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 100/1000\n",
      "84/84 [==============================] - 37s 441ms/step - loss: 20.5583 - output_0_loss: 12.4616 - output_1_loss: 8.0967 - val_loss: 18.9155 - val_output_0_loss: 11.2551 - val_output_1_loss: 7.6604\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9398 1.4021 (0.2883, 7.5563) - mae: 1.2334 0.9000 (0.1800, 4.8425) - mse: 6.1102 0.9830 (0.0416, 28.5489) - rmse: 1.3717 0.9914 (0.2039, 5.3431)\n",
      "\n",
      "Epoch 00100: val_loss improved from 18.96707 to 18.91548, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 101/1000\n",
      "84/84 [==============================] - 36s 432ms/step - loss: 20.3342 - output_0_loss: 12.3658 - output_1_loss: 7.9684 - val_loss: 19.9672 - val_output_0_loss: 11.8191 - val_output_1_loss: 8.1481\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0967 1.5042 (0.2828, 8.5503) - mae: 1.3415 0.9500 (0.1800, 5.4210) - mse: 8.6163 1.1314 (0.0400, 36.5539) - rmse: 1.4826 1.0636 (0.2000, 6.0460)\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 18.91548\n",
      "Epoch 102/1000\n",
      "84/84 [==============================] - 37s 439ms/step - loss: 19.9768 - output_0_loss: 12.1334 - output_1_loss: 7.8434 - val_loss: 19.0769 - val_output_0_loss: 11.3566 - val_output_1_loss: 7.7203\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0089 1.4096 (0.3046, 7.8476) - mae: 1.2831 0.9000 (0.1800, 5.0223) - mse: 6.6820 0.9936 (0.0464, 30.7927) - rmse: 1.4205 0.9968 (0.2154, 5.5491)\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 18.91548\n",
      "Epoch 103/1000\n",
      "84/84 [==============================] - 37s 436ms/step - loss: 19.9961 - output_0_loss: 12.1594 - output_1_loss: 7.8367 - val_loss: 18.7981 - val_output_0_loss: 11.2354 - val_output_1_loss: 7.5628\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9400 1.3097 (0.2828, 7.5769) - mae: 1.2324 0.8100 (0.1646, 4.8535) - mse: 6.3017 0.8578 (0.0400, 28.7052) - rmse: 1.3718 0.9261 (0.1999, 5.3577)\n",
      "\n",
      "Epoch 00103: val_loss improved from 18.91548 to 18.79814, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 104/1000\n",
      "84/84 [==============================] - 37s 442ms/step - loss: 19.9901 - output_0_loss: 12.1448 - output_1_loss: 7.8453 - val_loss: 19.6498 - val_output_0_loss: 11.6987 - val_output_1_loss: 7.9511\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0444 1.4320 (0.3122, 7.6594) - mae: 1.3058 0.8950 (0.2000, 5.0209) - mse: 7.4263 1.0254 (0.0487, 29.3336) - rmse: 1.4456 1.0126 (0.2208, 5.4160)\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 18.79814\n",
      "Epoch 105/1000\n",
      "84/84 [==============================] - 36s 430ms/step - loss: 20.1101 - output_0_loss: 12.2266 - output_1_loss: 7.8834 - val_loss: 18.5231 - val_output_0_loss: 11.0644 - val_output_1_loss: 7.4587\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9427 1.3139 (0.2683, 7.7308) - mae: 1.2395 0.8350 (0.1600, 4.9415) - mse: 6.7571 0.8632 (0.0360, 29.8827) - rmse: 1.3737 0.9290 (0.1897, 5.4665)\n",
      "\n",
      "Epoch 00105: val_loss improved from 18.79814 to 18.52313, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 106/1000\n",
      "84/84 [==============================] - 36s 433ms/step - loss: 19.9156 - output_0_loss: 12.0116 - output_1_loss: 7.9040 - val_loss: 18.8338 - val_output_0_loss: 11.0412 - val_output_1_loss: 7.7926\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0376 1.4461 (0.3124, 8.0848) - mae: 1.3006 0.9050 (0.2000, 5.1239) - mse: 8.1521 1.0456 (0.0488, 32.6822) - rmse: 1.4408 1.0225 (0.2209, 5.7168)\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 18.52313\n",
      "Epoch 107/1000\n",
      "84/84 [==============================] - 37s 444ms/step - loss: 20.0076 - output_0_loss: 12.1290 - output_1_loss: 7.8786 - val_loss: 17.8683 - val_output_0_loss: 10.6620 - val_output_1_loss: 7.2062\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.8687 1.2637 (0.2400, 7.5677) - mae: 1.1891 0.8076 (0.1400, 4.9241) - mse: 6.5470 0.7987 (0.0288, 28.6348) - rmse: 1.3214 0.8936 (0.1697, 5.3511)\n",
      "\n",
      "Epoch 00107: val_loss improved from 18.52313 to 17.86829, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 108/1000\n",
      "84/84 [==============================] - 36s 434ms/step - loss: 19.7728 - output_0_loss: 12.0028 - output_1_loss: 7.7699 - val_loss: 18.3621 - val_output_0_loss: 10.8499 - val_output_1_loss: 7.5122\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9446 1.3253 (0.2884, 7.8063) - mae: 1.2372 0.8449 (0.1800, 4.9157) - mse: 6.2849 0.8786 (0.0416, 30.4689) - rmse: 1.3751 0.9371 (0.2040, 5.5199)\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 17.86829\n",
      "Epoch 109/1000\n",
      "84/84 [==============================] - 37s 436ms/step - loss: 19.5876 - output_0_loss: 11.8894 - output_1_loss: 7.6982 - val_loss: 19.4944 - val_output_0_loss: 11.7085 - val_output_1_loss: 7.7859\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9791 1.3632 (0.3043, 7.6935) - mae: 1.2626 0.8597 (0.1800, 4.8292) - mse: 6.3165 0.9292 (0.0463, 29.5953) - rmse: 1.3994 0.9639 (0.2152, 5.4402)\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 17.86829\n",
      "Epoch 110/1000\n",
      "84/84 [==============================] - 37s 440ms/step - loss: 19.8355 - output_0_loss: 12.1068 - output_1_loss: 7.7286 - val_loss: 19.7977 - val_output_0_loss: 11.6883 - val_output_1_loss: 8.1095\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0920 1.5178 (0.3440, 8.0357) - mae: 1.3220 0.9600 (0.2106, 5.1001) - mse: 6.2516 1.1518 (0.0592, 32.2863) - rmse: 1.4793 1.0732 (0.2432, 5.6821)\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 17.86829\n",
      "Epoch 111/1000\n",
      "84/84 [==============================] - 37s 437ms/step - loss: 19.4159 - output_0_loss: 11.7736 - output_1_loss: 7.6423 - val_loss: 19.8075 - val_output_0_loss: 11.4943 - val_output_1_loss: 8.3132\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1135 1.5724 (0.3399, 7.6777) - mae: 1.3423 0.9700 (0.2200, 5.0003) - mse: 6.3938 1.2368 (0.0578, 29.4738) - rmse: 1.4944 1.1119 (0.2403, 5.4290)\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 17.86829\n",
      "Epoch 112/1000\n",
      "84/84 [==============================] - 37s 440ms/step - loss: 19.5716 - output_0_loss: 11.8509 - output_1_loss: 7.7207 - val_loss: 18.2271 - val_output_0_loss: 10.7366 - val_output_1_loss: 7.4905\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9623 1.3992 (0.2884, 7.3955) - mae: 1.2480 0.8550 (0.1800, 4.7003) - mse: 6.9255 0.9789 (0.0416, 27.3463) - rmse: 1.3876 0.9894 (0.2040, 5.2294)\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 17.86829\n",
      "Epoch 113/1000\n",
      "84/84 [==============================] - 36s 433ms/step - loss: 19.5378 - output_0_loss: 11.7896 - output_1_loss: 7.7482 - val_loss: 18.4619 - val_output_0_loss: 10.8295 - val_output_1_loss: 7.6324\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9741 1.4081 (0.2884, 7.6821) - mae: 1.2524 0.8749 (0.1800, 4.7936) - mse: 6.0438 0.9913 (0.0416, 29.5076) - rmse: 1.3959 0.9956 (0.2040, 5.4321)\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 17.86829\n",
      "Epoch 114/1000\n",
      "84/84 [==============================] - 37s 440ms/step - loss: 19.1712 - output_0_loss: 11.6557 - output_1_loss: 7.5155 - val_loss: 17.7747 - val_output_0_loss: 10.4638 - val_output_1_loss: 7.3109\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9180 1.3665 (0.3046, 7.3117) - mae: 1.2193 0.8450 (0.1800, 4.7204) - mse: 6.1948 0.9336 (0.0464, 26.7306) - rmse: 1.3562 0.9662 (0.2154, 5.1702)\n",
      "\n",
      "Epoch 00114: val_loss improved from 17.86829 to 17.77473, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 115/1000\n",
      "84/84 [==============================] - 37s 446ms/step - loss: 19.4763 - output_0_loss: 11.7891 - output_1_loss: 7.6872 - val_loss: 19.5289 - val_output_0_loss: 11.2604 - val_output_1_loss: 8.2685\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1015 1.5137 (0.3418, 7.7220) - mae: 1.3321 0.9450 (0.2200, 4.9605) - mse: 6.2420 1.1457 (0.0584, 29.8146) - rmse: 1.4860 1.0703 (0.2417, 5.4603)\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 17.77473\n",
      "Epoch 116/1000\n",
      "84/84 [==============================] - 36s 430ms/step - loss: 19.4713 - output_0_loss: 11.7603 - output_1_loss: 7.7109 - val_loss: 18.3361 - val_output_0_loss: 10.6376 - val_output_1_loss: 7.6986\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9993 1.4500 (0.3224, 7.3741) - mae: 1.2702 0.9200 (0.2000, 4.8679) - mse: 6.9610 1.0512 (0.0520, 27.1885) - rmse: 1.4137 1.0253 (0.2280, 5.2143)\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 17.77473\n",
      "Epoch 117/1000\n",
      "84/84 [==============================] - 36s 434ms/step - loss: 19.1999 - output_0_loss: 11.5896 - output_1_loss: 7.6103 - val_loss: 18.3242 - val_output_0_loss: 10.6985 - val_output_1_loss: 7.6256\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9877 1.3685 (0.2683, 7.6011) - mae: 1.2613 0.8750 (0.1600, 4.8400) - mse: 6.5507 0.9364 (0.0360, 28.8882) - rmse: 1.4055 0.9677 (0.1897, 5.3748)\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 17.77473\n",
      "Epoch 118/1000\n",
      "84/84 [==============================] - 37s 441ms/step - loss: 19.1021 - output_0_loss: 11.5433 - output_1_loss: 7.5588 - val_loss: 17.9142 - val_output_0_loss: 10.6731 - val_output_1_loss: 7.2411\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.8837 1.2493 (0.2263, 7.5628) - mae: 1.1985 0.7900 (0.1400, 4.7205) - mse: 6.3299 0.7804 (0.0256, 28.5982) - rmse: 1.3320 0.8834 (0.1600, 5.3477)\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 17.77473\n",
      "Epoch 119/1000\n",
      "84/84 [==============================] - 36s 424ms/step - loss: 18.9636 - output_0_loss: 11.4521 - output_1_loss: 7.5115 - val_loss: 19.4591 - val_output_0_loss: 11.2263 - val_output_1_loss: 8.2328\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0727 1.4875 (0.3260, 8.0660) - mae: 1.3160 0.9500 (0.2000, 5.2220) - mse: 6.3640 1.1064 (0.0531, 32.5303) - rmse: 1.4656 1.0518 (0.2305, 5.7035)\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 17.77473\n",
      "Epoch 120/1000\n",
      "84/84 [==============================] - 37s 441ms/step - loss: 18.8235 - output_0_loss: 11.3610 - output_1_loss: 7.4626 - val_loss: 18.6383 - val_output_0_loss: 10.9170 - val_output_1_loss: 7.7213\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0468 1.4295 (0.3124, 7.8413) - mae: 1.3009 0.9100 (0.2000, 5.0213) - mse: 7.6953 1.0218 (0.0488, 30.7432) - rmse: 1.4473 1.0108 (0.2209, 5.5447)\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 17.77473\n",
      "Epoch 121/1000\n",
      "84/84 [==============================] - 37s 440ms/step - loss: 18.9777 - output_0_loss: 11.4568 - output_1_loss: 7.5210 - val_loss: 18.6115 - val_output_0_loss: 10.8368 - val_output_1_loss: 7.7747\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0437 1.5126 (0.2885, 7.7410) - mae: 1.3036 0.9500 (0.1800, 4.8412) - mse: 7.3736 1.1440 (0.0416, 29.9612) - rmse: 1.4451 1.0695 (0.2040, 5.4737)\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 17.77473\n",
      "Epoch 122/1000\n",
      "84/84 [==============================] - 37s 435ms/step - loss: 19.2930 - output_0_loss: 11.6387 - output_1_loss: 7.6543 - val_loss: 17.6177 - val_output_0_loss: 10.4479 - val_output_1_loss: 7.1698\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.8910 1.2859 (0.2529, 7.7039) - mae: 1.2083 0.8150 (0.1600, 4.8401) - mse: 6.9061 0.8276 (0.0320, 29.6751) - rmse: 1.3372 0.9093 (0.1789, 5.4475)\n",
      "\n",
      "Epoch 00122: val_loss improved from 17.77473 to 17.61774, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 123/1000\n",
      "84/84 [==============================] - 37s 445ms/step - loss: 19.1263 - output_0_loss: 11.5082 - output_1_loss: 7.6182 - val_loss: 19.6752 - val_output_0_loss: 11.4114 - val_output_1_loss: 8.2639\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1305 1.6658 (0.3578, 7.2458) - mae: 1.3488 1.0250 (0.2200, 4.7812) - mse: 7.4038 1.3874 (0.0640, 26.2511) - rmse: 1.5065 1.1779 (0.2530, 5.1236)\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 17.61774\n",
      "Epoch 124/1000\n",
      "84/84 [==============================] - 36s 431ms/step - loss: 18.8846 - output_0_loss: 11.4035 - output_1_loss: 7.4810 - val_loss: 19.0156 - val_output_0_loss: 11.2316 - val_output_1_loss: 7.7840\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0339 1.4528 (0.3392, 7.4653) - mae: 1.2915 0.9200 (0.2200, 4.8414) - mse: 6.3887 1.0554 (0.0575, 27.8651) - rmse: 1.4382 1.0273 (0.2398, 5.2787)\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 17.61774\n",
      "Epoch 125/1000\n",
      "84/84 [==============================] - 37s 442ms/step - loss: 19.0953 - output_0_loss: 11.4594 - output_1_loss: 7.6359 - val_loss: 18.4038 - val_output_0_loss: 10.8654 - val_output_1_loss: 7.5384\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9067 1.3194 (0.2828, 7.7794) - mae: 1.2115 0.8206 (0.1800, 4.7259) - mse: 5.9452 0.8704 (0.0400, 30.2599) - rmse: 1.3482 0.9329 (0.2000, 5.5009)\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 17.61774\n",
      "Epoch 126/1000\n",
      "84/84 [==============================] - 37s 436ms/step - loss: 18.9713 - output_0_loss: 11.4024 - output_1_loss: 7.5688 - val_loss: 18.4361 - val_output_0_loss: 10.7933 - val_output_1_loss: 7.6428\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9854 1.3976 (0.2884, 7.6985) - mae: 1.2629 0.8862 (0.1800, 4.7807) - mse: 6.2725 0.9770 (0.0416, 29.6332) - rmse: 1.4039 0.9882 (0.2040, 5.4436)\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 17.61774\n",
      "Epoch 127/1000\n",
      "84/84 [==============================] - 37s 436ms/step - loss: 18.6961 - output_0_loss: 11.2703 - output_1_loss: 7.4258 - val_loss: 18.2229 - val_output_0_loss: 10.5576 - val_output_1_loss: 7.6653\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0159 1.3756 (0.2828, 7.9337) - mae: 1.2835 0.8600 (0.1800, 5.0863) - mse: 7.6235 0.9462 (0.0400, 31.4715) - rmse: 1.4254 0.9727 (0.2000, 5.6099)\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 17.61774\n",
      "Epoch 128/1000\n",
      "84/84 [==============================] - 36s 433ms/step - loss: 18.8355 - output_0_loss: 11.3510 - output_1_loss: 7.4845 - val_loss: 19.1017 - val_output_0_loss: 11.2245 - val_output_1_loss: 7.8771\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0405 1.4663 (0.3225, 7.2924) - mae: 1.2943 0.9100 (0.2000, 4.7400) - mse: 6.2669 1.0750 (0.0520, 26.5894) - rmse: 1.4428 1.0368 (0.2280, 5.1565)\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 17.61774\n",
      "Epoch 129/1000\n",
      "84/84 [==============================] - 37s 442ms/step - loss: 18.5501 - output_0_loss: 11.1622 - output_1_loss: 7.3879 - val_loss: 18.2628 - val_output_0_loss: 10.6381 - val_output_1_loss: 7.6247\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0028 1.4647 (0.2800, 8.0838) - mae: 1.2702 0.9100 (0.1600, 5.0401) - mse: 7.1816 1.0727 (0.0392, 32.6744) - rmse: 1.4162 1.0357 (0.1980, 5.7161)\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 17.61774\n",
      "Epoch 130/1000\n",
      "84/84 [==============================] - 37s 440ms/step - loss: 18.5550 - output_0_loss: 11.1670 - output_1_loss: 7.3880 - val_loss: 18.7347 - val_output_0_loss: 10.8021 - val_output_1_loss: 7.9326\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0775 1.4899 (0.3298, 7.7836) - mae: 1.3197 0.9223 (0.2200, 5.0142) - mse: 6.6828 1.1101 (0.0544, 30.2926) - rmse: 1.4690 1.0535 (0.2332, 5.5039)\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 17.61774\n",
      "Epoch 131/1000\n",
      "84/84 [==============================] - 36s 429ms/step - loss: 18.6593 - output_0_loss: 11.2637 - output_1_loss: 7.3957 - val_loss: 18.6886 - val_output_0_loss: 10.8533 - val_output_1_loss: 7.8353\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0243 1.4762 (0.3124, 7.1286) - mae: 1.2840 0.9300 (0.2000, 4.6600) - mse: 6.0509 1.0896 (0.0488, 25.4083) - rmse: 1.4314 1.0438 (0.2209, 5.0407)\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 17.61774\n",
      "Epoch 132/1000\n",
      "84/84 [==============================] - 37s 445ms/step - loss: 18.8238 - output_0_loss: 11.2995 - output_1_loss: 7.5243 - val_loss: 17.2709 - val_output_0_loss: 10.0751 - val_output_1_loss: 7.1958\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9035 1.2571 (0.2563, 7.5145) - mae: 1.2103 0.7900 (0.1600, 4.9003) - mse: 6.1526 0.7902 (0.0329, 28.2342) - rmse: 1.3460 0.8889 (0.1813, 5.3136)\n",
      "\n",
      "Epoch 00132: val_loss improved from 17.61774 to 17.27093, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 133/1000\n",
      "84/84 [==============================] - 36s 427ms/step - loss: 18.6867 - output_0_loss: 11.2437 - output_1_loss: 7.4431 - val_loss: 17.4259 - val_output_0_loss: 10.0561 - val_output_1_loss: 7.3697\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9895 1.3929 (0.3124, 7.4615) - mae: 1.2674 0.8950 (0.2000, 4.7777) - mse: 8.2742 0.9707 (0.0488, 27.8375) - rmse: 1.4068 0.9849 (0.2209, 5.2761)\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 17.27093\n",
      "Epoch 134/1000\n",
      "84/84 [==============================] - 38s 450ms/step - loss: 18.5105 - output_0_loss: 11.1415 - output_1_loss: 7.3690 - val_loss: 17.6123 - val_output_0_loss: 10.3385 - val_output_1_loss: 7.2738\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9186 1.3585 (0.2561, 7.8621) - mae: 1.2195 0.8600 (0.1600, 4.9748) - mse: 6.4130 0.9230 (0.0328, 30.9060) - rmse: 1.3567 0.9606 (0.1811, 5.5593)\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 17.27093\n",
      "Epoch 135/1000\n",
      "84/84 [==============================] - 36s 433ms/step - loss: 18.8058 - output_0_loss: 11.3479 - output_1_loss: 7.4579 - val_loss: 18.3242 - val_output_0_loss: 10.6211 - val_output_1_loss: 7.7030\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0169 1.4175 (0.3124, 7.5530) - mae: 1.2779 0.8950 (0.2000, 4.7960) - mse: 6.3374 1.0049 (0.0488, 28.5243) - rmse: 1.4261 1.0023 (0.2209, 5.3408)\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 17.27093\n",
      "Epoch 136/1000\n",
      "84/84 [==============================] - 36s 430ms/step - loss: 18.6076 - output_0_loss: 11.1575 - output_1_loss: 7.4500 - val_loss: 18.0593 - val_output_0_loss: 10.5355 - val_output_1_loss: 7.5238\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9937 1.2964 (0.2683, 7.8977) - mae: 1.2741 0.8350 (0.1600, 5.0290) - mse: 9.6560 0.8404 (0.0360, 31.1870) - rmse: 1.4097 0.9167 (0.1897, 5.5845)\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 17.27093\n",
      "Epoch 137/1000\n",
      "84/84 [==============================] - 38s 449ms/step - loss: 18.5748 - output_0_loss: 11.1195 - output_1_loss: 7.4553 - val_loss: 17.7208 - val_output_0_loss: 10.1821 - val_output_1_loss: 7.5387\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0379 1.4228 (0.2912, 8.1715) - mae: 1.2950 0.9150 (0.1800, 5.1070) - mse: 7.9229 1.0122 (0.0424, 33.3867) - rmse: 1.4410 1.0061 (0.2059, 5.7781)\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 17.27093\n",
      "Epoch 138/1000\n",
      "84/84 [==============================] - 37s 443ms/step - loss: 18.3279 - output_0_loss: 11.0292 - output_1_loss: 7.2988 - val_loss: 17.5464 - val_output_0_loss: 10.0485 - val_output_1_loss: 7.4978\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9673 1.3796 (0.2828, 7.5559) - mae: 1.2514 0.8775 (0.1800, 4.8407) - mse: 6.1858 0.9516 (0.0400, 28.5459) - rmse: 1.3911 0.9755 (0.2000, 5.3428)\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 17.27093\n",
      "Epoch 139/1000\n",
      "84/84 [==============================] - 37s 435ms/step - loss: 18.0988 - output_0_loss: 10.9074 - output_1_loss: 7.1914 - val_loss: 18.2142 - val_output_0_loss: 10.3091 - val_output_1_loss: 7.9050\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0719 1.4830 (0.3200, 8.0532) - mae: 1.3166 0.9300 (0.2000, 5.1546) - mse: 6.8915 1.0996 (0.0512, 32.4268) - rmse: 1.4651 1.0486 (0.2263, 5.6944)\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 17.27093\n",
      "Epoch 140/1000\n",
      "84/84 [==============================] - 37s 440ms/step - loss: 18.1708 - output_0_loss: 10.9244 - output_1_loss: 7.2464 - val_loss: 18.0637 - val_output_0_loss: 10.2464 - val_output_1_loss: 7.8172\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0700 1.3982 (0.3122, 8.0189) - mae: 1.3197 0.8886 (0.2000, 5.1604) - mse: 8.4628 0.9778 (0.0487, 32.1513) - rmse: 1.4637 0.9887 (0.2208, 5.6702)\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 17.27093\n",
      "Epoch 141/1000\n",
      "84/84 [==============================] - 37s 444ms/step - loss: 18.3064 - output_0_loss: 11.0083 - output_1_loss: 7.2981 - val_loss: 17.1573 - val_output_0_loss: 9.9293 - val_output_1_loss: 7.2280\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.8938 1.2390 (0.2332, 7.7467) - mae: 1.2054 0.7950 (0.1400, 5.1003) - mse: 6.3033 0.7677 (0.0272, 30.0060) - rmse: 1.3391 0.8761 (0.1649, 5.4778)\n",
      "\n",
      "Epoch 00141: val_loss improved from 17.27093 to 17.15728, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 142/1000\n",
      "84/84 [==============================] - 36s 427ms/step - loss: 18.1247 - output_0_loss: 10.8430 - output_1_loss: 7.2816 - val_loss: 18.8331 - val_output_0_loss: 10.7677 - val_output_1_loss: 8.0654\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1258 1.4810 (0.3225, 8.1507) - mae: 1.3498 0.9200 (0.2000, 5.2103) - mse: 8.2497 1.0970 (0.0520, 33.2173) - rmse: 1.5032 1.0473 (0.2280, 5.7634)\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 17.15728\n",
      "Epoch 143/1000\n",
      "84/84 [==============================] - 37s 441ms/step - loss: 18.2405 - output_0_loss: 10.9220 - output_1_loss: 7.3185 - val_loss: 19.0521 - val_output_0_loss: 10.8736 - val_output_1_loss: 8.1785\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0911 1.3887 (0.3225, 8.2223) - mae: 1.3327 0.8950 (0.2000, 5.3004) - mse: 8.1439 0.9644 (0.0520, 33.8032) - rmse: 1.4786 0.9820 (0.2280, 5.8140)\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 17.15728\n",
      "Epoch 144/1000\n",
      "84/84 [==============================] - 36s 430ms/step - loss: 18.3270 - output_0_loss: 10.9855 - output_1_loss: 7.3415 - val_loss: 19.3267 - val_output_0_loss: 10.9811 - val_output_1_loss: 8.3457\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1640 1.5378 (0.3688, 7.9377) - mae: 1.3735 0.9884 (0.2399, 5.1805) - mse: 6.8730 1.1824 (0.0680, 31.5039) - rmse: 1.5302 1.0874 (0.2608, 5.6128)\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 17.15728\n",
      "Epoch 145/1000\n",
      "84/84 [==============================] - 37s 442ms/step - loss: 18.0884 - output_0_loss: 10.8887 - output_1_loss: 7.1997 - val_loss: 18.5165 - val_output_0_loss: 10.4706 - val_output_1_loss: 8.0459\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0556 1.5431 (0.3124, 7.8105) - mae: 1.3019 0.9650 (0.2000, 5.1042) - mse: 6.3475 1.1906 (0.0488, 30.5018) - rmse: 1.4535 1.0911 (0.2209, 5.5228)\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 17.15728\n",
      "Epoch 146/1000\n",
      "84/84 [==============================] - 37s 435ms/step - loss: 18.2830 - output_0_loss: 10.9775 - output_1_loss: 7.3055 - val_loss: 17.5504 - val_output_0_loss: 10.1755 - val_output_1_loss: 7.3749\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9399 1.3237 (0.2828, 7.6663) - mae: 1.2327 0.8300 (0.1800, 4.7800) - mse: 6.1716 0.8762 (0.0400, 29.3859) - rmse: 1.3718 0.9360 (0.2000, 5.4209)\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 17.15728\n",
      "Epoch 147/1000\n",
      "84/84 [==============================] - 37s 441ms/step - loss: 18.3043 - output_0_loss: 10.9568 - output_1_loss: 7.3475 - val_loss: 17.0205 - val_output_0_loss: 9.9563 - val_output_1_loss: 7.0642\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9016 1.3075 (0.2560, 7.6492) - mae: 1.2126 0.8210 (0.1600, 4.7010) - mse: 6.9291 0.8550 (0.0328, 29.2551) - rmse: 1.3446 0.9245 (0.1811, 5.4088)\n",
      "\n",
      "Epoch 00147: val_loss improved from 17.15728 to 17.02047, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 148/1000\n",
      "84/84 [==============================] - 36s 434ms/step - loss: 18.1917 - output_0_loss: 10.8837 - output_1_loss: 7.3080 - val_loss: 18.0170 - val_output_0_loss: 10.4401 - val_output_1_loss: 7.5769\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0010 1.3537 (0.2828, 7.6941) - mae: 1.2746 0.8700 (0.1800, 4.8536) - mse: 6.8724 0.9166 (0.0400, 29.5994) - rmse: 1.4150 0.9572 (0.2000, 5.4405)\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 17.02047\n",
      "Epoch 149/1000\n",
      "84/84 [==============================] - 36s 434ms/step - loss: 18.0309 - output_0_loss: 10.8311 - output_1_loss: 7.1998 - val_loss: 17.3946 - val_output_0_loss: 10.2250 - val_output_1_loss: 7.1695\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9015 1.3245 (0.2683, 7.5964) - mae: 1.2112 0.8500 (0.1800, 4.7642) - mse: 6.0821 0.8772 (0.0360, 28.8529) - rmse: 1.3445 0.9366 (0.1897, 5.3715)\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 17.02047\n",
      "Epoch 150/1000\n",
      "84/84 [==============================] - 36s 426ms/step - loss: 18.2391 - output_0_loss: 10.9549 - output_1_loss: 7.2842 - val_loss: 16.9033 - val_output_0_loss: 9.7990 - val_output_1_loss: 7.1043\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.8477 1.2252 (0.2332, 7.6195) - mae: 1.1767 0.7700 (0.1400, 4.8718) - mse: 6.2723 0.7506 (0.0272, 29.0286) - rmse: 1.3065 0.8663 (0.1649, 5.3878)\n",
      "\n",
      "Epoch 00150: val_loss improved from 17.02047 to 16.90330, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 151/1000\n",
      "84/84 [==============================] - 38s 448ms/step - loss: 17.9121 - output_0_loss: 10.7375 - output_1_loss: 7.1746 - val_loss: 16.3669 - val_output_0_loss: 9.5148 - val_output_1_loss: 6.8521\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.8518 1.2590 (0.2332, 7.4034) - mae: 1.1778 0.7850 (0.1400, 4.7000) - mse: 6.8059 0.7926 (0.0272, 27.4056) - rmse: 1.3094 0.8902 (0.1649, 5.2350)\n",
      "\n",
      "Epoch 00151: val_loss improved from 16.90330 to 16.36692, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 152/1000\n",
      "84/84 [==============================] - 36s 431ms/step - loss: 18.0686 - output_0_loss: 10.8030 - output_1_loss: 7.2656 - val_loss: 17.8027 - val_output_0_loss: 10.1227 - val_output_1_loss: 7.6800\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9577 1.3205 (0.2561, 7.6488) - mae: 1.2470 0.8500 (0.1600, 4.7615) - mse: 6.3983 0.8718 (0.0328, 29.2518) - rmse: 1.3843 0.9337 (0.1811, 5.4085)\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 16.36692\n",
      "Epoch 153/1000\n",
      "84/84 [==============================] - 36s 434ms/step - loss: 17.7308 - output_0_loss: 10.6208 - output_1_loss: 7.1100 - val_loss: 17.5118 - val_output_0_loss: 10.0373 - val_output_1_loss: 7.4745\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9877 1.3320 (0.2828, 8.0994) - mae: 1.2641 0.8200 (0.1800, 5.0103) - mse: 7.7489 0.8872 (0.0400, 32.8002) - rmse: 1.4055 0.9419 (0.2000, 5.7271)\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 16.36692\n",
      "Epoch 154/1000\n",
      "84/84 [==============================] - 37s 445ms/step - loss: 17.7394 - output_0_loss: 10.6350 - output_1_loss: 7.1044 - val_loss: 17.3988 - val_output_0_loss: 10.0608 - val_output_1_loss: 7.3380\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9238 1.3386 (0.2683, 7.3610) - mae: 1.2245 0.8300 (0.1605, 4.7180) - mse: 6.0097 0.8962 (0.0360, 27.0922) - rmse: 1.3604 0.9465 (0.1897, 5.2050)\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 16.36692\n",
      "Epoch 155/1000\n",
      "84/84 [==============================] - 37s 445ms/step - loss: 17.7673 - output_0_loss: 10.6441 - output_1_loss: 7.1232 - val_loss: 17.7212 - val_output_0_loss: 10.2070 - val_output_1_loss: 7.5142\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9491 1.3632 (0.2828, 7.5309) - mae: 1.2420 0.8510 (0.1800, 4.8205) - mse: 6.2017 0.9295 (0.0400, 28.3574) - rmse: 1.3782 0.9639 (0.2000, 5.3252)\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 16.36692\n",
      "Epoch 156/1000\n",
      "84/84 [==============================] - 36s 434ms/step - loss: 17.9703 - output_0_loss: 10.7510 - output_1_loss: 7.2194 - val_loss: 18.9668 - val_output_0_loss: 10.6888 - val_output_1_loss: 8.2779\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1314 1.6236 (0.3622, 7.4811) - mae: 1.3509 1.0100 (0.2400, 4.7605) - mse: 6.0327 1.3180 (0.0656, 27.9832) - rmse: 1.5071 1.1480 (0.2561, 5.2899)\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 16.36692\n",
      "Epoch 157/1000\n",
      "84/84 [==============================] - 36s 433ms/step - loss: 18.0488 - output_0_loss: 10.8532 - output_1_loss: 7.1957 - val_loss: 18.2214 - val_output_0_loss: 10.5433 - val_output_1_loss: 7.6781\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0023 1.4667 (0.3225, 7.8224) - mae: 1.2693 0.9350 (0.2000, 4.9489) - mse: 6.1301 1.0756 (0.0520, 30.5953) - rmse: 1.4158 1.0371 (0.2280, 5.5313)\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 16.36692\n",
      "Epoch 158/1000\n",
      "84/84 [==============================] - 38s 447ms/step - loss: 17.6482 - output_0_loss: 10.6091 - output_1_loss: 7.0390 - val_loss: 16.5291 - val_output_0_loss: 9.5057 - val_output_1_loss: 7.0234\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.8589 1.2992 (0.2561, 7.2877) - mae: 1.1811 0.8050 (0.1600, 4.6810) - mse: 5.7731 0.8450 (0.0328, 26.5553) - rmse: 1.3144 0.9187 (0.1811, 5.1532)\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 16.36692\n",
      "Epoch 159/1000\n",
      "84/84 [==============================] - 36s 425ms/step - loss: 17.8104 - output_0_loss: 10.6287 - output_1_loss: 7.1817 - val_loss: 16.5957 - val_output_0_loss: 9.7110 - val_output_1_loss: 6.8847\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.8194 1.1973 (0.2527, 7.3642) - mae: 1.1584 0.7450 (0.1600, 4.7947) - mse: 5.3068 0.7168 (0.0319, 27.1157) - rmse: 1.2865 0.8466 (0.1787, 5.2073)\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 16.36692\n",
      "Epoch 160/1000\n",
      "84/84 [==============================] - 36s 433ms/step - loss: 17.8381 - output_0_loss: 10.6767 - output_1_loss: 7.1614 - val_loss: 16.4807 - val_output_0_loss: 9.6110 - val_output_1_loss: 6.8697\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.8002 1.2463 (0.2415, 7.1658) - mae: 1.1455 0.7727 (0.1600, 4.5820) - mse: 5.2939 0.7768 (0.0292, 25.6746) - rmse: 1.2729 0.8813 (0.1707, 5.0670)\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 16.36692\n",
      "Epoch 161/1000\n",
      "84/84 [==============================] - 38s 450ms/step - loss: 17.4912 - output_0_loss: 10.5111 - output_1_loss: 6.9802 - val_loss: 18.8790 - val_output_0_loss: 10.6039 - val_output_1_loss: 8.2751\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.1556 1.6138 (0.3688, 7.4844) - mae: 1.3648 1.0000 (0.2339, 4.7400) - mse: 7.4969 1.3024 (0.0680, 28.0084) - rmse: 1.5243 1.1411 (0.2608, 5.2923)\n",
      "\n",
      "Epoch 00161: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 16.36692\n",
      "Epoch 162/1000\n",
      "84/84 [==============================] - 35s 423ms/step - loss: 16.4513 - output_0_loss: 9.9220 - output_1_loss: 6.5293 - val_loss: 15.9561 - val_output_0_loss: 9.1780 - val_output_1_loss: 6.7781\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.8688 1.2812 (0.2683, 7.0882) - mae: 1.1899 0.8150 (0.1600, 4.5743) - mse: 6.7681 0.8211 (0.0360, 25.1214) - rmse: 1.3214 0.9059 (0.1897, 5.0121)\n",
      "\n",
      "Epoch 00162: val_loss improved from 16.36692 to 15.95612, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 163/1000\n",
      "84/84 [==============================] - 37s 439ms/step - loss: 16.1812 - output_0_loss: 9.8074 - output_1_loss: 6.3738 - val_loss: 16.4528 - val_output_0_loss: 9.3978 - val_output_1_loss: 7.0551\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9318 1.3756 (0.3046, 7.0756) - mae: 1.2261 0.8600 (0.1800, 4.6220) - mse: 6.8862 0.9462 (0.0464, 25.0323) - rmse: 1.3660 0.9727 (0.2154, 5.0032)\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 15.95612\n",
      "Epoch 164/1000\n",
      "84/84 [==============================] - 37s 439ms/step - loss: 16.0173 - output_0_loss: 9.7008 - output_1_loss: 6.3166 - val_loss: 16.1213 - val_output_0_loss: 9.2879 - val_output_1_loss: 6.8334\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.8629 1.3016 (0.2706, 6.8485) - mae: 1.1800 0.8250 (0.1700, 4.4400) - mse: 5.4783 0.8472 (0.0366, 23.4507) - rmse: 1.3173 0.9204 (0.1913, 4.8426)\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 15.95612\n",
      "Epoch 165/1000\n",
      "84/84 [==============================] - 37s 439ms/step - loss: 16.2336 - output_0_loss: 9.8543 - output_1_loss: 6.3793 - val_loss: 16.2107 - val_output_0_loss: 9.2447 - val_output_1_loss: 6.9660\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.8972 1.3302 (0.2883, 7.2586) - mae: 1.2028 0.8427 (0.1800, 4.6005) - mse: 5.5974 0.8848 (0.0416, 26.3437) - rmse: 1.3415 0.9406 (0.2039, 5.1326)\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 15.95612\n",
      "Epoch 166/1000\n",
      "84/84 [==============================] - 37s 444ms/step - loss: 15.9537 - output_0_loss: 9.7154 - output_1_loss: 6.2383 - val_loss: 16.6804 - val_output_0_loss: 9.4688 - val_output_1_loss: 7.2116\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9689 1.4205 (0.3200, 7.2772) - mae: 1.2483 0.8900 (0.2000, 4.6825) - mse: 6.4461 1.0090 (0.0512, 26.4787) - rmse: 1.3922 1.0044 (0.2263, 5.1457)\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 15.95612\n",
      "Epoch 167/1000\n",
      "84/84 [==============================] - 37s 436ms/step - loss: 15.7123 - output_0_loss: 9.5528 - output_1_loss: 6.1595 - val_loss: 15.5528 - val_output_0_loss: 8.9756 - val_output_1_loss: 6.5772\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.8028 1.2181 (0.2561, 7.1931) - mae: 1.1456 0.7600 (0.1600, 4.6417) - mse: 5.5291 0.7420 (0.0328, 25.8701) - rmse: 1.2748 0.8614 (0.1811, 5.0863)\n",
      "\n",
      "Epoch 00167: val_loss improved from 15.95612 to 15.55280, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 168/1000\n",
      "84/84 [==============================] - 37s 438ms/step - loss: 15.9103 - output_0_loss: 9.6882 - output_1_loss: 6.2221 - val_loss: 15.9039 - val_output_0_loss: 9.0859 - val_output_1_loss: 6.8180\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.8640 1.3155 (0.2683, 7.1404) - mae: 1.1846 0.8200 (0.1705, 4.5610) - mse: 5.8338 0.8653 (0.0360, 25.4929) - rmse: 1.3181 0.9302 (0.1897, 5.0491)\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 15.55280\n",
      "Epoch 169/1000\n",
      "84/84 [==============================] - 39s 465ms/step - loss: 15.8140 - output_0_loss: 9.6447 - output_1_loss: 6.1694 - val_loss: 15.8128 - val_output_0_loss: 9.0794 - val_output_1_loss: 6.7334\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.8538 1.2885 (0.2561, 7.2419) - mae: 1.1785 0.7900 (0.1600, 4.6610) - mse: 5.8164 0.8302 (0.0328, 26.2228) - rmse: 1.3108 0.9111 (0.1811, 5.1208)\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 15.55280\n",
      "Epoch 170/1000\n",
      "84/84 [==============================] - 37s 443ms/step - loss: 15.7737 - output_0_loss: 9.6196 - output_1_loss: 6.1540 - val_loss: 16.6083 - val_output_0_loss: 9.3930 - val_output_1_loss: 7.2153\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9734 1.4039 (0.3225, 7.3101) - mae: 1.2536 0.8738 (0.2000, 4.7200) - mse: 7.1324 0.9856 (0.0520, 26.7190) - rmse: 1.3954 0.9927 (0.2280, 5.1690)\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 15.55280\n",
      "Epoch 171/1000\n",
      "84/84 [==============================] - 37s 442ms/step - loss: 15.7107 - output_0_loss: 9.5674 - output_1_loss: 6.1433 - val_loss: 16.5120 - val_output_0_loss: 9.3880 - val_output_1_loss: 7.1240\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9668 1.3265 (0.2912, 7.5055) - mae: 1.2513 0.8400 (0.1800, 4.7414) - mse: 7.5838 0.8798 (0.0424, 28.1662) - rmse: 1.3907 0.9380 (0.2059, 5.3072)\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 15.55280\n",
      "Epoch 172/1000\n",
      "84/84 [==============================] - 37s 438ms/step - loss: 15.8893 - output_0_loss: 9.6673 - output_1_loss: 6.2220 - val_loss: 17.0201 - val_output_0_loss: 9.6110 - val_output_1_loss: 7.4090\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0103 1.4359 (0.3124, 7.4395) - mae: 1.2763 0.8986 (0.2000, 4.8605) - mse: 7.6567 1.0310 (0.0488, 27.6731) - rmse: 1.4215 1.0153 (0.2209, 5.2605)\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 15.55280\n",
      "Epoch 173/1000\n",
      "84/84 [==============================] - 36s 432ms/step - loss: 15.7164 - output_0_loss: 9.5844 - output_1_loss: 6.1321 - val_loss: 16.4453 - val_output_0_loss: 9.2695 - val_output_1_loss: 7.1757\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9658 1.3767 (0.2912, 7.2195) - mae: 1.2497 0.8800 (0.1800, 4.6800) - mse: 7.3577 0.9476 (0.0424, 26.0605) - rmse: 1.3900 0.9734 (0.2059, 5.1049)\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 15.55280\n",
      "Epoch 174/1000\n",
      "84/84 [==============================] - 37s 439ms/step - loss: 15.6719 - output_0_loss: 9.5503 - output_1_loss: 6.1216 - val_loss: 16.6043 - val_output_0_loss: 9.3367 - val_output_1_loss: 7.2676\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0130 1.3559 (0.3198, 7.4820) - mae: 1.2807 0.8550 (0.2000, 4.8577) - mse: 8.4015 0.9192 (0.0511, 27.9902) - rmse: 1.4234 0.9587 (0.2261, 5.2906)\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 15.55280\n",
      "Epoch 175/1000\n",
      "84/84 [==============================] - 36s 428ms/step - loss: 15.6581 - output_0_loss: 9.5709 - output_1_loss: 6.0872 - val_loss: 16.6561 - val_output_0_loss: 9.4070 - val_output_1_loss: 7.2491\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9918 1.3855 (0.3198, 7.3758) - mae: 1.2652 0.8800 (0.2000, 4.7816) - mse: 7.7385 0.9600 (0.0511, 27.2012) - rmse: 1.4084 0.9797 (0.2261, 5.2155)\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 15.55280\n",
      "Epoch 176/1000\n",
      "84/84 [==============================] - 37s 444ms/step - loss: 15.7383 - output_0_loss: 9.6230 - output_1_loss: 6.1153 - val_loss: 16.1210 - val_output_0_loss: 9.0865 - val_output_1_loss: 7.0345\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9436 1.3175 (0.2828, 7.6208) - mae: 1.2351 0.8300 (0.1800, 4.7210) - mse: 7.9888 0.8686 (0.0400, 29.0387) - rmse: 1.3743 0.9316 (0.2000, 5.3888)\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 15.55280\n",
      "Epoch 177/1000\n",
      "84/84 [==============================] - 37s 439ms/step - loss: 15.7513 - output_0_loss: 9.6413 - output_1_loss: 6.1101 - val_loss: 15.1176 - val_output_0_loss: 8.6558 - val_output_1_loss: 6.4618\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.8050 1.2250 (0.2400, 6.8926) - mae: 1.1486 0.7650 (0.1597, 4.3606) - mse: 7.0732 0.7504 (0.0288, 23.7542) - rmse: 1.2763 0.8662 (0.1697, 4.8738)\n",
      "\n",
      "Epoch 00177: val_loss improved from 15.55280 to 15.11760, saving model to /home/jake/deepposekit-data/datasets/fly/best_model_fly_densenet.h5\n",
      "Epoch 178/1000\n",
      "84/84 [==============================] - 37s 438ms/step - loss: 15.6313 - output_0_loss: 9.5675 - output_1_loss: 6.0638 - val_loss: 16.1131 - val_output_0_loss: 9.1078 - val_output_1_loss: 7.0053\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9088 1.3383 (0.2884, 7.3635) - mae: 1.2095 0.8500 (0.1800, 4.6781) - mse: 6.1358 0.8956 (0.0416, 27.1108) - rmse: 1.3497 0.9464 (0.2040, 5.2068)\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 15.11760\n",
      "Epoch 179/1000\n",
      "84/84 [==============================] - 37s 439ms/step - loss: 15.4346 - output_0_loss: 9.4528 - output_1_loss: 5.9818 - val_loss: 15.8046 - val_output_0_loss: 8.8968 - val_output_1_loss: 6.9078\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.8877 1.3078 (0.2560, 7.4723) - mae: 1.1980 0.8250 (0.1600, 4.8563) - mse: 6.4249 0.8554 (0.0328, 27.9175) - rmse: 1.3348 0.9248 (0.1811, 5.2837)\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 15.11760\n",
      "Epoch 180/1000\n",
      "84/84 [==============================] - 37s 437ms/step - loss: 15.7179 - output_0_loss: 9.6206 - output_1_loss: 6.0974 - val_loss: 16.6428 - val_output_0_loss: 9.3532 - val_output_1_loss: 7.2896\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0066 1.3944 (0.2912, 7.4439) - mae: 1.2736 0.8650 (0.1800, 4.8800) - mse: 7.7369 0.9722 (0.0424, 27.7061) - rmse: 1.4189 0.9860 (0.2059, 5.2637)\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 15.11760\n",
      "Epoch 181/1000\n",
      "84/84 [==============================] - 37s 439ms/step - loss: 15.7093 - output_0_loss: 9.6063 - output_1_loss: 6.1030 - val_loss: 16.2839 - val_output_0_loss: 9.2132 - val_output_1_loss: 7.0707\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9535 1.3235 (0.2885, 7.5533) - mae: 1.2411 0.8300 (0.1800, 4.8410) - mse: 7.6278 0.8758 (0.0416, 28.5259) - rmse: 1.3813 0.9358 (0.2040, 5.3410)\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 15.11760\n",
      "Epoch 182/1000\n",
      "84/84 [==============================] - 37s 439ms/step - loss: 15.4754 - output_0_loss: 9.4911 - output_1_loss: 5.9843 - val_loss: 15.6355 - val_output_0_loss: 8.8892 - val_output_1_loss: 6.7462\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.8836 1.2361 (0.2530, 7.5613) - mae: 1.1963 0.7950 (0.1600, 4.8201) - mse: 7.2524 0.7640 (0.0320, 28.5869) - rmse: 1.3319 0.8741 (0.1789, 5.3467)\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 15.11760\n",
      "Epoch 183/1000\n",
      "84/84 [==============================] - 36s 432ms/step - loss: 15.5029 - output_0_loss: 9.4836 - output_1_loss: 6.0193 - val_loss: 15.9614 - val_output_0_loss: 9.0053 - val_output_1_loss: 6.9561\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9149 1.3209 (0.2911, 7.4674) - mae: 1.2135 0.8400 (0.1800, 4.8041) - mse: 6.4684 0.8724 (0.0424, 27.8812) - rmse: 1.3540 0.9340 (0.2059, 5.2803)\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 15.11760\n",
      "Epoch 184/1000\n",
      "84/84 [==============================] - 37s 436ms/step - loss: 15.6301 - output_0_loss: 9.5514 - output_1_loss: 6.0787 - val_loss: 16.4817 - val_output_0_loss: 9.1567 - val_output_1_loss: 7.3250\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 2.0292 1.4222 (0.3224, 7.4695) - mae: 1.2884 0.8861 (0.2000, 4.8552) - mse: 8.3461 1.0114 (0.0520, 27.8964) - rmse: 1.4349 1.0057 (0.2280, 5.2817)\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 15.11760\n",
      "Epoch 185/1000\n",
      "84/84 [==============================] - 37s 439ms/step - loss: 15.5273 - output_0_loss: 9.5355 - output_1_loss: 5.9918 - val_loss: 15.3296 - val_output_0_loss: 8.6913 - val_output_1_loss: 6.6383\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.8328 1.2048 (0.2263, 7.2822) - mae: 1.1677 0.7673 (0.1400, 4.6186) - mse: 7.4346 0.7259 (0.0256, 26.5150) - rmse: 1.2960 0.8519 (0.1600, 5.1493)\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 15.11760\n",
      "Epoch 186/1000\n",
      "84/84 [==============================] - 38s 451ms/step - loss: 15.5003 - output_0_loss: 9.4982 - output_1_loss: 6.0021 - val_loss: 15.9646 - val_output_0_loss: 8.9379 - val_output_1_loss: 7.0266\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9155 1.3254 (0.2828, 7.3817) - mae: 1.2158 0.8300 (0.1800, 4.7204) - mse: 7.3729 0.8784 (0.0400, 27.2449) - rmse: 1.3545 0.9372 (0.2000, 5.2197)\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 15.11760\n",
      "Epoch 187/1000\n",
      "84/84 [==============================] - 37s 437ms/step - loss: 15.5129 - output_0_loss: 9.4874 - output_1_loss: 6.0255 - val_loss: 15.7517 - val_output_0_loss: 8.8721 - val_output_1_loss: 6.8796\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9065 1.3038 (0.2800, 7.4577) - mae: 1.2119 0.8400 (0.1600, 4.8210) - mse: 6.9166 0.8500 (0.0392, 27.8087) - rmse: 1.3481 0.9219 (0.1980, 5.2734)\n",
      "\n",
      "Epoch 00187: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 15.11760\n",
      "Epoch 188/1000\n",
      "84/84 [==============================] - 36s 430ms/step - loss: 15.2360 - output_0_loss: 9.3671 - output_1_loss: 5.8689 - val_loss: 15.8786 - val_output_0_loss: 8.9096 - val_output_1_loss: 6.9691\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9266 1.3096 (0.2884, 7.2539) - mae: 1.2243 0.8450 (0.1800, 4.7410) - mse: 7.4051 0.8576 (0.0416, 26.3094) - rmse: 1.3623 0.9261 (0.2040, 5.1293)\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 15.11760\n",
      "Epoch 189/1000\n",
      "84/84 [==============================] - 37s 441ms/step - loss: 15.1251 - output_0_loss: 9.2987 - output_1_loss: 5.8264 - val_loss: 15.6805 - val_output_0_loss: 8.8119 - val_output_1_loss: 6.8686\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9036 1.3154 (0.2800, 7.1583) - mae: 1.2106 0.8115 (0.1800, 4.6805) - mse: 7.4025 0.8652 (0.0392, 25.6210) - rmse: 1.3460 0.9301 (0.1980, 5.0617)\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 15.11760\n",
      "Epoch 190/1000\n",
      "84/84 [==============================] - 36s 433ms/step - loss: 15.2028 - output_0_loss: 9.3482 - output_1_loss: 5.8546 - val_loss: 15.8007 - val_output_0_loss: 8.8613 - val_output_1_loss: 6.9394\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9270 1.2943 (0.2883, 7.3335) - mae: 1.2247 0.8181 (0.1800, 4.7000) - mse: 7.5428 0.8376 (0.0416, 26.8899) - rmse: 1.3626 0.9152 (0.2039, 5.1855)\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 15.11760\n",
      "Epoch 191/1000\n",
      "84/84 [==============================] - 36s 434ms/step - loss: 14.9720 - output_0_loss: 9.2159 - output_1_loss: 5.7561 - val_loss: 15.8271 - val_output_0_loss: 8.9059 - val_output_1_loss: 6.9212\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9206 1.3116 (0.2912, 7.2643) - mae: 1.2209 0.8300 (0.1800, 4.7205) - mse: 7.3612 0.8601 (0.0424, 26.3848) - rmse: 1.3581 0.9274 (0.2059, 5.1366)\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 15.11760\n",
      "Epoch 192/1000\n",
      "84/84 [==============================] - 37s 445ms/step - loss: 15.0042 - output_0_loss: 9.2367 - output_1_loss: 5.7675 - val_loss: 15.6898 - val_output_0_loss: 8.8278 - val_output_1_loss: 6.8620\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9012 1.2886 (0.2560, 7.2027) - mae: 1.2091 0.8200 (0.1600, 4.7800) - mse: 7.4459 0.8302 (0.0328, 25.9396) - rmse: 1.3443 0.9112 (0.1811, 5.0931)\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 15.11760\n",
      "Epoch 193/1000\n",
      "84/84 [==============================] - 36s 428ms/step - loss: 14.8739 - output_0_loss: 9.1714 - output_1_loss: 5.7025 - val_loss: 16.0779 - val_output_0_loss: 8.9944 - val_output_1_loss: 7.0835\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9549 1.3405 (0.2912, 7.2936) - mae: 1.2416 0.8400 (0.1800, 4.7405) - mse: 7.6278 0.8985 (0.0424, 26.5980) - rmse: 1.3823 0.9478 (0.2059, 5.1573)\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 15.11760\n",
      "Epoch 194/1000\n",
      "84/84 [==============================] - 38s 448ms/step - loss: 15.1680 - output_0_loss: 9.3432 - output_1_loss: 5.8248 - val_loss: 15.4894 - val_output_0_loss: 8.7427 - val_output_1_loss: 6.7466\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.8840 1.2531 (0.2530, 7.2113) - mae: 1.1983 0.7950 (0.1600, 4.7405) - mse: 7.5753 0.7852 (0.0320, 26.0011) - rmse: 1.3322 0.8861 (0.1789, 5.0991)\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 15.11760\n",
      "Epoch 195/1000\n",
      "84/84 [==============================] - 37s 443ms/step - loss: 14.9933 - output_0_loss: 9.2309 - output_1_loss: 5.7624 - val_loss: 16.1501 - val_output_0_loss: 8.9970 - val_output_1_loss: 7.1531\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9729 1.3612 (0.3046, 7.3220) - mae: 1.2531 0.8600 (0.1800, 4.7810) - mse: 7.7241 0.9266 (0.0464, 26.8061) - rmse: 1.3951 0.9625 (0.2154, 5.1775)\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 15.11760\n",
      "Epoch 196/1000\n",
      "84/84 [==============================] - 37s 442ms/step - loss: 14.9824 - output_0_loss: 9.2462 - output_1_loss: 5.7361 - val_loss: 16.1100 - val_output_0_loss: 8.9616 - val_output_1_loss: 7.1484\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9792 1.3489 (0.2912, 7.4647) - mae: 1.2561 0.8599 (0.1800, 4.8422) - mse: 7.8566 0.9098 (0.0424, 27.8612) - rmse: 1.3995 0.9538 (0.2059, 5.2784)\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 15.11760\n",
      "Epoch 197/1000\n",
      "84/84 [==============================] - 37s 441ms/step - loss: 15.1712 - output_0_loss: 9.3472 - output_1_loss: 5.8240 - val_loss: 15.7402 - val_output_0_loss: 8.8095 - val_output_1_loss: 6.9307\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9098 1.2923 (0.2683, 7.3222) - mae: 1.2156 0.8170 (0.1800, 4.8165) - mse: 7.6156 0.8352 (0.0360, 26.8077) - rmse: 1.3504 0.9138 (0.1897, 5.1776)\n",
      "\n",
      "Epoch 00197: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 15.11760\n",
      "Epoch 198/1000\n",
      "84/84 [==============================] - 37s 445ms/step - loss: 15.0219 - output_0_loss: 9.2682 - output_1_loss: 5.7537 - val_loss: 15.6066 - val_output_0_loss: 8.7607 - val_output_1_loss: 6.8459\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.8973 1.2601 (0.2561, 7.3169) - mae: 1.2079 0.7950 (0.1600, 4.8200) - mse: 7.6684 0.7940 (0.0328, 26.7686) - rmse: 1.3416 0.8910 (0.1811, 5.1738)\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 15.11760\n",
      "Epoch 199/1000\n",
      "84/84 [==============================] - 37s 435ms/step - loss: 15.0350 - output_0_loss: 9.2678 - output_1_loss: 5.7672 - val_loss: 15.7208 - val_output_0_loss: 8.8174 - val_output_1_loss: 6.9034\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9077 1.2909 (0.2800, 7.3158) - mae: 1.2139 0.8100 (0.1600, 4.7772) - mse: 7.6264 0.8332 (0.0392, 26.7602) - rmse: 1.3490 0.9128 (0.1980, 5.1730)\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 15.11760\n",
      "Epoch 200/1000\n",
      "84/84 [==============================] - 37s 436ms/step - loss: 15.1071 - output_0_loss: 9.3165 - output_1_loss: 5.7906 - val_loss: 15.7601 - val_output_0_loss: 8.8451 - val_output_1_loss: 6.9149\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9137 1.2964 (0.2797, 7.3158) - mae: 1.2176 0.8100 (0.1600, 4.7176) - mse: 7.6511 0.8404 (0.0391, 26.7602) - rmse: 1.3532 0.9167 (0.1978, 5.1730)\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 15.11760\n",
      "Epoch 201/1000\n",
      "84/84 [==============================] - 36s 433ms/step - loss: 14.9828 - output_0_loss: 9.2402 - output_1_loss: 5.7426 - val_loss: 15.7547 - val_output_0_loss: 8.8389 - val_output_1_loss: 6.9159\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9149 1.2870 (0.2820, 7.2030) - mae: 1.2181 0.8150 (0.1800, 4.7064) - mse: 7.6302 0.8282 (0.0398, 25.9420) - rmse: 1.3540 0.9100 (0.1994, 5.0933)\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 15.11760\n",
      "Epoch 202/1000\n",
      "84/84 [==============================] - 37s 439ms/step - loss: 15.0291 - output_0_loss: 9.2558 - output_1_loss: 5.7733 - val_loss: 15.8200 - val_output_0_loss: 8.8799 - val_output_1_loss: 6.9402\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9216 1.2893 (0.2828, 7.2434) - mae: 1.2223 0.8300 (0.1800, 4.6869) - mse: 7.6392 0.8312 (0.0400, 26.2338) - rmse: 1.3588 0.9117 (0.2000, 5.1219)\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 15.11760\n",
      "Epoch 203/1000\n",
      "84/84 [==============================] - 36s 431ms/step - loss: 14.9835 - output_0_loss: 9.2472 - output_1_loss: 5.7363 - val_loss: 15.8383 - val_output_0_loss: 8.8884 - val_output_1_loss: 6.9499\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9256 1.3058 (0.2828, 7.2426) - mae: 1.2246 0.8200 (0.1800, 4.7019) - mse: 7.6603 0.8526 (0.0400, 26.2280) - rmse: 1.3616 0.9233 (0.1999, 5.1213)\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 15.11760\n",
      "Epoch 204/1000\n",
      "84/84 [==============================] - 37s 440ms/step - loss: 15.1204 - output_0_loss: 9.3256 - output_1_loss: 5.7948 - val_loss: 15.6746 - val_output_0_loss: 8.8137 - val_output_1_loss: 6.8610\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9030 1.2738 (0.2561, 7.2022) - mae: 1.2108 0.7997 (0.1600, 4.7774) - mse: 7.6331 0.8114 (0.0328, 25.9362) - rmse: 1.3457 0.9007 (0.1811, 5.0928)\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 15.11760\n",
      "Epoch 205/1000\n",
      "84/84 [==============================] - 36s 433ms/step - loss: 15.0256 - output_0_loss: 9.2752 - output_1_loss: 5.7504 - val_loss: 15.7599 - val_output_0_loss: 8.8561 - val_output_1_loss: 6.9039\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9143 1.2790 (0.2797, 7.2420) - mae: 1.2177 0.8050 (0.1800, 4.7415) - mse: 7.6522 0.8180 (0.0391, 26.2236) - rmse: 1.3536 0.9044 (0.1978, 5.1209)\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 15.11760\n",
      "Epoch 206/1000\n",
      "84/84 [==============================] - 36s 433ms/step - loss: 15.0829 - output_0_loss: 9.3006 - output_1_loss: 5.7823 - val_loss: 15.7761 - val_output_0_loss: 8.8569 - val_output_1_loss: 6.9192\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9195 1.2976 (0.2828, 7.2385) - mae: 1.2208 0.8200 (0.1800, 4.7404) - mse: 7.6481 0.8420 (0.0400, 26.1976) - rmse: 1.3573 0.9175 (0.2000, 5.1184)\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 15.11760\n",
      "Epoch 207/1000\n",
      "84/84 [==============================] - 38s 449ms/step - loss: 15.0057 - output_0_loss: 9.2584 - output_1_loss: 5.7473 - val_loss: 15.7993 - val_output_0_loss: 8.8613 - val_output_1_loss: 6.9380\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9230 1.3052 (0.2683, 7.2487) - mae: 1.2231 0.8150 (0.1799, 4.7005) - mse: 7.6584 0.8518 (0.0360, 26.2720) - rmse: 1.3598 0.9229 (0.1897, 5.1256)\n",
      "\n",
      "Epoch 00207: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 15.11760\n",
      "Epoch 208/1000\n",
      "84/84 [==============================] - 36s 431ms/step - loss: 14.9515 - output_0_loss: 9.2397 - output_1_loss: 5.7118 - val_loss: 15.7818 - val_output_0_loss: 8.8522 - val_output_1_loss: 6.9296\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9211 1.3008 (0.2828, 7.2415) - mae: 1.2217 0.8200 (0.1797, 4.7002) - mse: 7.6544 0.8460 (0.0400, 26.2195) - rmse: 1.3584 0.9198 (0.1999, 5.1205)\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 15.11760\n",
      "Epoch 209/1000\n",
      "84/84 [==============================] - 37s 435ms/step - loss: 15.0189 - output_0_loss: 9.2774 - output_1_loss: 5.7416 - val_loss: 15.8074 - val_output_0_loss: 8.8647 - val_output_1_loss: 6.9427\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9243 1.3008 (0.2769, 7.2497) - mae: 1.2237 0.8200 (0.1799, 4.7006) - mse: 7.6679 0.8460 (0.0383, 26.2789) - rmse: 1.3607 0.9198 (0.1958, 5.1263)\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 15.11760\n",
      "Epoch 210/1000\n",
      "84/84 [==============================] - 37s 442ms/step - loss: 15.0232 - output_0_loss: 9.2701 - output_1_loss: 5.7531 - val_loss: 15.8079 - val_output_0_loss: 8.8626 - val_output_1_loss: 6.9453\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9252 1.2997 (0.2683, 7.2607) - mae: 1.2242 0.8200 (0.1800, 4.7184) - mse: 7.6708 0.8446 (0.0360, 26.3591) - rmse: 1.3613 0.9190 (0.1897, 5.1341)\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 15.11760\n",
      "Epoch 211/1000\n",
      "84/84 [==============================] - 37s 441ms/step - loss: 15.0336 - output_0_loss: 9.2869 - output_1_loss: 5.7467 - val_loss: 15.7973 - val_output_0_loss: 8.8604 - val_output_1_loss: 6.9369\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9231 1.2997 (0.2797, 7.2607) - mae: 1.2229 0.8150 (0.1800, 4.6972) - mse: 7.6643 0.8446 (0.0391, 26.3591) - rmse: 1.3598 0.9190 (0.1978, 5.1341)\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 15.11760\n",
      "Epoch 212/1000\n",
      "84/84 [==============================] - 37s 438ms/step - loss: 15.0316 - output_0_loss: 9.2948 - output_1_loss: 5.7367 - val_loss: 15.8013 - val_output_0_loss: 8.8645 - val_output_1_loss: 6.9367\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9234 1.2997 (0.2683, 7.2812) - mae: 1.2231 0.8150 (0.1800, 4.7012) - mse: 7.6666 0.8446 (0.0360, 26.5076) - rmse: 1.3601 0.9190 (0.1897, 5.1486)\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 15.11760\n",
      "Epoch 213/1000\n",
      "84/84 [==============================] - 37s 439ms/step - loss: 14.9717 - output_0_loss: 9.2430 - output_1_loss: 5.7287 - val_loss: 15.8230 - val_output_0_loss: 8.8762 - val_output_1_loss: 6.9469\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9262 1.3045 (0.2828, 7.2818) - mae: 1.2248 0.8150 (0.1800, 4.7005) - mse: 7.6713 0.8508 (0.0400, 26.5125) - rmse: 1.3620 0.9224 (0.2000, 5.1490)\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 15.11760\n",
      "Epoch 214/1000\n",
      "84/84 [==============================] - 37s 440ms/step - loss: 14.9282 - output_0_loss: 9.2276 - output_1_loss: 5.7006 - val_loss: 15.8034 - val_output_0_loss: 8.8668 - val_output_1_loss: 6.9366\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9241 1.3093 (0.2828, 7.2616) - mae: 1.2235 0.8200 (0.1800, 4.7002) - mse: 7.6716 0.8572 (0.0400, 26.3652) - rmse: 1.3606 0.9258 (0.2000, 5.1347)\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 15.11760\n",
      "Epoch 215/1000\n",
      "84/84 [==============================] - 38s 447ms/step - loss: 15.0039 - output_0_loss: 9.2763 - output_1_loss: 5.7276 - val_loss: 15.8042 - val_output_0_loss: 8.8686 - val_output_1_loss: 6.9356\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9240 1.3046 (0.2828, 7.2989) - mae: 1.2235 0.8200 (0.1600, 4.6972) - mse: 7.6713 0.8510 (0.0400, 26.6373) - rmse: 1.3605 0.9225 (0.2000, 5.1611)\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 15.11760\n",
      "Epoch 216/1000\n",
      "84/84 [==============================] - 37s 437ms/step - loss: 15.0904 - output_0_loss: 9.3000 - output_1_loss: 5.7903 - val_loss: 15.8054 - val_output_0_loss: 8.8664 - val_output_1_loss: 6.9389\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9248 1.3014 (0.2828, 7.2948) - mae: 1.2239 0.8200 (0.1649, 4.6972) - mse: 7.6752 0.8468 (0.0400, 26.6071) - rmse: 1.3610 0.9202 (0.2000, 5.1582)\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 15.11760\n",
      "Epoch 217/1000\n",
      "84/84 [==============================] - 36s 433ms/step - loss: 14.9373 - output_0_loss: 9.2340 - output_1_loss: 5.7032 - val_loss: 15.7927 - val_output_0_loss: 8.8595 - val_output_1_loss: 6.9332\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9227 1.3046 (0.2828, 7.2948) - mae: 1.2227 0.8100 (0.1796, 4.6972) - mse: 7.6725 0.8510 (0.0400, 26.6071) - rmse: 1.3596 0.9225 (0.1999, 5.1582)\n",
      "\n",
      "Epoch 00217: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 15.11760\n",
      "Epoch 218/1000\n",
      "84/84 [==============================] - 37s 440ms/step - loss: 14.9090 - output_0_loss: 9.2098 - output_1_loss: 5.6992 - val_loss: 15.7919 - val_output_0_loss: 8.8594 - val_output_1_loss: 6.9326\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9227 1.3046 (0.2828, 7.2948) - mae: 1.2227 0.8100 (0.1600, 4.6972) - mse: 7.6719 0.8510 (0.0400, 26.6071) - rmse: 1.3595 0.9225 (0.2000, 5.1582)\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 15.11760\n",
      "Epoch 219/1000\n",
      "84/84 [==============================] - 36s 434ms/step - loss: 14.9145 - output_0_loss: 9.2232 - output_1_loss: 5.6913 - val_loss: 15.7935 - val_output_0_loss: 8.8600 - val_output_1_loss: 6.9335\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9229 1.3015 (0.2828, 7.2948) - mae: 1.2228 0.8100 (0.1796, 4.6972) - mse: 7.6728 0.8470 (0.0400, 26.6071) - rmse: 1.3597 0.9203 (0.2000, 5.1582)\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 15.11760\n",
      "Epoch 220/1000\n",
      "84/84 [==============================] - 37s 436ms/step - loss: 14.9246 - output_0_loss: 9.2164 - output_1_loss: 5.7081 - val_loss: 15.7941 - val_output_0_loss: 8.8607 - val_output_1_loss: 6.9334\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9230 1.3015 (0.2828, 7.2948) - mae: 1.2229 0.8100 (0.1800, 4.7002) - mse: 7.6735 0.8470 (0.0400, 26.6071) - rmse: 1.3598 0.9203 (0.2000, 5.1582)\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 15.11760\n",
      "Epoch 221/1000\n",
      "84/84 [==============================] - 38s 447ms/step - loss: 15.0775 - output_0_loss: 9.3013 - output_1_loss: 5.7762 - val_loss: 15.7973 - val_output_0_loss: 8.8624 - val_output_1_loss: 6.9349\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9233 1.3015 (0.2828, 7.2948) - mae: 1.2231 0.8100 (0.1800, 4.7002) - mse: 7.6744 0.8470 (0.0400, 26.6071) - rmse: 1.3600 0.9203 (0.2000, 5.1582)\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 15.11760\n",
      "Epoch 222/1000\n",
      "84/84 [==============================] - 36s 434ms/step - loss: 15.0834 - output_0_loss: 9.3146 - output_1_loss: 5.7688 - val_loss: 15.7942 - val_output_0_loss: 8.8609 - val_output_1_loss: 6.9332\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9231 1.3015 (0.2828, 7.2948) - mae: 1.2229 0.8100 (0.1600, 4.7002) - mse: 7.6727 0.8470 (0.0400, 26.6071) - rmse: 1.3598 0.9203 (0.2000, 5.1582)\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 15.11760\n",
      "Epoch 223/1000\n",
      "84/84 [==============================] - 37s 435ms/step - loss: 15.0595 - output_0_loss: 9.2995 - output_1_loss: 5.7600 - val_loss: 15.7935 - val_output_0_loss: 8.8609 - val_output_1_loss: 6.9326\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9228 1.3015 (0.2828, 7.2948) - mae: 1.2227 0.8100 (0.1600, 4.6972) - mse: 7.6722 0.8470 (0.0400, 26.6071) - rmse: 1.3596 0.9203 (0.2000, 5.1582)\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 15.11760\n",
      "Epoch 224/1000\n",
      "84/84 [==============================] - 37s 443ms/step - loss: 15.0290 - output_0_loss: 9.2797 - output_1_loss: 5.7494 - val_loss: 15.7968 - val_output_0_loss: 8.8624 - val_output_1_loss: 6.9343\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9230 1.3014 (0.2828, 7.2948) - mae: 1.2229 0.8100 (0.1600, 4.6972) - mse: 7.6709 0.8468 (0.0400, 26.6071) - rmse: 1.3598 0.9202 (0.2000, 5.1582)\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 15.11760\n",
      "Epoch 225/1000\n",
      "84/84 [==============================] - 37s 443ms/step - loss: 14.9376 - output_0_loss: 9.2147 - output_1_loss: 5.7229 - val_loss: 15.7853 - val_output_0_loss: 8.8575 - val_output_1_loss: 6.9278\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9217 1.3014 (0.2828, 7.2948) - mae: 1.2221 0.8100 (0.1649, 4.6972) - mse: 7.6692 0.8468 (0.0400, 26.6071) - rmse: 1.3589 0.9202 (0.2000, 5.1582)\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 15.11760\n",
      "Epoch 226/1000\n",
      "84/84 [==============================] - 37s 442ms/step - loss: 14.8560 - output_0_loss: 9.1930 - output_1_loss: 5.6630 - val_loss: 15.7822 - val_output_0_loss: 8.8557 - val_output_1_loss: 6.9265\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9212 1.3014 (0.2800, 7.2948) - mae: 1.2218 0.8050 (0.1600, 4.6972) - mse: 7.6688 0.8468 (0.0392, 26.6071) - rmse: 1.3585 0.9202 (0.1980, 5.1582)\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 15.11760\n",
      "Epoch 227/1000\n",
      "84/84 [==============================] - 37s 435ms/step - loss: 15.0417 - output_0_loss: 9.2848 - output_1_loss: 5.7569 - val_loss: 15.7758 - val_output_0_loss: 8.8535 - val_output_1_loss: 6.9222\n",
      "evaluation_metrics: mean median (2.5%, 97.5%) - euclidean: 1.9204 1.3014 (0.2800, 7.2948) - mae: 1.2213 0.8050 (0.1600, 4.6972) - mse: 7.6679 0.8468 (0.0392, 26.6071) - rmse: 1.3579 0.9202 (0.1980, 5.1582)\n",
      "\n",
      "Epoch 00227: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 15.11760\n",
      "Epoch 00227: early stopping\n"
     ]
    }
   ],
   "source": [
    "model.fit(batch_size=16,\n",
    "          validation_batch_size=10,\n",
    "          callbacks=callbacks,\n",
    "          epochs=1000,\n",
    "          n_workers=8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
